{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using base prefix 'c:\\\\users\\\\benar\\\\anaconda3'\n",
      "  No LICENSE.txt / LICENSE found in source\n",
      "New python executable in C:\\Users\\benar\\Desktop\\project_data\\bertenv\\Scripts\\python.exe\n",
      "Installing setuptools, pip, wheel...\n",
      "done.\n"
     ]
    }
   ],
   "source": [
    "!virtualenv bertenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# libraries\n",
    "import os\n",
    "import csv\n",
    "import time\n",
    "import tensorflow as tf\n",
    "import bert\n",
    "import pandas as pd\n",
    "from NYT_parser import NYTArticle\n",
    "from utilities import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get pathways\n",
    "train_paths = data_setup.get_paths('train')\n",
    "article = NYTArticle.from_file(os.path.join('data', train_paths[0][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set destination folder and make folders if needed\n",
    "dest_folder = 'sample/train/'\n",
    "if not os.path.exists(dest_folder):\n",
    "    os.makedirs(dest_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing sample/train/739212\n"
     ]
    }
   ],
   "source": [
    "# attempt a single file output\n",
    "print(\"Writing\", dest_folder+article.docid)\n",
    "article.simple_csv_output(dest_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing sample/train/1397928\n",
      "Writing sample/train/1609775\n",
      "Writing sample/train/297100\n",
      "Writing sample/train/448007\n",
      "Writing sample/train/1463610\n",
      "Writing sample/train/590096\n",
      "Writing sample/train/762936\n",
      "Writing sample/train/1570877\n",
      "Writing sample/train/1725268\n",
      "Writing sample/train/1647864\n",
      "Writing sample/train/1251662\n",
      "Writing sample/train/551924\n",
      "Writing sample/train/74723\n",
      "Writing sample/train/1535917\n",
      "Writing sample/train/744457\n",
      "Writing sample/train/97129\n",
      "Writing sample/train/899133\n",
      "Writing sample/train/791668\n",
      "Writing sample/train/779448\n",
      "Writing sample/train/1287650\n",
      "Writing sample/train/927546\n",
      "Writing sample/train/1587613\n",
      "Writing sample/train/638654\n",
      "Writing sample/train/870914\n",
      "Writing sample/train/800527\n",
      "Writing sample/train/1584905\n",
      "Writing sample/train/1287373\n",
      "Writing sample/train/1337862\n",
      "Writing sample/train/1646102\n",
      "Writing sample/train/1363692\n",
      "Writing sample/train/50986\n",
      "Writing sample/train/1481311\n",
      "Writing sample/train/1265869\n",
      "Writing sample/train/199802\n",
      "Writing sample/train/1000735\n",
      "Writing sample/train/1537677\n",
      "Writing sample/train/700412\n",
      "Writing sample/train/1043116\n",
      "Writing sample/train/1509284\n",
      "Writing sample/train/1562666\n"
     ]
    }
   ],
   "source": [
    "# attempt 50 article write minus filtered out\n",
    "for path in train_paths[:50]:\n",
    "    article = NYTArticle.from_file(os.path.join('data',path[0]))\n",
    "    if article.pass_filters():\n",
    "        print(\"Writing\", dest_folder+article.docid)\n",
    "        article.simple_csv_output(dest_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opened 10000 articles. Output 8341 articles.\n",
      "\n",
      "... processed 10000 files in 4.4035398960113525 seconds\n"
     ]
    }
   ],
   "source": [
    "# write all filtered articles in train set\n",
    "opened_article = 0\n",
    "written_article = 0\n",
    "start = time.time()\n",
    "for path in train_paths[:10000]:\n",
    "    opened_article += 1\n",
    "    article = NYTArticle.from_file(os.path.join('data',path[0]))\n",
    "    if article.pass_filters():\n",
    "        written_article += 1\n",
    "        article.simple_csv_output(dest_folder)\n",
    "    if opened_article % 10000 == 0:\n",
    "        print(\"Opened\", opened_article,\"articles. Output\", written_article,\"articles.\")\n",
    "print(f\"\\n... processed {opened_article} files in {time.time() - start} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headline</th>\n",
       "      <th>body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A Killer, Yes, but She's a Good Old Girl</td>\n",
       "      <td>Aileen Wuornos was big news 10 years ago. At a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>How High's The Bidding, Mama?</td>\n",
       "      <td>THE blue Rolls Royce sat at the York Street cu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Pacificorp reports earnings for Qtr to Sept 30</td>\n",
       "      <td>LEAD:\\n*3*** COMPANY REPORTS **\\n*3* Pacificor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Stewart Set to Return</td>\n",
       "      <td>There is bad news for Oakland's competition in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Taxing Online Sales</td>\n",
       "      <td>To the Editor:\\nRe ''So Many Online Sales, So ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         headline  \\\n",
       "0        A Killer, Yes, but She's a Good Old Girl   \n",
       "1                   How High's The Bidding, Mama?   \n",
       "2  Pacificorp reports earnings for Qtr to Sept 30   \n",
       "3                           Stewart Set to Return   \n",
       "4                             Taxing Online Sales   \n",
       "\n",
       "                                                body  \n",
       "0  Aileen Wuornos was big news 10 years ago. At a...  \n",
       "1  THE blue Rolls Royce sat at the York Street cu...  \n",
       "2  LEAD:\\n*3*** COMPANY REPORTS **\\n*3* Pacificor...  \n",
       "3  There is bad news for Oakland's competition in...  \n",
       "4  To the Editor:\\nRe ''So Many Online Sales, So ...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# build dataframe with articles\n",
    "sample = 1000\n",
    "\n",
    "headlines = []\n",
    "bodies = []\n",
    "\n",
    "for path in train_paths[:sample]:\n",
    "    article = NYTArticle.from_file(os.path.join('data',path[0]))\n",
    "    if article.pass_filters():\n",
    "        article.simple_csv_output(dest_folder)\n",
    "        headlines.append(article.print_hede[0])\n",
    "        # join paragraphs for now, may want to do something else later\n",
    "        bodies.append('\\n'.join(article.paragraphs))\n",
    "\n",
    "train_df = pd.DataFrame(data={'headline':headlines, 'body':bodies})\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Universal Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install deps\n",
    "!pip install -q -U tensor2tensor\n",
    "!pip install -q tensorflow matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0713 23:38:09.553236 139783483422528 deprecation_wrapper.py:119] From /home/mark/anaconda3/lib/python3.7/site-packages/tensor2tensor/utils/expert_utils.py:68: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
      "\n",
      "W0713 23:38:11.178983 139783483422528 lazy_loader.py:50] \n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "W0713 23:38:12.607595 139783483422528 deprecation_wrapper.py:119] From /home/mark/anaconda3/lib/python3.7/site-packages/tensor2tensor/utils/adafactor.py:27: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W0713 23:38:12.608830 139783483422528 deprecation_wrapper.py:119] From /home/mark/anaconda3/lib/python3.7/site-packages/tensor2tensor/utils/multistep_optimizer.py:32: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
      "\n",
      "W0713 23:38:12.626253 139783483422528 deprecation_wrapper.py:119] From /home/mark/anaconda3/lib/python3.7/site-packages/mesh_tensorflow/ops.py:4237: The name tf.train.CheckpointSaverListener is deprecated. Please use tf.estimator.CheckpointSaverListener instead.\n",
      "\n",
      "W0713 23:38:12.627107 139783483422528 deprecation_wrapper.py:119] From /home/mark/anaconda3/lib/python3.7/site-packages/mesh_tensorflow/ops.py:4260: The name tf.train.SessionRunHook is deprecated. Please use tf.estimator.SessionRunHook instead.\n",
      "\n",
      "W0713 23:38:12.685399 139783483422528 deprecation_wrapper.py:119] From /home/mark/anaconda3/lib/python3.7/site-packages/tensor2tensor/rl/gym_utils.py:219: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n",
      "\n",
      "W0713 23:38:12.735237 139783483422528 deprecation_wrapper.py:119] From /home/mark/anaconda3/lib/python3.7/site-packages/tensor2tensor/utils/trainer_lib.py:109: The name tf.OptimizerOptions is deprecated. Please use tf.compat.v1.OptimizerOptions instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Imports we need.\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import collections\n",
    "\n",
    "from tensor2tensor import models\n",
    "from tensor2tensor import problems\n",
    "from tensor2tensor.layers import common_layers\n",
    "from tensor2tensor.utils import trainer_lib\n",
    "from tensor2tensor.utils import t2t_model\n",
    "from tensor2tensor.utils import registry\n",
    "from tensor2tensor.utils import metrics\n",
    "\n",
    "# Enable TF Eager execution\n",
    "tfe = tf.contrib.eager\n",
    "tfe.enable_eager_execution()\n",
    "\n",
    "# Other setup\n",
    "Modes = tf.estimator.ModeKeys\n",
    "\n",
    "# Setup some directories\n",
    "data_dir = os.path.expanduser(\"./t2t/data\")\n",
    "tmp_dir = os.path.expanduser(\"./t2t/tmp\")\n",
    "train_dir = os.path.expanduser(\"./t2t/train\")\n",
    "checkpoint_dir = os.path.expanduser(\"./t2t/checkpoints\")\n",
    "tf.gfile.MakeDirs(data_dir)\n",
    "tf.gfile.MakeDirs(tmp_dir)\n",
    "tf.gfile.MakeDirs(train_dir)\n",
    "tf.gfile.MakeDirs(checkpoint_dir)\n",
    "gs_data_dir = \"gs://tensor2tensor-data/\"\n",
    "gs_ckpt_dir = \"gs://tensor2tensor-checkpoints/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# problems.available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying gs://tensor2tensor-data/vocab.summarize_cnn_dailymail32k.32768.subwords...\n",
      "- [1 files][293.7 KiB/293.7 KiB]                                                \n",
      "Operation completed over 1 objects/293.7 KiB.                                    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0713 23:38:16.647266 139783483422528 deprecation_wrapper.py:119] From /home/mark/anaconda3/lib/python3.7/site-packages/tensor2tensor/data_generators/text_encoder.py:938: The name tf.gfile.Exists is deprecated. Please use tf.io.gfile.exists instead.\n",
      "\n",
      "W0713 23:38:16.648737 139783483422528 deprecation_wrapper.py:119] From /home/mark/anaconda3/lib/python3.7/site-packages/tensor2tensor/data_generators/text_encoder.py:940: The name tf.gfile.Open is deprecated. Please use tf.io.gfile.GFile instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Fetch the problem\n",
    "sumCNN_problem = problems.problem(\"summarize_cnn_dailymail32k\")\n",
    "\n",
    "# Copy the vocab file locally so we can encode inputs and decode model outputs\n",
    "# All vocabs are stored on GCS\n",
    "# vocab_name = \"vocab.translate_ende_wmt32k.32768.subwords\"\n",
    "vocab_name = \"vocab.summarize_cnn_dailymail32k.32768.subwords\"\n",
    "vocab_file = os.path.join(gs_data_dir, vocab_name)\n",
    "!gsutil cp {vocab_file} {data_dir}\n",
    "\n",
    "# Get the encoders from the problem\n",
    "encoders = sumCNN_problem.feature_encoders(data_dir)\n",
    "\n",
    "# Setup helper functions for encoding and decoding\n",
    "def encode(input_str, output_str=None):\n",
    "  \"\"\"Input str to features dict, ready for inference\"\"\"\n",
    "  inputs = encoders[\"inputs\"].encode(input_str) + [1]  # add EOS id\n",
    "  batch_inputs = tf.reshape(inputs, [1, -1, 1])  # Make it 3D.\n",
    "  return {\"inputs\": batch_inputs}\n",
    "\n",
    "def decode(integers):\n",
    "  \"\"\"List of ints to str\"\"\"\n",
    "  integers = list(np.squeeze(integers))\n",
    "  if 1 in integers:\n",
    "    integers = integers[:integers.index(1)]\n",
    "  return encoders[\"inputs\"].decode(np.squeeze(integers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate and view the data\n",
    "# This cell is commented out because WMT data generation can take hours\n",
    "\n",
    "# sumCNN_problem.generate_data(data_dir, tmp_dir)\n",
    "# example = tfe.Iterator(sumCNN_problem.dataset(Modes.TRAIN, data_dir)).next()\n",
    "# inputs = [int(x) for x in example[\"inputs\"].numpy()] # Cast to ints.\n",
    "# targets = [int(x) for x in example[\"targets\"].numpy()] # Cast to ints.\n",
    "\n",
    "# # Example inputs as int-tensor.\n",
    "# print(\"Inputs, encoded:\")\n",
    "# print(inputs)\n",
    "# print(\"Inputs, decoded:\")\n",
    "# # Example inputs as a sentence.\n",
    "# print(decode(inputs))\n",
    "# # Example targets as int-tensor.\n",
    "# print(\"Targets, encoded:\")\n",
    "# print(targets)\n",
    "# # Example targets as a sentence.\n",
    "# print(\"Targets, decoded:\")\n",
    "# print(decode(targets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There are many models available in Tensor2Tensor\n",
    "# NOTE THAT THERE IS A UNIVERSAL TRANSFORMER IN HERE\n",
    "# registry.list_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0713 23:38:16.869588 139783483422528 deprecation_wrapper.py:119] From /home/mark/anaconda3/lib/python3.7/site-packages/tensor2tensor/layers/common_layers.py:94: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0713 23:38:17.114422 139783483422528 deprecation_wrapper.py:119] From /home/mark/anaconda3/lib/python3.7/site-packages/tensor2tensor/utils/t2t_model.py:243: The name tf.summary.text is deprecated. Please use tf.compat.v1.summary.text instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create hparams and the model\n",
    "model_name = \"transformer\"\n",
    "hparams_set = \"transformer_prepend\"\n",
    "\n",
    "hparams = trainer_lib.create_hparams(hparams_set, data_dir=data_dir, problem_name=\"summarize_cnn_dailymail32k\")\n",
    "\n",
    "# NOTE: Only create the model once when restoring from a checkpoint; it's a\n",
    "# Layer and so subsequent instantiations will have different variable scopes\n",
    "# that will not match the checkpoint.\n",
    "sumCNN_model = registry.model(model_name)(hparams, Modes.TRAIN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy the pretrained checkpoint locally\n",
    "# ckpt_name = \"transformer_ende_test\"\n",
    "# gs_ckpt = os.path.join(gs_ckpt_dir, ckpt_name)\n",
    "# !gsutil -q cp -R {gs_ckpt} {checkpoint_dir}\n",
    "# ckpt_path = tf.train.latest_checkpoint(os.path.join(checkpoint_dir, ckpt_name))\n",
    "# ckpt_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What checkpoints are available\n",
    "# gs://tensor2tensor-data/\n",
    "#     gs_data_dir\n",
    "# !gsutil ls {gs_ckpt_dir}\n",
    "# !gsutil ls {gs_data_dir}\n",
    "# !gsutil -q cp -R {'gs://tensor2tensor-data/vocab.cnndailymail.32768'} {checkpoint_dir}\n",
    "# !gsutil -q cp -R {'gs://tensor2tensor-data/vocab.summarize_cnn_dailymail32k.32768.subwords'} {checkpoint_dir}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0713 23:38:17.237405 139783483422528 deprecation.py:323] From /home/mark/anaconda3/lib/python3.7/site-packages/tensor2tensor/data_generators/problem.py:680: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.\n",
      "W0713 23:38:17.262322 139783483422528 deprecation_wrapper.py:119] From /home/mark/anaconda3/lib/python3.7/site-packages/tensor2tensor/data_generators/text_problems.py:394: The name tf.VarLenFeature is deprecated. Please use tf.io.VarLenFeature instead.\n",
      "\n",
      "W0713 23:38:17.263098 139783483422528 deprecation_wrapper.py:119] From /home/mark/anaconda3/lib/python3.7/site-packages/tensor2tensor/data_generators/problem.py:705: The name tf.FixedLenFeature is deprecated. Please use tf.io.FixedLenFeature instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Prepare for the training loop\n",
    "\n",
    "# In Eager mode, opt.minimize must be passed a loss function wrapped with\n",
    "# implicit_value_and_gradients\n",
    "@tfe.implicit_value_and_gradients\n",
    "def loss_fn(features):\n",
    "  _, losses = sumCNN_model(features)\n",
    "  return losses[\"training\"]\n",
    "\n",
    "# Setup the training data\n",
    "BATCH_SIZE = 1\n",
    "sumCNN_problem = problems.problem(\"summarize_cnn_dailymail32k\")\n",
    "sumCNN_dataset = sumCNN_problem.dataset(Modes.TRAIN, data_dir)\n",
    "sumCNN_dataset = sumCNN_dataset.repeat(None).batch(BATCH_SIZE)\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0713 23:38:17.462545 139783483422528 deprecation.py:323] From /home/mark/anaconda3/lib/python3.7/site-packages/tensor2tensor/utils/t2t_model.py:1367: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "W0713 23:38:17.578155 139783483422528 deprecation.py:323] From /home/mark/anaconda3/lib/python3.7/site-packages/tensor2tensor/layers/common_attention.py:856: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "W0713 23:38:17.591538 139783483422528 deprecation.py:323] From /home/mark/anaconda3/lib/python3.7/site-packages/tensor2tensor/utils/expert_utils.py:621: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "W0713 23:38:17.620629 139783483422528 deprecation_wrapper.py:119] From /home/mark/anaconda3/lib/python3.7/site-packages/tensor2tensor/layers/common_layers.py:3106: The name tf.layers.Dense is deprecated. Please use tf.compat.v1.layers.Dense instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 0, Loss: 9.538\n",
      "Step: 1, Loss: 8.869\n",
      "Step: 2, Loss: 8.981\n",
      "Step: 3, Loss: 8.170\n",
      "Step: 4, Loss: 8.577\n",
      "Step: 5, Loss: 7.643\n",
      "Step: 6, Loss: 7.989\n",
      "Step: 7, Loss: 8.202\n",
      "Step: 8, Loss: 7.758\n",
      "Step: 9, Loss: 7.898\n",
      "Step: 10, Loss: 7.992\n",
      "Step: 11, Loss: 7.677\n",
      "Step: 12, Loss: 7.712\n",
      "Step: 13, Loss: 8.245\n",
      "Step: 14, Loss: 7.242\n",
      "Step: 15, Loss: 7.520\n",
      "Step: 16, Loss: 8.657\n",
      "Step: 17, Loss: 7.090\n",
      "Step: 18, Loss: 7.319\n",
      "Step: 19, Loss: 7.459\n",
      "Step: 20, Loss: 8.075\n",
      "Step: 21, Loss: 8.205\n",
      "Step: 22, Loss: 7.676\n",
      "Step: 23, Loss: 6.971\n",
      "Step: 24, Loss: 8.007\n",
      "Step: 25, Loss: 7.403\n",
      "Step: 26, Loss: 7.468\n",
      "Step: 27, Loss: 6.904\n",
      "Step: 28, Loss: 7.520\n",
      "Step: 29, Loss: 7.623\n",
      "Step: 30, Loss: 7.588\n",
      "Step: 31, Loss: 7.643\n",
      "Step: 32, Loss: 7.620\n",
      "Step: 33, Loss: 7.318\n",
      "Step: 34, Loss: 7.433\n",
      "Step: 35, Loss: 7.667\n",
      "Step: 36, Loss: 7.077\n",
      "Step: 37, Loss: 7.985\n",
      "Step: 38, Loss: 8.073\n",
      "Step: 39, Loss: 7.463\n",
      "Step: 40, Loss: 7.257\n",
      "Step: 41, Loss: 7.105\n",
      "Step: 42, Loss: 7.541\n",
      "Step: 43, Loss: 7.835\n",
      "Step: 44, Loss: 7.481\n",
      "Step: 45, Loss: 7.946\n",
      "Step: 46, Loss: 7.176\n",
      "Step: 47, Loss: 7.435\n",
      "Step: 48, Loss: 6.598\n",
      "Step: 49, Loss: 7.558\n",
      "Step: 50, Loss: 7.747\n"
     ]
    }
   ],
   "source": [
    "# Train\n",
    "NUM_STEPS = 50\n",
    "\n",
    "for count, example in enumerate(tfe.Iterator(sumCNN_dataset)):\n",
    "#   print(example[\"targets\"])\n",
    "#   example[\"targets\"] = tf.reshape(example[\"targets\"], [BATCH_SIZE, 1, 1, 1])  # Make it 4D.\n",
    "  loss, gv = loss_fn(example)\n",
    "  optimizer.apply_gradients(gv)\n",
    "\n",
    "#   if count % 50 == 0:\n",
    "#     print(\"Step: %d, Loss: %.3f\" % (count, loss.numpy()))\n",
    "  print(\"Step: %d, Loss: %.3f\" % (count, loss.numpy()))\n",
    "  if count >= NUM_STEPS:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inputs = \"\"\"LEAD: New estimates by the Congressional Budget Office show that the cost of Government benefit programs is increasing much faster than had been expected.', 'New estimates by the Congressional Budget Office show that the cost of Government benefit programs is increasing much faster than had been expected.', 'The increase appears to result in part from decisions by state officials to expand social welfare programs such as Medicaid, which provides health care to the poor and is financed jointly by the Federal Government and the states.', 'In the Medicaid program, states set eligibility criteria and define the scope of benefits within guidelines set by Federal law. In the last year many states have expanded Medicaid eligibility or increased benefits to provide more assistance to pregnant women and children from low-income families.', 'In each state, the Federal Government pays at least half the costs of Medicaid and Aid to Families with Dependent Children, the main Federal-state welfare program. Giant Share of U.S. Spending', 'Benefit programs account for nearly half of all Federal spending. In August the budget office estimated that the cost of these programs would rise from $467 billion in the current fiscal year, 1987, to $499 billion in 1988 and eventually to $593 billion in 1991.', 'Aides to Rudolph G. Penner, director of the Congressional Budget Office, said today that the new estimates were $10 billion to $15 billion higher for 1987 and for 1988, and more than $20 billion higher for 1991.', 'These figures suggest that it will be difficult for Congress to meet the deficit targets set in the budget-balancing law signed by President Reagan in December 1985. The targets are $144 billion for 1987 and $108 billion for 1988. Under the law, the budget is supposed to be balanced by 1991.', \"\"Mr. Reagan plans to submit his 1988 budget to Congress on Monday. His budget director, James C. Miller 3d, has said that the President's budget would show a deficit of no more than $108 billion in 1988. Estimates of the cost of benefit programs have not yet been made public, and the budget does not contain a figure combining all the benefit programs.\"\", 'The latest estimates by the Congressional Budget Office mean that Democrats will be under new pressure to restrain the growth of domestic programs that they might otherwise want to expand. Democrats in the Senate and the House have begun drafting legislation to expand welfare, Medicare, the Federal health insurance program for the elderly and disabled, and Medicaid.', 'Under the major benefit programs, such as Social Security, student loans and unemployment compensation, people are entitled to benefits if they meet certain eligibility requirements set by law. In some of the programs, there is a test of financial need. But in others, people can obtain benefits regardless of their income or asssets.', 'Several of the programs provide assistance to farmers to support the prices of agricultural commodities such as corn, wheat, rice and cotton. Aides to Mr. Penner said the projected costs of these programs had risen substantially above the levels estimated in August: $19.7 billion for 1987 and $21.6 billion for 1988. But they said the new figures would not be disclosed for at least a week. Change in Revenue Estimates', \"\"Administration officials said President Reagan's budget would show revenue dramatically different from that estimated by Congress when it approved a major tax bill in September.\"\", 'At that time, the Congressional Joint Committee on Taxation compared the new measure with prior law and concluded that it would generate $11 billion more in 1987, but $17 billion less in 1988.', \"\"But Mr. Reagan's budget, using estimates developed by the Treasury Department, says the new law will produce a bigger gain in 1987, $18 billion, and no loss at all in 1988.\"\", 'David H. Brockway, chief of staff for the joint committee, said the panel had not changed its estimates.', \"\"The Treasury's figures have political implications because they would make it easier for the President and Congress to reduce the deficit in 1987 and 1988. But in later years the Treasury's estimates would have a different effect, because they show smaller gains in revenue, or more of a loss, than the joint committee's estimates.\"\", 'Most state income-tax laws are linked to Federal tax law in some way. Thirty-five states are expected to gain revenue if they make no change in their own laws. Some of the states plan to use part of that money to expand social welfare benefits.', 'Such changes could require a further increase in Federal spending because the Federal Government shares the cost of several major social welfare programs. The Federal contribution ranges from 50 percent to 78 percent of the cost of benefits under Medicaid and Aid to Families with Dependent Children. Increase for Science Foundation', 'While proposing cuts in many domestic programs, Administration officials said Mr. Reagan would seek an increase of more than 15 percent in the budget of the National Science Foundation, which supports research in science and engineering. The agency has a budget of $1.6 billion this year.', \"\"The proposed increase is part of Mr. Reagan's overall effort to ''keep America competitive'' by maintaining its technological edge over other countries.\"\", 'But budget officials said Mr. Reagan would ask Congress to slash the budget of the Corporation for Public Broadcasting, which supports public radio and television stations around the country. Congress has already voted to give the corporation $214 million in 1988, $228 million in 1989 and $254 million 1990.', \"\"Mr. Reagan wants to cut the corporation's budget to $170 million in 1988, $140 million in 1989 and $132 million in 1990, according to confidential budget documents.\"\"]\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0713 23:41:38.466648 139783483422528 deprecation.py:323] From /home/mark/anaconda3/lib/python3.7/site-packages/tensor2tensor/models/transformer.py:1148: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inputs: Hello, my name is Ben. And my partner on this project is Mark.\n",
      "Outputs: . . . . . . . . . . . . . . . . . . . . . . . . in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in\n"
     ]
    }
   ],
   "source": [
    "# Restore and translate!\n",
    "def translate(inputs):\n",
    "  encoded_inputs = encode(inputs)\n",
    "#   with tfe.restore_variables_on_create(ckpt_path):\n",
    "#     model_output = translate_model.infer(encoded_inputs)[\"outputs\"]\n",
    "  model_output = sumCNN_model.infer(encoded_inputs)[\"outputs\"]\n",
    "  return decode(model_output)\n",
    "\n",
    "inputs = \"Hello, my name is Ben. And my partner on this project is Mark.\"\n",
    "outputs = translate(inputs)\n",
    "\n",
    "print(\"Inputs: %s\" % inputs)\n",
    "print(\"Outputs: %s\" % outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
