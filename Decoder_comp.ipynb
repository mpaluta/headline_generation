{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0731 05:07:33.147006 139730746439488 lazy_loader.py:50] \n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "W0731 05:07:35.014700 139730746439488 deprecation_wrapper.py:119] From /home/arnoldyb/anaconda3/lib/python3.7/site-packages/tensor2tensor/utils/expert_utils.py:68: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# import libraries\n",
    "import os\n",
    "import pandas as pd\n",
    "from tensor2tensor.utils import registry\n",
    "from tensor2tensor.data_generators import text_problems #, token_generator, EOS\n",
    "from tensor2tensor.data_generators import problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0731 06:18:04.444290 139690170451776 deprecation_wrapper.py:119] From /home/arnoldyb/anaconda3/lib/python3.7/site-packages/tensor2tensor/utils/expert_utils.py:68: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
      "\n",
      "W0731 06:18:05.588047 139690170451776 lazy_loader.py:50] \n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "W0731 06:18:08.665431 139690170451776 deprecation_wrapper.py:119] From /home/arnoldyb/anaconda3/lib/python3.7/site-packages/tensor2tensor/utils/adafactor.py:27: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W0731 06:18:08.666222 139690170451776 deprecation_wrapper.py:119] From /home/arnoldyb/anaconda3/lib/python3.7/site-packages/tensor2tensor/utils/multistep_optimizer.py:32: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
      "\n",
      "W0731 06:18:08.698443 139690170451776 deprecation_wrapper.py:119] From /home/arnoldyb/anaconda3/lib/python3.7/site-packages/mesh_tensorflow/ops.py:4237: The name tf.train.CheckpointSaverListener is deprecated. Please use tf.estimator.CheckpointSaverListener instead.\n",
      "\n",
      "W0731 06:18:08.698792 139690170451776 deprecation_wrapper.py:119] From /home/arnoldyb/anaconda3/lib/python3.7/site-packages/mesh_tensorflow/ops.py:4260: The name tf.train.SessionRunHook is deprecated. Please use tf.estimator.SessionRunHook instead.\n",
      "\n",
      "W0731 06:18:08.739360 139690170451776 deprecation_wrapper.py:119] From /home/arnoldyb/anaconda3/lib/python3.7/site-packages/tensor2tensor/rl/gym_utils.py:219: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n",
      "\n",
      "W0731 06:18:08.782795 139690170451776 deprecation_wrapper.py:119] From /home/arnoldyb/anaconda3/lib/python3.7/site-packages/tensor2tensor/utils/trainer_lib.py:109: The name tf.OptimizerOptions is deprecated. Please use tf.compat.v1.OptimizerOptions instead.\n",
      "\n",
      "W0731 06:18:09.615194 139690170451776 deprecation_wrapper.py:119] From /home/arnoldyb/anaconda3/bin/t2t-decoder:16: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.\n",
      "\n",
      "W0731 06:18:09.615610 139690170451776 deprecation_wrapper.py:119] From /home/arnoldyb/anaconda3/bin/t2t-decoder:16: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.\n",
      "\n",
      "W0731 06:18:09.615918 139690170451776 deprecation_wrapper.py:119] From /home/arnoldyb/anaconda3/bin/t2t-decoder:17: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.\n",
      "\n",
      "W0731 06:18:09.616677 139690170451776 deprecation_wrapper.py:119] From /home/arnoldyb/anaconda3/lib/python3.7/site-packages/tensor2tensor/utils/trainer_lib.py:780: The name tf.set_random_seed is deprecated. Please use tf.compat.v1.set_random_seed instead.\n",
      "\n",
      "I0731 06:18:09.617536 139690170451776 usr_dir.py:43] Importing user module headline_generation from path /home/arnoldyb/w266/project\n",
      "W0731 06:18:09.913639 139690170451776 deprecation_wrapper.py:119] From /home/arnoldyb/anaconda3/lib/python3.7/site-packages/tensor2tensor/data_generators/text_encoder.py:938: The name tf.gfile.Exists is deprecated. Please use tf.io.gfile.exists instead.\n",
      "\n",
      "W0731 06:18:09.914170 139690170451776 deprecation_wrapper.py:119] From /home/arnoldyb/anaconda3/lib/python3.7/site-packages/tensor2tensor/data_generators/text_encoder.py:940: The name tf.gfile.Open is deprecated. Please use tf.io.gfile.GFile instead.\n",
      "\n",
      "W0731 06:18:10.139476 139690170451776 deprecation_wrapper.py:119] From /home/arnoldyb/anaconda3/lib/python3.7/site-packages/tensor2tensor/utils/trainer_lib.py:121: The name tf.GraphOptions is deprecated. Please use tf.compat.v1.GraphOptions instead.\n",
      "\n",
      "W0731 06:18:10.140638 139690170451776 deprecation_wrapper.py:119] From /home/arnoldyb/anaconda3/lib/python3.7/site-packages/tensor2tensor/utils/trainer_lib.py:127: The name tf.GPUOptions is deprecated. Please use tf.compat.v1.GPUOptions instead.\n",
      "\n",
      "W0731 06:18:10.141801 139690170451776 deprecation.py:323] From /home/arnoldyb/anaconda3/lib/python3.7/site-packages/tensor2tensor/utils/trainer_lib.py:240: RunConfig.__init__ (from tensorflow.contrib.learn.python.learn.estimators.run_config) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "When switching to tf.estimator.Estimator, use tf.estimator.RunConfig instead.\n",
      "I0731 06:18:10.142401 139690170451776 trainer_lib.py:263] Configuring DataParallelism to replicate the model.\n",
      "I0731 06:18:10.142689 139690170451776 devices.py:76] schedule=continuous_train_and_eval\n",
      "I0731 06:18:10.142834 139690170451776 devices.py:77] worker_gpu=1\n",
      "I0731 06:18:10.142940 139690170451776 devices.py:78] sync=False\n",
      "W0731 06:18:10.143147 139690170451776 deprecation_wrapper.py:119] From /home/arnoldyb/anaconda3/lib/python3.7/site-packages/tensor2tensor/utils/devices.py:139: The name tf.logging.warn is deprecated. Please use tf.compat.v1.logging.warn instead.\n",
      "\n",
      "W0731 06:18:10.143594 139690170451776 devices.py:141] Schedule=continuous_train_and_eval. Assuming that training is running on a single machine.\n",
      "I0731 06:18:10.144079 139690170451776 devices.py:170] datashard_devices: ['gpu:0']\n",
      "I0731 06:18:10.144430 139690170451776 devices.py:171] caching_devices: None\n",
      "I0731 06:18:10.144722 139690170451776 devices.py:172] ps_devices: ['gpu:0']\n",
      "I0731 06:18:10.157221 139690170451776 estimator.py:209] Using config: {'_task_type': None, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f0ba94266d8>, '_master': '', '_num_ps_replicas': 0, '_num_worker_replicas': 0, '_environment': 'local', '_is_chief': True, '_evaluation_master': '', '_train_distribute': None, '_eval_distribute': None, '_experimental_max_worker_delay_secs': None, '_device_fn': None, '_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1.0\n",
      "}\n",
      ", '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_secs': None, '_log_step_count_steps': 100, '_protocol': None, '_session_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 0.95\n",
      "}\n",
      "allow_soft_placement: true\n",
      "graph_options {\n",
      "  optimizer_options {\n",
      "    global_jit_level: OFF\n",
      "  }\n",
      "}\n",
      "isolate_session_state: true\n",
      ", '_save_checkpoints_steps': 1000, '_keep_checkpoint_max': 20, '_keep_checkpoint_every_n_hours': 10000, '_model_dir': './t2t_data/model', 'use_tpu': False, 't2t_device_info': {'num_async_replicas': 1}, 'data_parallelism': <tensor2tensor.utils.expert_utils.Parallelism object at 0x7f0ba9426748>}\n",
      "W0731 06:18:10.157738 139690170451776 model_fn.py:630] Estimator's model_fn (<function T2TModel.make_estimator_model_fn.<locals>.wrapping_model_fn at 0x7f0babeb2ea0>) includes params argument, but params are not passed to Estimator.\n",
      "I0731 06:18:10.158322 139690170451776 decoding.py:182] Performing local inference from dataset for gavrilov.\n",
      "W0731 06:18:10.158542 139690170451776 deprecation_wrapper.py:119] From /home/arnoldyb/anaconda3/lib/python3.7/site-packages/tensor2tensor/utils/decoding.py:188: The name tf.gfile.MakeDirs is deprecated. Please use tf.io.gfile.makedirs instead.\n",
      "\n",
      "I0731 06:18:10.158766 139690170451776 decoding.py:208] Decoding 0\n",
      "I0731 06:18:10.214591 139690170451776 problem.py:644] Reading data files from ./t2t_data/gavrilov-dev*\n",
      "I0731 06:18:10.227293 139690170451776 problem.py:670] partition: 0 num_data_files: 1\n",
      "W0731 06:18:10.304355 139690170451776 deprecation.py:323] From /home/arnoldyb/anaconda3/lib/python3.7/site-packages/tensor2tensor/utils/data_reader.py:37: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "W0731 06:18:10.622359 139690170451776 deprecation.py:323] From /home/arnoldyb/anaconda3/lib/python3.7/site-packages/tensorflow/python/data/experimental/ops/grouping.py:193: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W0731 06:18:10.695116 139690170451776 deprecation_wrapper.py:119] From /home/arnoldyb/anaconda3/lib/python3.7/site-packages/tensor2tensor/utils/data_reader.py:231: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.\n",
      "\n",
      "W0731 06:18:10.714166 139690170451776 deprecation.py:323] From /home/arnoldyb/anaconda3/lib/python3.7/site-packages/tensor2tensor/utils/data_reader.py:233: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "I0731 06:18:10.806219 139690170451776 estimator.py:1145] Calling model_fn.\n",
      "I0731 06:18:10.808068 139690170451776 t2t_model.py:2172] Setting T2TModel mode to 'infer'\n",
      "I0731 06:18:10.808939 139690170451776 t2t_model.py:2172] Setting hparams.dropout to 0.0\n",
      "I0731 06:18:10.809173 139690170451776 t2t_model.py:2172] Setting hparams.label_smoothing to 0.0\n",
      "I0731 06:18:10.809326 139690170451776 t2t_model.py:2172] Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "I0731 06:18:10.809466 139690170451776 t2t_model.py:2172] Setting hparams.symbol_dropout to 0.0\n",
      "I0731 06:18:10.809615 139690170451776 t2t_model.py:2172] Setting hparams.attention_dropout to 0.0\n",
      "I0731 06:18:10.809737 139690170451776 t2t_model.py:2172] Setting hparams.relu_dropout to 0.0\n",
      "W0731 06:18:10.934415 139690170451776 deprecation_wrapper.py:119] From /home/arnoldyb/anaconda3/lib/python3.7/site-packages/tensor2tensor/utils/t2t_model.py:243: The name tf.summary.text is deprecated. Please use tf.compat.v1.summary.text instead.\n",
      "\n",
      "I0731 06:18:10.957029 139690170451776 t2t_model.py:2172] Beam Decoding with beam size 3\n",
      "I0731 06:18:12.269674 139690170451776 api.py:255] Using variable initializer: uniform_unit_scaling\n",
      "I0731 06:18:12.888085 139690170451776 t2t_model.py:2172] Transforming feature 'inputs' with symbol_modality_32611_1024.bottom\n",
      "I0731 06:18:13.126152 139690170451776 t2t_model.py:2172] Transforming feature 'targets' with symbol_modality_32611_1024.targets_bottom\n",
      "I0731 06:18:13.159798 139690170451776 t2t_model.py:2172] Building model body\n",
      "W0731 06:18:13.211638 139690170451776 deprecation.py:506] From /home/arnoldyb/anaconda3/lib/python3.7/site-packages/tensor2tensor/models/research/universal_transformer.py:78: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "W0731 06:18:13.650787 139690170451776 deprecation_wrapper.py:119] From /home/arnoldyb/anaconda3/lib/python3.7/site-packages/tensor2tensor/layers/common_layers.py:3106: The name tf.layers.Dense is deprecated. Please use tf.compat.v1.layers.Dense instead.\n",
      "\n",
      "I0731 06:18:15.971622 139690170451776 t2t_model.py:2172] Transforming body output with symbol_modality_32611_1024.top\n",
      "W0731 06:18:16.176383 139690170451776 deprecation_wrapper.py:119] From /home/arnoldyb/anaconda3/lib/python3.7/site-packages/tensor2tensor/utils/t2t_model.py:1734: The name tf.saved_model.signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY is deprecated. Please use tf.saved_model.DEFAULT_SERVING_SIGNATURE_DEF_KEY instead.\n",
      "\n",
      "I0731 06:18:16.176803 139690170451776 estimator.py:1147] Done calling model_fn.\n",
      "I0731 06:18:16.407427 139690170451776 monitored_session.py:240] Graph was finalized.\n",
      "2019-07-31 06:18:16.407973: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "2019-07-31 06:18:16.422655: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2200000000 Hz\n",
      "2019-07-31 06:18:16.425539: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5592eb01ff30 executing computations on platform Host. Devices:\n",
      "2019-07-31 06:18:16.425597: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>\n",
      "W0731 06:18:16.428372 139690170451776 deprecation.py:323] From /home/arnoldyb/anaconda3/lib/python3.7/site-packages/tensorflow/python/training/saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "I0731 06:18:16.437540 139690170451776 saver.py:1280] Restoring parameters from ./t2t_data/model/model.ckpt-14000\n",
      "2019-07-31 06:18:16.534700: W tensorflow/core/common_runtime/colocation_graph.cc:1016] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [\n",
      "  /job:localhost/replica:0/task:0/device:CPU:0\n",
      "  /job:localhost/replica:0/task:0/device:XLA_CPU:0].\n",
      "See below for details of this colocation group:\n",
      "Colocation Debug Info:\n",
      "Colocation group had the following types and supported devices: \n",
      "Root Member(assigned_device_name_index_=-1 requested_device_name_='/device:GPU:0' assigned_device_name_='' resource_device_name_='/device:GPU:0' supported_device_types_=[CPU, XLA_CPU] possible_devices_=[]\n",
      "Enter: CPU XLA_CPU \n",
      "ReadVariableOp: CPU XLA_CPU \n",
      "AssignVariableOp: CPU XLA_CPU \n",
      "RandomStandardNormal: CPU XLA_CPU \n",
      "Mul: CPU XLA_CPU \n",
      "Add: CPU XLA_CPU \n",
      "VarHandleOp: CPU XLA_CPU \n",
      "Const: CPU XLA_CPU \n",
      "VarIsInitializedOp: CPU XLA_CPU \n",
      "\n",
      "Colocation members, user-requested devices, and framework assigned devices, if any:\n",
      "  universal_transformer/symbol_modality_32611_1024/shared/weights_0/Initializer/random_normal/shape (Const) \n",
      "  universal_transformer/symbol_modality_32611_1024/shared/weights_0/Initializer/random_normal/mean (Const) \n",
      "  universal_transformer/symbol_modality_32611_1024/shared/weights_0/Initializer/random_normal/stddev (Const) \n",
      "  universal_transformer/symbol_modality_32611_1024/shared/weights_0/Initializer/random_normal/RandomStandardNormal (RandomStandardNormal) \n",
      "  universal_transformer/symbol_modality_32611_1024/shared/weights_0/Initializer/random_normal/mul (Mul) \n",
      "  universal_transformer/symbol_modality_32611_1024/shared/weights_0/Initializer/random_normal (Add) \n",
      "  universal_transformer/symbol_modality_32611_1024/shared/weights_0 (VarHandleOp) /device:GPU:0\n",
      "  universal_transformer/symbol_modality_32611_1024/shared/weights_0/IsInitialized/VarIsInitializedOp (VarIsInitializedOp) /device:GPU:0\n",
      "  universal_transformer/symbol_modality_32611_1024/shared/weights_0/Assign (AssignVariableOp) /device:GPU:0\n",
      "  universal_transformer/symbol_modality_32611_1024/shared/weights_0/Read/ReadVariableOp (ReadVariableOp) /device:GPU:0\n",
      "  while/universal_transformer/parallel_0_6/universal_transformer/universal_transformer/symbol_modality_32611_1024/shared/concat/ReadVariableOp/Enter (Enter) /device:GPU:0\n",
      "  while/universal_transformer/parallel_0_6/universal_transformer/universal_transformer/symbol_modality_32611_1024/shared/concat/ReadVariableOp (ReadVariableOp) /device:GPU:0\n",
      "  while/universal_transformer/parallel_0_6/universal_transformer/universal_transformer/symbol_modality_32611_1024_1/shared/concat/ReadVariableOp (ReadVariableOp) /device:GPU:0\n",
      "  while/universal_transformer/parallel_0_6/universal_transformer/universal_transformer/symbol_modality_32611_1024_2/shared/concat/ReadVariableOp (ReadVariableOp) /device:GPU:0\n",
      "  report_uninitialized_variables/VarIsInitializedOp (VarIsInitializedOp) \n",
      "  report_uninitialized_variables_1/VarIsInitializedOp (VarIsInitializedOp) \n",
      "  save/AssignVariableOp_33 (AssignVariableOp) /device:GPU:0\n",
      "\n",
      "2019-07-31 06:18:16.535133: W tensorflow/core/common_runtime/colocation_graph.cc:1016] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [\n",
      "  /job:localhost/replica:0/task:0/device:CPU:0\n",
      "  /job:localhost/replica:0/task:0/device:XLA_CPU:0].\n",
      "See below for details of this colocation group:\n",
      "Colocation Debug Info:\n",
      "Colocation group had the following types and supported devices: \n",
      "Root Member(assigned_device_name_index_=-1 requested_device_name_='/device:GPU:0' assigned_device_name_='' resource_device_name_='/device:GPU:0' supported_device_types_=[CPU, XLA_CPU] possible_devices_=[]\n",
      "Enter: CPU XLA_CPU \n",
      "ReadVariableOp: CPU XLA_CPU \n",
      "AssignVariableOp: CPU XLA_CPU \n",
      "RandomStandardNormal: CPU XLA_CPU \n",
      "Mul: CPU XLA_CPU \n",
      "Add: CPU XLA_CPU \n",
      "VarHandleOp: CPU XLA_CPU \n",
      "Const: CPU XLA_CPU \n",
      "VarIsInitializedOp: CPU XLA_CPU \n",
      "\n",
      "Colocation members, user-requested devices, and framework assigned devices, if any:\n",
      "  universal_transformer/symbol_modality_32611_1024/shared/weights_1/Initializer/random_normal/shape (Const) \n",
      "  universal_transformer/symbol_modality_32611_1024/shared/weights_1/Initializer/random_normal/mean (Const) \n",
      "  universal_transformer/symbol_modality_32611_1024/shared/weights_1/Initializer/random_normal/stddev (Const) \n",
      "  universal_transformer/symbol_modality_32611_1024/shared/weights_1/Initializer/random_normal/RandomStandardNormal (RandomStandardNormal) \n",
      "  universal_transformer/symbol_modality_32611_1024/shared/weights_1/Initializer/random_normal/mul (Mul) \n",
      "  universal_transformer/symbol_modality_32611_1024/shared/weights_1/Initializer/random_normal (Add) \n",
      "  universal_transformer/symbol_modality_32611_1024/shared/weights_1 (VarHandleOp) /device:GPU:0\n",
      "  universal_transformer/symbol_modality_32611_1024/shared/weights_1/IsInitialized/VarIsInitializedOp (VarIsInitializedOp) /device:GPU:0\n",
      "  universal_transformer/symbol_modality_32611_1024/shared/weights_1/Assign (AssignVariableOp) /device:GPU:0\n",
      "  universal_transformer/symbol_modality_32611_1024/shared/weights_1/Read/ReadVariableOp (ReadVariableOp) /device:GPU:0\n",
      "  while/universal_transformer/parallel_0_6/universal_transformer/universal_transformer/symbol_modality_32611_1024/shared/concat/ReadVariableOp_1/Enter (Enter) /device:GPU:0\n",
      "  while/universal_transformer/parallel_0_6/universal_transformer/universal_transformer/symbol_modality_32611_1024/shared/concat/ReadVariableOp_1 (ReadVariableOp) /device:GPU:0\n",
      "  while/universal_transformer/parallel_0_6/universal_transformer/universal_transformer/symbol_modality_32611_1024_1/shared/concat/ReadVariableOp_1 (ReadVariableOp) /device:GPU:0\n",
      "  while/universal_transformer/parallel_0_6/universal_transformer/universal_transformer/symbol_modality_32611_1024_2/shared/concat/ReadVariableOp_1 (ReadVariableOp) /device:GPU:0\n",
      "  report_uninitialized_variables/VarIsInitializedOp_1 (VarIsInitializedOp) \n",
      "  report_uninitialized_variables_1/VarIsInitializedOp_1 (VarIsInitializedOp) \n",
      "  save/AssignVariableOp_34 (AssignVariableOp) /device:GPU:0\n",
      "\n",
      "2019-07-31 06:18:16.535641: W tensorflow/core/common_runtime/colocation_graph.cc:1016] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [\n",
      "  /job:localhost/replica:0/task:0/device:CPU:0\n",
      "  /job:localhost/replica:0/task:0/device:XLA_CPU:0].\n",
      "See below for details of this colocation group:\n",
      "Colocation Debug Info:\n",
      "Colocation group had the following types and supported devices: \n",
      "Root Member(assigned_device_name_index_=-1 requested_device_name_='/device:GPU:0' assigned_device_name_='' resource_device_name_='/device:GPU:0' supported_device_types_=[CPU, XLA_CPU] possible_devices_=[]\n",
      "Enter: CPU XLA_CPU \n",
      "ReadVariableOp: CPU XLA_CPU \n",
      "AssignVariableOp: CPU XLA_CPU \n",
      "RandomStandardNormal: CPU XLA_CPU \n",
      "Mul: CPU XLA_CPU \n",
      "Add: CPU XLA_CPU \n",
      "VarHandleOp: CPU XLA_CPU \n",
      "Const: CPU XLA_CPU \n",
      "VarIsInitializedOp: CPU XLA_CPU \n",
      "\n",
      "Colocation members, user-requested devices, and framework assigned devices, if any:\n",
      "  universal_transformer/symbol_modality_32611_1024/shared/weights_2/Initializer/random_normal/shape (Const) \n",
      "  universal_transformer/symbol_modality_32611_1024/shared/weights_2/Initializer/random_normal/mean (Const) \n",
      "  universal_transformer/symbol_modality_32611_1024/shared/weights_2/Initializer/random_normal/stddev (Const) \n",
      "  universal_transformer/symbol_modality_32611_1024/shared/weights_2/Initializer/random_normal/RandomStandardNormal (RandomStandardNormal) \n",
      "  universal_transformer/symbol_modality_32611_1024/shared/weights_2/Initializer/random_normal/mul (Mul) \n",
      "  universal_transformer/symbol_modality_32611_1024/shared/weights_2/Initializer/random_normal (Add) \n",
      "  universal_transformer/symbol_modality_32611_1024/shared/weights_2 (VarHandleOp) /device:GPU:0\n",
      "  universal_transformer/symbol_modality_32611_1024/shared/weights_2/IsInitialized/VarIsInitializedOp (VarIsInitializedOp) /device:GPU:0\n",
      "  universal_transformer/symbol_modality_32611_1024/shared/weights_2/Assign (AssignVariableOp) /device:GPU:0\n",
      "  universal_transformer/symbol_modality_32611_1024/shared/weights_2/Read/ReadVariableOp (ReadVariableOp) /device:GPU:0\n",
      "  while/universal_transformer/parallel_0_6/universal_transformer/universal_transformer/symbol_modality_32611_1024/shared/concat/ReadVariableOp_2/Enter (Enter) /device:GPU:0\n",
      "  while/universal_transformer/parallel_0_6/universal_transformer/universal_transformer/symbol_modality_32611_1024/shared/concat/ReadVariableOp_2 (ReadVariableOp) /device:GPU:0\n",
      "  while/universal_transformer/parallel_0_6/universal_transformer/universal_transformer/symbol_modality_32611_1024_1/shared/concat/ReadVariableOp_2 (ReadVariableOp) /device:GPU:0\n",
      "  while/universal_transformer/parallel_0_6/universal_transformer/universal_transformer/symbol_modality_32611_1024_2/shared/concat/ReadVariableOp_2 (ReadVariableOp) /device:GPU:0\n",
      "  report_uninitialized_variables/VarIsInitializedOp_2 (VarIsInitializedOp) \n",
      "  report_uninitialized_variables_1/VarIsInitializedOp_2 (VarIsInitializedOp) \n",
      "  save/AssignVariableOp_41 (AssignVariableOp) /device:GPU:0\n",
      "\n",
      "2019-07-31 06:18:16.536133: W tensorflow/core/common_runtime/colocation_graph.cc:1016] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [\n",
      "  /job:localhost/replica:0/task:0/device:CPU:0\n",
      "  /job:localhost/replica:0/task:0/device:XLA_CPU:0].\n",
      "See below for details of this colocation group:\n",
      "Colocation Debug Info:\n",
      "Colocation group had the following types and supported devices: \n",
      "Root Member(assigned_device_name_index_=-1 requested_device_name_='/device:GPU:0' assigned_device_name_='' resource_device_name_='/device:GPU:0' supported_device_types_=[CPU, XLA_CPU] possible_devices_=[]\n",
      "Enter: CPU XLA_CPU \n",
      "ReadVariableOp: CPU XLA_CPU \n",
      "AssignVariableOp: CPU XLA_CPU \n",
      "RandomStandardNormal: CPU XLA_CPU \n",
      "Mul: CPU XLA_CPU \n",
      "Add: CPU XLA_CPU \n",
      "VarHandleOp: CPU XLA_CPU \n",
      "Const: CPU XLA_CPU \n",
      "VarIsInitializedOp: CPU XLA_CPU \n",
      "\n",
      "Colocation members, user-requested devices, and framework assigned devices, if any:\n",
      "  universal_transformer/symbol_modality_32611_1024/shared/weights_3/Initializer/random_normal/shape (Const) \n",
      "  universal_transformer/symbol_modality_32611_1024/shared/weights_3/Initializer/random_normal/mean (Const) \n",
      "  universal_transformer/symbol_modality_32611_1024/shared/weights_3/Initializer/random_normal/stddev (Const) \n",
      "  universal_transformer/symbol_modality_32611_1024/shared/weights_3/Initializer/random_normal/RandomStandardNormal (RandomStandardNormal) \n",
      "  universal_transformer/symbol_modality_32611_1024/shared/weights_3/Initializer/random_normal/mul (Mul) \n",
      "  universal_transformer/symbol_modality_32611_1024/shared/weights_3/Initializer/random_normal (Add) \n",
      "  universal_transformer/symbol_modality_32611_1024/shared/weights_3 (VarHandleOp) /device:GPU:0\n",
      "  universal_transformer/symbol_modality_32611_1024/shared/weights_3/IsInitialized/VarIsInitializedOp (VarIsInitializedOp) /device:GPU:0\n",
      "  universal_transformer/symbol_modality_32611_1024/shared/weights_3/Assign (AssignVariableOp) /device:GPU:0\n",
      "  universal_transformer/symbol_modality_32611_1024/shared/weights_3/Read/ReadVariableOp (ReadVariableOp) /device:GPU:0\n",
      "  while/universal_transformer/parallel_0_6/universal_transformer/universal_transformer/symbol_modality_32611_1024/shared/concat/ReadVariableOp_3/Enter (Enter) /device:GPU:0\n",
      "  while/universal_transformer/parallel_0_6/universal_transformer/universal_transformer/symbol_modality_32611_1024/shared/concat/ReadVariableOp_3 (ReadVariableOp) /device:GPU:0\n",
      "  while/universal_transformer/parallel_0_6/universal_transformer/universal_transformer/symbol_modality_32611_1024_1/shared/concat/ReadVariableOp_3 (ReadVariableOp) /device:GPU:0\n",
      "  while/universal_transformer/parallel_0_6/universal_transformer/universal_transformer/symbol_modality_32611_1024_2/shared/concat/ReadVariableOp_3 (ReadVariableOp) /device:GPU:0\n",
      "  report_uninitialized_variables/VarIsInitializedOp_3 (VarIsInitializedOp) \n",
      "  report_uninitialized_variables_1/VarIsInitializedOp_3 (VarIsInitializedOp) \n",
      "  save/AssignVariableOp_42 (AssignVariableOp) /device:GPU:0\n",
      "\n",
      "2019-07-31 06:18:16.536594: W tensorflow/core/common_runtime/colocation_graph.cc:1016] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [\n",
      "  /job:localhost/replica:0/task:0/device:CPU:0\n",
      "  /job:localhost/replica:0/task:0/device:XLA_CPU:0].\n",
      "See below for details of this colocation group:\n",
      "Colocation Debug Info:\n",
      "Colocation group had the following types and supported devices: \n",
      "Root Member(assigned_device_name_index_=-1 requested_device_name_='/device:GPU:0' assigned_device_name_='' resource_device_name_='/device:GPU:0' supported_device_types_=[CPU, XLA_CPU] possible_devices_=[]\n",
      "Enter: CPU XLA_CPU \n",
      "ReadVariableOp: CPU XLA_CPU \n",
      "AssignVariableOp: CPU XLA_CPU \n",
      "RandomStandardNormal: CPU XLA_CPU \n",
      "Mul: CPU XLA_CPU \n",
      "Add: CPU XLA_CPU \n",
      "VarHandleOp: CPU XLA_CPU \n",
      "Const: CPU XLA_CPU \n",
      "VarIsInitializedOp: CPU XLA_CPU \n",
      "\n",
      "Colocation members, user-requested devices, and framework assigned devices, if any:\n",
      "  universal_transformer/symbol_modality_32611_1024/shared/weights_4/Initializer/random_normal/shape (Const) \n",
      "  universal_transformer/symbol_modality_32611_1024/shared/weights_4/Initializer/random_normal/mean (Const) \n",
      "  universal_transformer/symbol_modality_32611_1024/shared/weights_4/Initializer/random_normal/stddev (Const) \n",
      "  universal_transformer/symbol_modality_32611_1024/shared/weights_4/Initializer/random_normal/RandomStandardNormal (RandomStandardNormal) \n",
      "  universal_transformer/symbol_modality_32611_1024/shared/weights_4/Initializer/random_normal/mul (Mul) \n",
      "  universal_transformer/symbol_modality_32611_1024/shared/weights_4/Initializer/random_normal (Add) \n",
      "  universal_transformer/symbol_modality_32611_1024/shared/weights_4 (VarHandleOp) /device:GPU:0\n",
      "  universal_transformer/symbol_modality_32611_1024/shared/weights_4/IsInitialized/VarIsInitializedOp (VarIsInitializedOp) /device:GPU:0\n",
      "  universal_transformer/symbol_modality_32611_1024/shared/weights_4/Assign (AssignVariableOp) /device:GPU:0\n",
      "  universal_transformer/symbol_modality_32611_1024/shared/weights_4/Read/ReadVariableOp (ReadVariableOp) /device:GPU:0\n",
      "  while/universal_transformer/parallel_0_6/universal_transformer/universal_transformer/symbol_modality_32611_1024/shared/concat/ReadVariableOp_4/Enter (Enter) /device:GPU:0\n",
      "  while/universal_transformer/parallel_0_6/universal_transformer/universal_transformer/symbol_modality_32611_1024/shared/concat/ReadVariableOp_4 (ReadVariableOp) /device:GPU:0\n",
      "  while/universal_transformer/parallel_0_6/universal_transformer/universal_transformer/symbol_modality_32611_1024_1/shared/concat/ReadVariableOp_4 (ReadVariableOp) /device:GPU:0\n",
      "  while/universal_transformer/parallel_0_6/universal_transformer/universal_transformer/symbol_modality_32611_1024_2/shared/concat/ReadVariableOp_4 (ReadVariableOp) /device:GPU:0\n",
      "  report_uninitialized_variables/VarIsInitializedOp_4 (VarIsInitializedOp) \n",
      "  report_uninitialized_variables_1/VarIsInitializedOp_4 (VarIsInitializedOp) \n",
      "  save/AssignVariableOp_43 (AssignVariableOp) /device:GPU:0\n",
      "\n",
      "2019-07-31 06:18:16.537050: W tensorflow/core/common_runtime/colocation_graph.cc:1016] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [\n",
      "  /job:localhost/replica:0/task:0/device:CPU:0\n",
      "  /job:localhost/replica:0/task:0/device:XLA_CPU:0].\n",
      "See below for details of this colocation group:\n",
      "Colocation Debug Info:\n",
      "Colocation group had the following types and supported devices: \n",
      "Root Member(assigned_device_name_index_=-1 requested_device_name_='/device:GPU:0' assigned_device_name_='' resource_device_name_='/device:GPU:0' supported_device_types_=[CPU, XLA_CPU] possible_devices_=[]\n",
      "Enter: CPU XLA_CPU \n",
      "ReadVariableOp: CPU XLA_CPU \n",
      "AssignVariableOp: CPU XLA_CPU \n",
      "RandomStandardNormal: CPU XLA_CPU \n",
      "Mul: CPU XLA_CPU \n",
      "Add: CPU XLA_CPU \n",
      "VarHandleOp: CPU XLA_CPU \n",
      "Const: CPU XLA_CPU \n",
      "VarIsInitializedOp: CPU XLA_CPU \n",
      "\n",
      "Colocation members, user-requested devices, and framework assigned devices, if any:\n",
      "  universal_transformer/symbol_modality_32611_1024/shared/weights_5/Initializer/random_normal/shape (Const) \n",
      "  universal_transformer/symbol_modality_32611_1024/shared/weights_5/Initializer/random_normal/mean (Const) \n",
      "  universal_transformer/symbol_modality_32611_1024/shared/weights_5/Initializer/random_normal/stddev (Const) \n",
      "  universal_transformer/symbol_modality_32611_1024/shared/weights_5/Initializer/random_normal/RandomStandardNormal (RandomStandardNormal) \n",
      "  universal_transformer/symbol_modality_32611_1024/shared/weights_5/Initializer/random_normal/mul (Mul) \n",
      "  universal_transformer/symbol_modality_32611_1024/shared/weights_5/Initializer/random_normal (Add) \n",
      "  universal_transformer/symbol_modality_32611_1024/shared/weights_5 (VarHandleOp) /device:GPU:0\n",
      "  universal_transformer/symbol_modality_32611_1024/shared/weights_5/IsInitialized/VarIsInitializedOp (VarIsInitializedOp) /device:GPU:0\n",
      "  universal_transformer/symbol_modality_32611_1024/shared/weights_5/Assign (AssignVariableOp) /device:GPU:0\n",
      "  universal_transformer/symbol_modality_32611_1024/shared/weights_5/Read/ReadVariableOp (ReadVariableOp) /device:GPU:0\n",
      "  while/universal_transformer/parallel_0_6/universal_transformer/universal_transformer/symbol_modality_32611_1024/shared/concat/ReadVariableOp_5/Enter (Enter) /device:GPU:0\n",
      "  while/universal_transformer/parallel_0_6/universal_transformer/universal_transformer/symbol_modality_32611_1024/shared/concat/ReadVariableOp_5 (ReadVariableOp) /device:GPU:0\n",
      "  while/universal_transformer/parallel_0_6/universal_transformer/universal_transformer/symbol_modality_32611_1024_1/shared/concat/ReadVariableOp_5 (ReadVariableOp) /device:GPU:0\n",
      "  while/universal_transformer/parallel_0_6/universal_transformer/universal_transformer/symbol_modality_32611_1024_2/shared/concat/ReadVariableOp_5 (ReadVariableOp) /device:GPU:0\n",
      "  report_uninitialized_variables/VarIsInitializedOp_5 (VarIsInitializedOp) \n",
      "  report_uninitialized_variables_1/VarIsInitializedOp_5 (VarIsInitializedOp) \n",
      "  save/AssignVariableOp_44 (AssignVariableOp) /device:GPU:0\n",
      "\n",
      "2019-07-31 06:18:16.537489: W tensorflow/core/common_runtime/colocation_graph.cc:1016] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [\n",
      "  /job:localhost/replica:0/task:0/device:CPU:0\n",
      "  /job:localhost/replica:0/task:0/device:XLA_CPU:0].\n",
      "See below for details of this colocation group:\n",
      "Colocation Debug Info:\n",
      "Colocation group had the following types and supported devices: \n",
      "Root Member(assigned_device_name_index_=-1 requested_device_name_='/device:GPU:0' assigned_device_name_='' resource_device_name_='/device:GPU:0' supported_device_types_=[CPU, XLA_CPU] possible_devices_=[]\n",
      "Enter: CPU XLA_CPU \n",
      "ReadVariableOp: CPU XLA_CPU \n",
      "AssignVariableOp: CPU XLA_CPU \n",
      "RandomStandardNormal: CPU XLA_CPU \n",
      "Mul: CPU XLA_CPU \n",
      "Add: CPU XLA_CPU \n",
      "VarHandleOp: CPU XLA_CPU \n",
      "Const: CPU XLA_CPU \n",
      "VarIsInitializedOp: CPU XLA_CPU \n",
      "\n",
      "Colocation members, user-requested devices, and framework assigned devices, if any:\n",
      "  universal_transformer/symbol_modality_32611_1024/shared/weights_6/Initializer/random_normal/shape (Const) \n",
      "  universal_transformer/symbol_modality_32611_1024/shared/weights_6/Initializer/random_normal/mean (Const) \n",
      "  universal_transformer/symbol_modality_32611_1024/shared/weights_6/Initializer/random_normal/stddev (Const) \n",
      "  universal_transformer/symbol_modality_32611_1024/shared/weights_6/Initializer/random_normal/RandomStandardNormal (RandomStandardNormal) \n",
      "  universal_transformer/symbol_modality_32611_1024/shared/weights_6/Initializer/random_normal/mul (Mul) \n",
      "  universal_transformer/symbol_modality_32611_1024/shared/weights_6/Initializer/random_normal (Add) \n",
      "  universal_transformer/symbol_modality_32611_1024/shared/weights_6 (VarHandleOp) /device:GPU:0\n",
      "  universal_transformer/symbol_modality_32611_1024/shared/weights_6/IsInitialized/VarIsInitializedOp (VarIsInitializedOp) /device:GPU:0\n",
      "  universal_transformer/symbol_modality_32611_1024/shared/weights_6/Assign (AssignVariableOp) /device:GPU:0\n",
      "  universal_transformer/symbol_modality_32611_1024/shared/weights_6/Read/ReadVariableOp (ReadVariableOp) /device:GPU:0\n",
      "  while/universal_transformer/parallel_0_6/universal_transformer/universal_transformer/symbol_modality_32611_1024/shared/concat/ReadVariableOp_6/Enter (Enter) /device:GPU:0\n",
      "  while/universal_transformer/parallel_0_6/universal_transformer/universal_transformer/symbol_modality_32611_1024/shared/concat/ReadVariableOp_6 (ReadVariableOp) /device:GPU:0\n",
      "  while/universal_transformer/parallel_0_6/universal_transformer/universal_transformer/symbol_modality_32611_1024_1/shared/concat/ReadVariableOp_6 (ReadVariableOp) /device:GPU:0\n",
      "  while/universal_transformer/parallel_0_6/universal_transformer/universal_transformer/symbol_modality_32611_1024_2/shared/concat/ReadVariableOp_6 (ReadVariableOp) /device:GPU:0\n",
      "  report_uninitialized_variables/VarIsInitializedOp_6 (VarIsInitializedOp) \n",
      "  report_uninitialized_variables_1/VarIsInitializedOp_6 (VarIsInitializedOp) \n",
      "  save/AssignVariableOp_45 (AssignVariableOp) /device:GPU:0\n",
      "\n",
      "2019-07-31 06:18:16.537930: W tensorflow/core/common_runtime/colocation_graph.cc:1016] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [\n",
      "  /job:localhost/replica:0/task:0/device:CPU:0\n",
      "  /job:localhost/replica:0/task:0/device:XLA_CPU:0].\n",
      "See below for details of this colocation group:\n",
      "Colocation Debug Info:\n",
      "Colocation group had the following types and supported devices: \n",
      "Root Member(assigned_device_name_index_=-1 requested_device_name_='/device:GPU:0' assigned_device_name_='' resource_device_name_='/device:GPU:0' supported_device_types_=[CPU, XLA_CPU] possible_devices_=[]\n",
      "Enter: CPU XLA_CPU \n",
      "ReadVariableOp: CPU XLA_CPU \n",
      "AssignVariableOp: CPU XLA_CPU \n",
      "RandomStandardNormal: CPU XLA_CPU \n",
      "Mul: CPU XLA_CPU \n",
      "Add: CPU XLA_CPU \n",
      "VarHandleOp: CPU XLA_CPU \n",
      "Const: CPU XLA_CPU \n",
      "VarIsInitializedOp: CPU XLA_CPU \n",
      "\n",
      "Colocation members, user-requested devices, and framework assigned devices, if any:\n",
      "  universal_transformer/symbol_modality_32611_1024/shared/weights_7/Initializer/random_normal/shape (Const) \n",
      "  universal_transformer/symbol_modality_32611_1024/shared/weights_7/Initializer/random_normal/mean (Const) \n",
      "  universal_transformer/symbol_modality_32611_1024/shared/weights_7/Initializer/random_normal/stddev (Const) \n",
      "  universal_transformer/symbol_modality_32611_1024/shared/weights_7/Initializer/random_normal/RandomStandardNormal (RandomStandardNormal) \n",
      "  universal_transformer/symbol_modality_32611_1024/shared/weights_7/Initializer/random_normal/mul (Mul) \n",
      "  universal_transformer/symbol_modality_32611_1024/shared/weights_7/Initializer/random_normal (Add) \n",
      "  universal_transformer/symbol_modality_32611_1024/shared/weights_7 (VarHandleOp) /device:GPU:0\n",
      "  universal_transformer/symbol_modality_32611_1024/shared/weights_7/IsInitialized/VarIsInitializedOp (VarIsInitializedOp) /device:GPU:0\n",
      "  universal_transformer/symbol_modality_32611_1024/shared/weights_7/Assign (AssignVariableOp) /device:GPU:0\n",
      "  universal_transformer/symbol_modality_32611_1024/shared/weights_7/Read/ReadVariableOp (ReadVariableOp) /device:GPU:0\n",
      "  while/universal_transformer/parallel_0_6/universal_transformer/universal_transformer/symbol_modality_32611_1024/shared/concat/ReadVariableOp_7/Enter (Enter) /device:GPU:0\n",
      "  while/universal_transformer/parallel_0_6/universal_transformer/universal_transformer/symbol_modality_32611_1024/shared/concat/ReadVariableOp_7 (ReadVariableOp) /device:GPU:0\n",
      "  while/universal_transformer/parallel_0_6/universal_transformer/universal_transformer/symbol_modality_32611_1024_1/shared/concat/ReadVariableOp_7 (ReadVariableOp) /device:GPU:0\n",
      "  while/universal_transformer/parallel_0_6/universal_transformer/universal_transformer/symbol_modality_32611_1024_2/shared/concat/ReadVariableOp_7 (ReadVariableOp) /device:GPU:0\n",
      "  report_uninitialized_variables/VarIsInitializedOp_7 (VarIsInitializedOp) \n",
      "  report_uninitialized_variables_1/VarIsInitializedOp_7 (VarIsInitializedOp) \n",
      "  save/AssignVariableOp_46 (AssignVariableOp) /device:GPU:0\n",
      "\n",
      "2019-07-31 06:18:16.538365: W tensorflow/core/common_runtime/colocation_graph.cc:1016] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [\n",
      "  /job:localhost/replica:0/task:0/device:CPU:0\n",
      "  /job:localhost/replica:0/task:0/device:XLA_CPU:0].\n",
      "See below for details of this colocation group:\n",
      "Colocation Debug Info:\n",
      "Colocation group had the following types and supported devices: \n",
      "Root Member(assigned_device_name_index_=-1 requested_device_name_='/device:GPU:0' assigned_device_name_='' resource_device_name_='/device:GPU:0' supported_device_types_=[CPU, XLA_CPU] possible_devices_=[]\n",
      "Enter: CPU XLA_CPU \n",
      "ReadVariableOp: CPU XLA_CPU \n",
      "AssignVariableOp: CPU XLA_CPU \n",
      "RandomStandardNormal: CPU XLA_CPU \n",
      "Mul: CPU XLA_CPU \n",
      "Add: CPU XLA_CPU \n",
      "VarHandleOp: CPU XLA_CPU \n",
      "Const: CPU XLA_CPU \n",
      "VarIsInitializedOp: CPU XLA_CPU \n",
      "\n",
      "Colocation members, user-requested devices, and framework assigned devices, if any:\n",
      "  universal_transformer/symbol_modality_32611_1024/shared/weights_8/Initializer/random_normal/shape (Const) \n",
      "  universal_transformer/symbol_modality_32611_1024/shared/weights_8/Initializer/random_normal/mean (Const) \n",
      "  universal_transformer/symbol_modality_32611_1024/shared/weights_8/Initializer/random_normal/stddev (Const) \n",
      "  universal_transformer/symbol_modality_32611_1024/shared/weights_8/Initializer/random_normal/RandomStandardNormal (RandomStandardNormal) \n",
      "  universal_transformer/symbol_modality_32611_1024/shared/weights_8/Initializer/random_normal/mul (Mul) \n",
      "  universal_transformer/symbol_modality_32611_1024/shared/weights_8/Initializer/random_normal (Add) \n",
      "  universal_transformer/symbol_modality_32611_1024/shared/weights_8 (VarHandleOp) /device:GPU:0\n",
      "  universal_transformer/symbol_modality_32611_1024/shared/weights_8/IsInitialized/VarIsInitializedOp (VarIsInitializedOp) /device:GPU:0\n",
      "  universal_transformer/symbol_modality_32611_1024/shared/weights_8/Assign (AssignVariableOp) /device:GPU:0\n",
      "  universal_transformer/symbol_modality_32611_1024/shared/weights_8/Read/ReadVariableOp (ReadVariableOp) /device:GPU:0\n",
      "  while/universal_transformer/parallel_0_6/universal_transformer/universal_transformer/symbol_modality_32611_1024/shared/concat/ReadVariableOp_8/Enter (Enter) /device:GPU:0\n",
      "  while/universal_transformer/parallel_0_6/universal_transformer/universal_transformer/symbol_modality_32611_1024/shared/concat/ReadVariableOp_8 (ReadVariableOp) /device:GPU:0\n",
      "  while/universal_transformer/parallel_0_6/universal_transformer/universal_transformer/symbol_modality_32611_1024_1/shared/concat/ReadVariableOp_8 (ReadVariableOp) /device:GPU:0\n",
      "  while/universal_transformer/parallel_0_6/universal_transformer/universal_transformer/symbol_modality_32611_1024_2/shared/concat/ReadVariableOp_8 (ReadVariableOp) /device:GPU:0\n",
      "  report_uninitialized_variables/VarIsInitializedOp_8 (VarIsInitializedOp) \n",
      "  report_uninitialized_variables_1/VarIsInitializedOp_8 (VarIsInitializedOp) \n",
      "  save/AssignVariableOp_47 (AssignVariableOp) /device:GPU:0\n",
      "\n",
      "2019-07-31 06:18:16.538811: W tensorflow/core/common_runtime/colocation_graph.cc:1016] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [\n",
      "  /job:localhost/replica:0/task:0/device:CPU:0\n",
      "  /job:localhost/replica:0/task:0/device:XLA_CPU:0].\n",
      "See below for details of this colocation group:\n",
      "Colocation Debug Info:\n",
      "Colocation group had the following types and supported devices: \n",
      "Root Member(assigned_device_name_index_=-1 requested_device_name_='/device:GPU:0' assigned_device_name_='' resource_device_name_='/device:GPU:0' supported_device_types_=[CPU, XLA_CPU] possible_devices_=[]\n",
      "Enter: CPU XLA_CPU \n",
      "ReadVariableOp: CPU XLA_CPU \n",
      "AssignVariableOp: CPU XLA_CPU \n",
      "RandomStandardNormal: CPU XLA_CPU \n",
      "Mul: CPU XLA_CPU \n",
      "Add: CPU XLA_CPU \n",
      "VarHandleOp: CPU XLA_CPU \n",
      "Const: CPU XLA_CPU \n",
      "VarIsInitializedOp: CPU XLA_CPU \n",
      "\n",
      "Colocation members, user-requested devices, and framework assigned devices, if any:\n",
      "  universal_transformer/symbol_modality_32611_1024/shared/weights_9/Initializer/random_normal/shape (Const) \n",
      "  universal_transformer/symbol_modality_32611_1024/shared/weights_9/Initializer/random_normal/mean (Const) \n",
      "  universal_transformer/symbol_modality_32611_1024/shared/weights_9/Initializer/random_normal/stddev (Const) \n",
      "  universal_transformer/symbol_modality_32611_1024/shared/weights_9/Initializer/random_normal/RandomStandardNormal (RandomStandardNormal) \n",
      "  universal_transformer/symbol_modality_32611_1024/shared/weights_9/Initializer/random_normal/mul (Mul) \n",
      "  universal_transformer/symbol_modality_32611_1024/shared/weights_9/Initializer/random_normal (Add) \n",
      "  universal_transformer/symbol_modality_32611_1024/shared/weights_9 (VarHandleOp) /device:GPU:0\n",
      "  universal_transformer/symbol_modality_32611_1024/shared/weights_9/IsInitialized/VarIsInitializedOp (VarIsInitializedOp) /device:GPU:0\n",
      "  universal_transformer/symbol_modality_32611_1024/shared/weights_9/Assign (AssignVariableOp) /device:GPU:0\n",
      "  universal_transformer/symbol_modality_32611_1024/shared/weights_9/Read/ReadVariableOp (ReadVariableOp) /device:GPU:0\n",
      "  while/universal_transformer/parallel_0_6/universal_transformer/universal_transformer/symbol_modality_32611_1024/shared/concat/ReadVariableOp_9/Enter (Enter) /device:GPU:0\n",
      "  while/universal_transformer/parallel_0_6/universal_transformer/universal_transformer/symbol_modality_32611_1024/shared/concat/ReadVariableOp_9 (ReadVariableOp) /device:GPU:0\n",
      "  while/universal_transformer/parallel_0_6/universal_transformer/universal_transformer/symbol_modality_32611_1024_1/shared/concat/ReadVariableOp_9 (ReadVariableOp) /device:GPU:0\n",
      "  while/universal_transformer/parallel_0_6/universal_transformer/universal_transformer/symbol_modality_32611_1024_2/shared/concat/ReadVariableOp_9 (ReadVariableOp) /device:GPU:0\n",
      "  report_uninitialized_variables/VarIsInitializedOp_9 (VarIsInitializedOp) \n",
      "  report_uninitialized_variables_1/VarIsInitializedOp_9 (VarIsInitializedOp) \n",
      "  save/AssignVariableOp_48 (AssignVariableOp) /device:GPU:0\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-07-31 06:18:16.539242: W tensorflow/core/common_runtime/colocation_graph.cc:1016] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [\r\n",
      "  /job:localhost/replica:0/task:0/device:CPU:0\r\n",
      "  /job:localhost/replica:0/task:0/device:XLA_CPU:0].\r\n",
      "See below for details of this colocation group:\r\n",
      "Colocation Debug Info:\r\n",
      "Colocation group had the following types and supported devices: \r\n",
      "Root Member(assigned_device_name_index_=-1 requested_device_name_='/device:GPU:0' assigned_device_name_='' resource_device_name_='/device:GPU:0' supported_device_types_=[CPU, XLA_CPU] possible_devices_=[]\r\n",
      "Enter: CPU XLA_CPU \r\n",
      "ReadVariableOp: CPU XLA_CPU \r\n",
      "AssignVariableOp: CPU XLA_CPU \r\n",
      "RandomStandardNormal: CPU XLA_CPU \r\n",
      "Mul: CPU XLA_CPU \r\n",
      "Add: CPU XLA_CPU \r\n",
      "VarHandleOp: CPU XLA_CPU \r\n",
      "Const: CPU XLA_CPU \r\n",
      "VarIsInitializedOp: CPU XLA_CPU \r\n",
      "\r\n",
      "Colocation members, user-requested devices, and framework assigned devices, if any:\r\n",
      "  universal_transformer/symbol_modality_32611_1024/shared/weights_10/Initializer/random_normal/shape (Const) \r\n",
      "  universal_transformer/symbol_modality_32611_1024/shared/weights_10/Initializer/random_normal/mean (Const) \r\n",
      "  universal_transformer/symbol_modality_32611_1024/shared/weights_10/Initializer/random_normal/stddev (Const) \r\n",
      "  universal_transformer/symbol_modality_32611_1024/shared/weights_10/Initializer/random_normal/RandomStandardNormal (RandomStandardNormal) \r\n",
      "  universal_transformer/symbol_modality_32611_1024/shared/weights_10/Initializer/random_normal/mul (Mul) \r\n",
      "  universal_transformer/symbol_modality_32611_1024/shared/weights_10/Initializer/random_normal (Add) \r\n",
      "  universal_transformer/symbol_modality_32611_1024/shared/weights_10 (VarHandleOp) /device:GPU:0\r\n",
      "  universal_transformer/symbol_modality_32611_1024/shared/weights_10/IsInitialized/VarIsInitializedOp (VarIsInitializedOp) /device:GPU:0\r\n",
      "  universal_transformer/symbol_modality_32611_1024/shared/weights_10/Assign (AssignVariableOp) /device:GPU:0\r\n",
      "  universal_transformer/symbol_modality_32611_1024/shared/weights_10/Read/ReadVariableOp (ReadVariableOp) /device:GPU:0\r\n",
      "  while/universal_transformer/parallel_0_6/universal_transformer/universal_transformer/symbol_modality_32611_1024/shared/concat/ReadVariableOp_10/Enter (Enter) /device:GPU:0\r\n",
      "  while/universal_transformer/parallel_0_6/universal_transformer/universal_transformer/symbol_modality_32611_1024/shared/concat/ReadVariableOp_10 (ReadVariableOp) /device:GPU:0\r\n",
      "  while/universal_transformer/parallel_0_6/universal_transformer/universal_transformer/symbol_modality_32611_1024_1/shared/concat/ReadVariableOp_10 (ReadVariableOp) /device:GPU:0\r\n",
      "  while/universal_transformer/parallel_0_6/universal_transformer/universal_transformer/symbol_modality_32611_1024_2/shared/concat/ReadVariableOp_10 (ReadVariableOp) /device:GPU:0\r\n",
      "  report_uninitialized_variables/VarIsInitializedOp_10 (VarIsInitializedOp) \r\n",
      "  report_uninitialized_variables_1/VarIsInitializedOp_10 (VarIsInitializedOp) \r\n",
      "  save/AssignVariableOp_35 (AssignVariableOp) /device:GPU:0\r\n",
      "\r\n",
      "2019-07-31 06:18:16.539666: W tensorflow/core/common_runtime/colocation_graph.cc:1016] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [\r\n",
      "  /job:localhost/replica:0/task:0/device:CPU:0\r\n",
      "  /job:localhost/replica:0/task:0/device:XLA_CPU:0].\r\n",
      "See below for details of this colocation group:\r\n",
      "Colocation Debug Info:\r\n",
      "Colocation group had the following types and supported devices: \r\n",
      "Root Member(assigned_device_name_index_=-1 requested_device_name_='/device:GPU:0' assigned_device_name_='' resource_device_name_='/device:GPU:0' supported_device_types_=[CPU, XLA_CPU] possible_devices_=[]\r\n",
      "Enter: CPU XLA_CPU \r\n",
      "ReadVariableOp: CPU XLA_CPU \r\n",
      "AssignVariableOp: CPU XLA_CPU \r\n",
      "RandomStandardNormal: CPU XLA_CPU \r\n",
      "Mul: CPU XLA_CPU \r\n",
      "Add: CPU XLA_CPU \r\n",
      "VarHandleOp: CPU XLA_CPU \r\n",
      "Const: CPU XLA_CPU \r\n",
      "VarIsInitializedOp: CPU XLA_CPU \r\n",
      "\r\n",
      "Colocation members, user-requested devices, and framework assigned devices, if any:\r\n",
      "  universal_transformer/symbol_modality_32611_1024/shared/weights_11/Initializer/random_normal/shape (Const) \r\n",
      "  universal_transformer/symbol_modality_32611_1024/shared/weights_11/Initializer/random_normal/mean (Const) \r\n",
      "  universal_transformer/symbol_modality_32611_1024/shared/weights_11/Initializer/random_normal/stddev (Const) \r\n",
      "  universal_transformer/symbol_modality_32611_1024/shared/weights_11/Initializer/random_normal/RandomStandardNormal (RandomStandardNormal) \r\n",
      "  universal_transformer/symbol_modality_32611_1024/shared/weights_11/Initializer/random_normal/mul (Mul) \r\n",
      "  universal_transformer/symbol_modality_32611_1024/shared/weights_11/Initializer/random_normal (Add) \r\n",
      "  universal_transformer/symbol_modality_32611_1024/shared/weights_11 (VarHandleOp) /device:GPU:0\r\n",
      "  universal_transformer/symbol_modality_32611_1024/shared/weights_11/IsInitialized/VarIsInitializedOp (VarIsInitializedOp) /device:GPU:0\r\n",
      "  universal_transformer/symbol_modality_32611_1024/shared/weights_11/Assign (AssignVariableOp) /device:GPU:0\r\n",
      "  universal_transformer/symbol_modality_32611_1024/shared/weights_11/Read/ReadVariableOp (ReadVariableOp) /device:GPU:0\r\n",
      "  while/universal_transformer/parallel_0_6/universal_transformer/universal_transformer/symbol_modality_32611_1024/shared/concat/ReadVariableOp_11/Enter (Enter) /device:GPU:0\r\n",
      "  while/universal_transformer/parallel_0_6/universal_transformer/universal_transformer/symbol_modality_32611_1024/shared/concat/ReadVariableOp_11 (ReadVariableOp) /device:GPU:0\r\n",
      "  while/universal_transformer/parallel_0_6/universal_transformer/universal_transformer/symbol_modality_32611_1024_1/shared/concat/ReadVariableOp_11 (ReadVariableOp) /device:GPU:0\r\n",
      "  while/universal_transformer/parallel_0_6/universal_transformer/universal_transformer/symbol_modality_32611_1024_2/shared/concat/ReadVariableOp_11 (ReadVariableOp) /device:GPU:0\r\n",
      "  report_uninitialized_variables/VarIsInitializedOp_11 (VarIsInitializedOp) \r\n",
      "  report_uninitialized_variables_1/VarIsInitializedOp_11 (VarIsInitializedOp) \r\n",
      "  save/AssignVariableOp_36 (AssignVariableOp) /device:GPU:0\r\n",
      "\r\n",
      "2019-07-31 06:18:16.540118: W tensorflow/core/common_runtime/colocation_graph.cc:1016] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [\r\n",
      "  /job:localhost/replica:0/task:0/device:CPU:0\r\n",
      "  /job:localhost/replica:0/task:0/device:XLA_CPU:0].\r\n",
      "See below for details of this colocation group:\r\n",
      "Colocation Debug Info:\r\n",
      "Colocation group had the following types and supported devices: \r\n",
      "Root Member(assigned_device_name_index_=-1 requested_device_name_='/device:GPU:0' assigned_device_name_='' resource_device_name_='/device:GPU:0' supported_device_types_=[CPU, XLA_CPU] possible_devices_=[]\r\n",
      "Enter: CPU XLA_CPU \r\n",
      "ReadVariableOp: CPU XLA_CPU \r\n",
      "AssignVariableOp: CPU XLA_CPU \r\n",
      "RandomStandardNormal: CPU XLA_CPU \r\n",
      "Mul: CPU XLA_CPU \r\n",
      "Add: CPU XLA_CPU \r\n",
      "VarHandleOp: CPU XLA_CPU \r\n",
      "Const: CPU XLA_CPU \r\n",
      "VarIsInitializedOp: CPU XLA_CPU \r\n",
      "\r\n",
      "Colocation members, user-requested devices, and framework assigned devices, if any:\r\n",
      "  universal_transformer/symbol_modality_32611_1024/shared/weights_12/Initializer/random_normal/shape (Const) \r\n",
      "  universal_transformer/symbol_modality_32611_1024/shared/weights_12/Initializer/random_normal/mean (Const) \r\n",
      "  universal_transformer/symbol_modality_32611_1024/shared/weights_12/Initializer/random_normal/stddev (Const) \r\n",
      "  universal_transformer/symbol_modality_32611_1024/shared/weights_12/Initializer/random_normal/RandomStandardNormal (RandomStandardNormal) \r\n",
      "  universal_transformer/symbol_modality_32611_1024/shared/weights_12/Initializer/random_normal/mul (Mul) \r\n",
      "  universal_transformer/symbol_modality_32611_1024/shared/weights_12/Initializer/random_normal (Add) \r\n",
      "  universal_transformer/symbol_modality_32611_1024/shared/weights_12 (VarHandleOp) /device:GPU:0\r\n",
      "  universal_transformer/symbol_modality_32611_1024/shared/weights_12/IsInitialized/VarIsInitializedOp (VarIsInitializedOp) /device:GPU:0\r\n",
      "  universal_transformer/symbol_modality_32611_1024/shared/weights_12/Assign (AssignVariableOp) /device:GPU:0\r\n",
      "  universal_transformer/symbol_modality_32611_1024/shared/weights_12/Read/ReadVariableOp (ReadVariableOp) /device:GPU:0\r\n",
      "  while/universal_transformer/parallel_0_6/universal_transformer/universal_transformer/symbol_modality_32611_1024/shared/concat/ReadVariableOp_12/Enter (Enter) /device:GPU:0\r\n",
      "  while/universal_transformer/parallel_0_6/universal_transformer/universal_transformer/symbol_modality_32611_1024/shared/concat/ReadVariableOp_12 (ReadVariableOp) /device:GPU:0\r\n",
      "  while/universal_transformer/parallel_0_6/universal_transformer/universal_transformer/symbol_modality_32611_1024_1/shared/concat/ReadVariableOp_12 (ReadVariableOp) /device:GPU:0\r\n",
      "  while/universal_transformer/parallel_0_6/universal_transformer/universal_transformer/symbol_modality_32611_1024_2/shared/concat/ReadVariableOp_12 (ReadVariableOp) /device:GPU:0\r\n",
      "  report_uninitialized_variables/VarIsInitializedOp_12 (VarIsInitializedOp) \r\n",
      "  report_uninitialized_variables_1/VarIsInitializedOp_12 (VarIsInitializedOp) \r\n",
      "  save/AssignVariableOp_37 (AssignVariableOp) /device:GPU:0\r\n",
      "\r\n",
      "2019-07-31 06:18:16.540537: W tensorflow/core/common_runtime/colocation_graph.cc:1016] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [\r\n",
      "  /job:localhost/replica:0/task:0/device:CPU:0\r\n",
      "  /job:localhost/replica:0/task:0/device:XLA_CPU:0].\r\n",
      "See below for details of this colocation group:\r\n",
      "Colocation Debug Info:\r\n",
      "Colocation group had the following types and supported devices: \r\n",
      "Root Member(assigned_device_name_index_=-1 requested_device_name_='/device:GPU:0' assigned_device_name_='' resource_device_name_='/device:GPU:0' supported_device_types_=[CPU, XLA_CPU] possible_devices_=[]\r\n",
      "Enter: CPU XLA_CPU \r\n",
      "ReadVariableOp: CPU XLA_CPU \r\n",
      "AssignVariableOp: CPU XLA_CPU \r\n",
      "RandomStandardNormal: CPU XLA_CPU \r\n",
      "Mul: CPU XLA_CPU \r\n",
      "Add: CPU XLA_CPU \r\n",
      "VarHandleOp: CPU XLA_CPU \r\n",
      "Const: CPU XLA_CPU \r\n",
      "VarIsInitializedOp: CPU XLA_CPU \r\n",
      "\r\n",
      "Colocation members, user-requested devices, and framework assigned devices, if any:\r\n",
      "  universal_transformer/symbol_modality_32611_1024/shared/weights_13/Initializer/random_normal/shape (Const) \r\n",
      "  universal_transformer/symbol_modality_32611_1024/shared/weights_13/Initializer/random_normal/mean (Const) \r\n",
      "  universal_transformer/symbol_modality_32611_1024/shared/weights_13/Initializer/random_normal/stddev (Const) \r\n",
      "  universal_transformer/symbol_modality_32611_1024/shared/weights_13/Initializer/random_normal/RandomStandardNormal (RandomStandardNormal) \r\n",
      "  universal_transformer/symbol_modality_32611_1024/shared/weights_13/Initializer/random_normal/mul (Mul) \r\n",
      "  universal_transformer/symbol_modality_32611_1024/shared/weights_13/Initializer/random_normal (Add) \r\n",
      "  universal_transformer/symbol_modality_32611_1024/shared/weights_13 (VarHandleOp) /device:GPU:0\r\n",
      "  universal_transformer/symbol_modality_32611_1024/shared/weights_13/IsInitialized/VarIsInitializedOp (VarIsInitializedOp) /device:GPU:0\r\n",
      "  universal_transformer/symbol_modality_32611_1024/shared/weights_13/Assign (AssignVariableOp) /device:GPU:0\r\n",
      "  universal_transformer/symbol_modality_32611_1024/shared/weights_13/Read/ReadVariableOp (ReadVariableOp) /device:GPU:0\r\n",
      "  while/universal_transformer/parallel_0_6/universal_transformer/universal_transformer/symbol_modality_32611_1024/shared/concat/ReadVariableOp_13/Enter (Enter) /device:GPU:0\r\n",
      "  while/universal_transformer/parallel_0_6/universal_transformer/universal_transformer/symbol_modality_32611_1024/shared/concat/ReadVariableOp_13 (ReadVariableOp) /device:GPU:0\r\n",
      "  while/universal_transformer/parallel_0_6/universal_transformer/universal_transformer/symbol_modality_32611_1024_1/shared/concat/ReadVariableOp_13 (ReadVariableOp) /device:GPU:0\r\n",
      "  while/universal_transformer/parallel_0_6/universal_transformer/universal_transformer/symbol_modality_32611_1024_2/shared/concat/ReadVariableOp_13 (ReadVariableOp) /device:GPU:0\r\n",
      "  report_uninitialized_variables/VarIsInitializedOp_13 (VarIsInitializedOp) \r\n",
      "  report_uninitialized_variables_1/VarIsInitializedOp_13 (VarIsInitializedOp) \r\n",
      "  save/AssignVariableOp_38 (AssignVariableOp) /device:GPU:0\r\n",
      "\r\n",
      "2019-07-31 06:18:16.540965: W tensorflow/core/common_runtime/colocation_graph.cc:1016] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [\r\n",
      "  /job:localhost/replica:0/task:0/device:CPU:0\r\n",
      "  /job:localhost/replica:0/task:0/device:XLA_CPU:0].\r\n",
      "See below for details of this colocation group:\r\n",
      "Colocation Debug Info:\r\n",
      "Colocation group had the following types and supported devices: \r\n",
      "Root Member(assigned_device_name_index_=-1 requested_device_name_='/device:GPU:0' assigned_device_name_='' resource_device_name_='/device:GPU:0' supported_device_types_=[CPU, XLA_CPU] possible_devices_=[]\r\n",
      "Enter: CPU XLA_CPU \r\n",
      "ReadVariableOp: CPU XLA_CPU \r\n",
      "AssignVariableOp: CPU XLA_CPU \r\n",
      "RandomStandardNormal: CPU XLA_CPU \r\n",
      "Mul: CPU XLA_CPU \r\n",
      "Add: CPU XLA_CPU \r\n",
      "VarHandleOp: CPU XLA_CPU \r\n",
      "Const: CPU XLA_CPU \r\n",
      "VarIsInitializedOp: CPU XLA_CPU \r\n",
      "\r\n",
      "Colocation members, user-requested devices, and framework assigned devices, if any:\r\n",
      "  universal_transformer/symbol_modality_32611_1024/shared/weights_14/Initializer/random_normal/shape (Const) \r\n",
      "  universal_transformer/symbol_modality_32611_1024/shared/weights_14/Initializer/random_normal/mean (Const) \r\n",
      "  universal_transformer/symbol_modality_32611_1024/shared/weights_14/Initializer/random_normal/stddev (Const) \r\n",
      "  universal_transformer/symbol_modality_32611_1024/shared/weights_14/Initializer/random_normal/RandomStandardNormal (RandomStandardNormal) \r\n",
      "  universal_transformer/symbol_modality_32611_1024/shared/weights_14/Initializer/random_normal/mul (Mul) \r\n",
      "  universal_transformer/symbol_modality_32611_1024/shared/weights_14/Initializer/random_normal (Add) \r\n",
      "  universal_transformer/symbol_modality_32611_1024/shared/weights_14 (VarHandleOp) /device:GPU:0\r\n",
      "  universal_transformer/symbol_modality_32611_1024/shared/weights_14/IsInitialized/VarIsInitializedOp (VarIsInitializedOp) /device:GPU:0\r\n",
      "  universal_transformer/symbol_modality_32611_1024/shared/weights_14/Assign (AssignVariableOp) /device:GPU:0\r\n",
      "  universal_transformer/symbol_modality_32611_1024/shared/weights_14/Read/ReadVariableOp (ReadVariableOp) /device:GPU:0\r\n",
      "  while/universal_transformer/parallel_0_6/universal_transformer/universal_transformer/symbol_modality_32611_1024/shared/concat/ReadVariableOp_14/Enter (Enter) /device:GPU:0\r\n",
      "  while/universal_transformer/parallel_0_6/universal_transformer/universal_transformer/symbol_modality_32611_1024/shared/concat/ReadVariableOp_14 (ReadVariableOp) /device:GPU:0\r\n",
      "  while/universal_transformer/parallel_0_6/universal_transformer/universal_transformer/symbol_modality_32611_1024_1/shared/concat/ReadVariableOp_14 (ReadVariableOp) /device:GPU:0\r\n",
      "  while/universal_transformer/parallel_0_6/universal_transformer/universal_transformer/symbol_modality_32611_1024_2/shared/concat/ReadVariableOp_14 (ReadVariableOp) /device:GPU:0\r\n",
      "  report_uninitialized_variables/VarIsInitializedOp_14 (VarIsInitializedOp) \r\n",
      "  report_uninitialized_variables_1/VarIsInitializedOp_14 (VarIsInitializedOp) \r\n",
      "  save/AssignVariableOp_39 (AssignVariableOp) /device:GPU:0\r\n",
      "\r\n",
      "2019-07-31 06:18:16.541385: W tensorflow/core/common_runtime/colocation_graph.cc:1016] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [\r\n",
      "  /job:localhost/replica:0/task:0/device:CPU:0\r\n",
      "  /job:localhost/replica:0/task:0/device:XLA_CPU:0].\r\n",
      "See below for details of this colocation group:\r\n",
      "Colocation Debug Info:\r\n",
      "Colocation group had the following types and supported devices: \r\n",
      "Root Member(assigned_device_name_index_=-1 requested_device_name_='/device:GPU:0' assigned_device_name_='' resource_device_name_='/device:GPU:0' supported_device_types_=[CPU, XLA_CPU] possible_devices_=[]\r\n",
      "Enter: CPU XLA_CPU \r\n",
      "ReadVariableOp: CPU XLA_CPU \r\n",
      "AssignVariableOp: CPU XLA_CPU \r\n",
      "RandomStandardNormal: CPU XLA_CPU \r\n",
      "Mul: CPU XLA_CPU \r\n",
      "Add: CPU XLA_CPU \r\n",
      "VarHandleOp: CPU XLA_CPU \r\n",
      "Const: CPU XLA_CPU \r\n",
      "VarIsInitializedOp: CPU XLA_CPU \r\n",
      "\r\n",
      "Colocation members, user-requested devices, and framework assigned devices, if any:\r\n",
      "  universal_transformer/symbol_modality_32611_1024/shared/weights_15/Initializer/random_normal/shape (Const) \r\n",
      "  universal_transformer/symbol_modality_32611_1024/shared/weights_15/Initializer/random_normal/mean (Const) \r\n",
      "  universal_transformer/symbol_modality_32611_1024/shared/weights_15/Initializer/random_normal/stddev (Const) \r\n",
      "  universal_transformer/symbol_modality_32611_1024/shared/weights_15/Initializer/random_normal/RandomStandardNormal (RandomStandardNormal) \r\n",
      "  universal_transformer/symbol_modality_32611_1024/shared/weights_15/Initializer/random_normal/mul (Mul) \r\n",
      "  universal_transformer/symbol_modality_32611_1024/shared/weights_15/Initializer/random_normal (Add) \r\n",
      "  universal_transformer/symbol_modality_32611_1024/shared/weights_15 (VarHandleOp) /device:GPU:0\r\n",
      "  universal_transformer/symbol_modality_32611_1024/shared/weights_15/IsInitialized/VarIsInitializedOp (VarIsInitializedOp) /device:GPU:0\r\n",
      "  universal_transformer/symbol_modality_32611_1024/shared/weights_15/Assign (AssignVariableOp) /device:GPU:0\r\n",
      "  universal_transformer/symbol_modality_32611_1024/shared/weights_15/Read/ReadVariableOp (ReadVariableOp) /device:GPU:0\r\n",
      "  while/universal_transformer/parallel_0_6/universal_transformer/universal_transformer/symbol_modality_32611_1024/shared/concat/ReadVariableOp_15/Enter (Enter) /device:GPU:0\r\n",
      "  while/universal_transformer/parallel_0_6/universal_transformer/universal_transformer/symbol_modality_32611_1024/shared/concat/ReadVariableOp_15 (ReadVariableOp) /device:GPU:0\r\n",
      "  while/universal_transformer/parallel_0_6/universal_transformer/universal_transformer/symbol_modality_32611_1024_1/shared/concat/ReadVariableOp_15 (ReadVariableOp) /device:GPU:0\r\n",
      "  while/universal_transformer/parallel_0_6/universal_transformer/universal_transformer/symbol_modality_32611_1024_2/shared/concat/ReadVariableOp_15 (ReadVariableOp) /device:GPU:0\r\n",
      "  report_uninitialized_variables/VarIsInitializedOp_15 (VarIsInitializedOp) \r\n",
      "  report_uninitialized_variables_1/VarIsInitializedOp_15 (VarIsInitializedOp) \r\n",
      "  save/AssignVariableOp_40 (AssignVariableOp) /device:GPU:0\r\n",
      "\r\n",
      "2019-07-31 06:18:16.541912: W tensorflow/core/common_runtime/colocation_graph.cc:1016] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [\r\n",
      "  /job:localhost/replica:0/task:0/device:CPU:0\r\n",
      "  /job:localhost/replica:0/task:0/device:XLA_CPU:0].\r\n",
      "See below for details of this colocation group:\r\n",
      "Colocation Debug Info:\r\n",
      "Colocation group had the following types and supported devices: \r\n",
      "Root Member(assigned_device_name_index_=-1 requested_device_name_='/device:GPU:0' assigned_device_name_='' resource_device_name_='/device:GPU:0' supported_device_types_=[CPU, XLA_CPU] possible_devices_=[]\r\n",
      "Enter: CPU XLA_CPU \r\n",
      "AssignVariableOp: CPU XLA_CPU \r\n",
      "RandomUniform: CPU XLA_CPU \r\n",
      "VarIsInitializedOp: CPU XLA_CPU \r\n",
      "Const: CPU XLA_CPU \r\n",
      "Mul: CPU XLA_CPU \r\n",
      "ReadVariableOp: CPU XLA_CPU \r\n",
      "Sub: CPU XLA_CPU \r\n",
      "VarHandleOp: CPU XLA_CPU \r\n",
      "Add: CPU XLA_CPU \r\n",
      "\r\n",
      "Colocation members, user-requested devices, and framework assigned devices, if any:\r\n",
      "  universal_transformer/body/target_space_embedding/kernel/Initializer/random_uniform/shape (Const) \r\n",
      "  universal_transformer/body/target_space_embedding/kernel/Initializer/random_uniform/min (Const) \r\n",
      "  universal_transformer/body/target_space_embedding/kernel/Initializer/random_uniform/max (Const) \r\n",
      "  universal_transformer/body/target_space_embedding/kernel/Initializer/random_uniform/RandomUniform (RandomUniform) \r\n",
      "  universal_transformer/body/target_space_embedding/kernel/Initializer/random_uniform/sub (Sub) \r\n",
      "  universal_transformer/body/target_space_embedding/kernel/Initializer/random_uniform/mul (Mul) \r\n",
      "  universal_transformer/body/target_space_embedding/kernel/Initializer/random_uniform (Add) \r\n",
      "  universal_transformer/body/target_space_embedding/kernel (VarHandleOp) /device:GPU:0\r\n",
      "  universal_transformer/body/target_space_embedding/kernel/IsInitialized/VarIsInitializedOp (VarIsInitializedOp) /device:GPU:0\r\n",
      "  universal_transformer/body/target_space_embedding/kernel/Assign (AssignVariableOp) /device:GPU:0\r\n",
      "  universal_transformer/body/target_space_embedding/kernel/Read/ReadVariableOp (ReadVariableOp) /device:GPU:0\r\n",
      "  while/universal_transformer/parallel_0_6/universal_transformer/universal_transformer/body/target_space_embedding/ReadVariableOp/Enter (Enter) /device:GPU:0\r\n",
      "  while/universal_transformer/parallel_0_6/universal_transformer/universal_transformer/body/target_space_embedding/ReadVariableOp (ReadVariableOp) /device:GPU:0\r\n",
      "  report_uninitialized_variables/VarIsInitializedOp_16 (VarIsInitializedOp) \r\n",
      "  report_uninitialized_variables_1/VarIsInitializedOp_16 (VarIsInitializedOp) \r\n",
      "  save/AssignVariableOp_32 (AssignVariableOp) /device:GPU:0\r\n",
      "\r\n",
      "2019-07-31 06:18:16.544385: W tensorflow/core/common_runtime/colocation_graph.cc:1016] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [\r\n",
      "  /job:localhost/replica:0/task:0/device:CPU:0\r\n",
      "  /job:localhost/replica:0/task:0/device:XLA_CPU:0].\r\n",
      "See below for details of this colocation group:\r\n",
      "Colocation Debug Info:\r\n",
      "Colocation group had the following types and supported devices: \r\n",
      "Root Member(assigned_device_name_index_=-1 requested_device_name_='/device:GPU:0' assigned_device_name_='' resource_device_name_='/device:GPU:0' supported_device_types_=[CPU, XLA_CPU] possible_devices_=[]\r\n",
      "ReadVariableOp: CPU XLA_CPU \r\n",
      "AssignVariableOp: CPU XLA_CPU \r\n",
      "RandomStandardNormal: CPU XLA_CPU \r\n",
      "Mul: CPU XLA_CPU \r\n",
      "Add: CPU XLA_CPU \r\n",
      "VarHandleOp: CPU XLA_CPU \r\n",
      "Const: CPU XLA_CPU \r\n",
      "VarIsInitializedOp: CPU XLA_CPU \r\n",
      "\r\n",
      "Colocation members, user-requested devices, and framework assigned devices, if any:\r\n",
      "  universal_transformer/body/encoder/universal_transformer_basic/layer_embedding/Initializer/random_normal/shape (Const) \r\n",
      "  universal_transformer/body/encoder/universal_transformer_basic/layer_embedding/Initializer/random_normal/mean (Const) \r\n",
      "  universal_transformer/body/encoder/universal_transformer_basic/layer_embedding/Initializer/random_normal/stddev (Const) \r\n",
      "  universal_transformer/body/encoder/universal_transformer_basic/layer_embedding/Initializer/random_normal/RandomStandardNormal (RandomStandardNormal) \r\n",
      "  universal_transformer/body/encoder/universal_transformer_basic/layer_embedding/Initializer/random_normal/mul (Mul) \r\n",
      "  universal_transformer/body/encoder/universal_transformer_basic/layer_embedding/Initializer/random_normal (Add) \r\n",
      "  universal_transformer/body/encoder/universal_transformer_basic/layer_embedding (VarHandleOp) /device:GPU:0\r\n",
      "  universal_transformer/body/encoder/universal_transformer_basic/layer_embedding/IsInitialized/VarIsInitializedOp (VarIsInitializedOp) /device:GPU:0\r\n",
      "  universal_transformer/body/encoder/universal_transformer_basic/layer_embedding/Assign (AssignVariableOp) /device:GPU:0\r\n",
      "  universal_transformer/body/encoder/universal_transformer_basic/layer_embedding/Read/ReadVariableOp (ReadVariableOp) /device:GPU:0\r\n",
      "  report_uninitialized_variables/VarIsInitializedOp_17 (VarIsInitializedOp) \r\n",
      "  report_uninitialized_variables_1/VarIsInitializedOp_17 (VarIsInitializedOp) \r\n",
      "  save/AssignVariableOp_19 (AssignVariableOp) /device:GPU:0\r\n",
      "\r\n",
      "2019-07-31 06:18:16.544826: W tensorflow/core/common_runtime/colocation_graph.cc:1016] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [\r\n",
      "  /job:localhost/replica:0/task:0/device:CPU:0\r\n",
      "  /job:localhost/replica:0/task:0/device:XLA_CPU:0].\r\n",
      "See below for details of this colocation group:\r\n",
      "Colocation Debug Info:\r\n",
      "Colocation group had the following types and supported devices: \r\n",
      "Root Member(assigned_device_name_index_=-1 requested_device_name_='/device:GPU:0' assigned_device_name_='' resource_device_name_='/device:GPU:0' supported_device_types_=[CPU, XLA_CPU] possible_devices_=[]\r\n",
      "AssignVariableOp: CPU XLA_CPU \r\n",
      "RandomUniform: CPU XLA_CPU \r\n",
      "VarIsInitializedOp: CPU XLA_CPU \r\n",
      "Const: CPU XLA_CPU \r\n",
      "Mul: CPU XLA_CPU \r\n",
      "ReadVariableOp: CPU XLA_CPU \r\n",
      "Sub: CPU XLA_CPU \r\n",
      "VarHandleOp: CPU XLA_CPU \r\n",
      "Add: CPU XLA_CPU \r\n",
      "\r\n",
      "Colocation members, user-requested devices, and framework assigned devices, if any:\r\n",
      "  universal_transformer/body/encoder/universal_transformer_basic/rec_layer_0/self_attention/multihead_attention/q/kernel/Initializer/random_uniform/shape (Const) \r\n",
      "  universal_transformer/body/encoder/universal_transformer_basic/rec_layer_0/self_attention/multihead_attention/q/kernel/Initializer/random_uniform/min (Const) \r\n",
      "  universal_transformer/body/encoder/universal_transformer_basic/rec_layer_0/self_attention/multihead_attention/q/kernel/Initializer/random_uniform/max (Const) \r\n",
      "  universal_transformer/body/encoder/universal_transformer_basic/rec_layer_0/self_attention/multihead_attention/q/kernel/Initializer/random_uniform/RandomUniform (RandomUniform) \r\n",
      "  universal_transformer/body/encoder/universal_transformer_basic/rec_layer_0/self_attention/multihead_attention/q/kernel/Initializer/random_uniform/sub (Sub) \r\n",
      "  universal_transformer/body/encoder/universal_transformer_basic/rec_layer_0/self_attention/multihead_attention/q/kernel/Initializer/random_uniform/mul (Mul) \r\n",
      "  universal_transformer/body/encoder/universal_transformer_basic/rec_layer_0/self_attention/multihead_attention/q/kernel/Initializer/random_uniform (Add) \r\n",
      "  universal_transformer/body/encoder/universal_transformer_basic/rec_layer_0/self_attention/multihead_attention/q/kernel (VarHandleOp) /device:GPU:0\r\n",
      "  universal_transformer/body/encoder/universal_transformer_basic/rec_layer_0/self_attention/multihead_attention/q/kernel/IsInitialized/VarIsInitializedOp (VarIsInitializedOp) /device:GPU:0\r\n",
      "  universal_transformer/body/encoder/universal_transformer_basic/rec_layer_0/self_attention/multihead_attention/q/kernel/Assign (AssignVariableOp) /device:GPU:0\r\n",
      "  universal_transformer/body/encoder/universal_transformer_basic/rec_layer_0/self_attention/multihead_attention/q/kernel/Read/ReadVariableOp (ReadVariableOp) /device:GPU:0\r\n",
      "  report_uninitialized_variables/VarIsInitializedOp_18 (VarIsInitializedOp) \r\n",
      "  report_uninitialized_variables_1/VarIsInitializedOp_18 (VarIsInitializedOp) \r\n",
      "  save/AssignVariableOp_30 (AssignVariableOp) /device:GPU:0\r\n",
      "\r\n",
      "2019-07-31 06:18:16.545270: W tensorflow/core/common_runtime/colocation_graph.cc:1016] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [\r\n",
      "  /job:localhost/replica:0/task:0/device:CPU:0\r\n",
      "  /job:localhost/replica:0/task:0/device:XLA_CPU:0].\r\n",
      "See below for details of this colocation group:\r\n",
      "Colocation Debug Info:\r\n",
      "Colocation group had the following types and supported devices: \r\n",
      "Root Member(assigned_device_name_index_=-1 requested_device_name_='/device:GPU:0' assigned_device_name_='' resource_device_name_='/device:GPU:0' supported_device_types_=[CPU, XLA_CPU] possible_devices_=[]\r\n",
      "AssignVariableOp: CPU XLA_CPU \r\n",
      "RandomUniform: CPU XLA_CPU \r\n",
      "VarIsInitializedOp: CPU XLA_CPU \r\n",
      "Const: CPU XLA_CPU \r\n",
      "Mul: CPU XLA_CPU \r\n",
      "ReadVariableOp: CPU XLA_CPU \r\n",
      "Sub: CPU XLA_CPU \r\n",
      "VarHandleOp: CPU XLA_CPU \r\n",
      "Add: CPU XLA_CPU \r\n",
      "\r\n",
      "Colocation members, user-requested devices, and framework assigned devices, if any:\r\n",
      "  universal_transformer/body/encoder/universal_transformer_basic/rec_layer_0/self_attention/multihead_attention/k/kernel/Initializer/random_uniform/shape (Const) \r\n",
      "  universal_transformer/body/encoder/universal_transformer_basic/rec_layer_0/self_attention/multihead_attention/k/kernel/Initializer/random_uniform/min (Const) \r\n",
      "  universal_transformer/body/encoder/universal_transformer_basic/rec_layer_0/self_attention/multihead_attention/k/kernel/Initializer/random_uniform/max (Const) \r\n",
      "  universal_transformer/body/encoder/universal_transformer_basic/rec_layer_0/self_attention/multihead_attention/k/kernel/Initializer/random_uniform/RandomUniform (RandomUniform) \r\n",
      "  universal_transformer/body/encoder/universal_transformer_basic/rec_layer_0/self_attention/multihead_attention/k/kernel/Initializer/random_uniform/sub (Sub) \r\n",
      "  universal_transformer/body/encoder/universal_transformer_basic/rec_layer_0/self_attention/multihead_attention/k/kernel/Initializer/random_uniform/mul (Mul) \r\n",
      "  universal_transformer/body/encoder/universal_transformer_basic/rec_layer_0/self_attention/multihead_attention/k/kernel/Initializer/random_uniform (Add) \r\n",
      "  universal_transformer/body/encoder/universal_transformer_basic/rec_layer_0/self_attention/multihead_attention/k/kernel (VarHandleOp) /device:GPU:0\r\n",
      "  universal_transformer/body/encoder/universal_transformer_basic/rec_layer_0/self_attention/multihead_attention/k/kernel/IsInitialized/VarIsInitializedOp (VarIsInitializedOp) /device:GPU:0\r\n",
      "  universal_transformer/body/encoder/universal_transformer_basic/rec_layer_0/self_attention/multihead_attention/k/kernel/Assign (AssignVariableOp) /device:GPU:0\r\n",
      "  universal_transformer/body/encoder/universal_transformer_basic/rec_layer_0/self_attention/multihead_attention/k/kernel/Read/ReadVariableOp (ReadVariableOp) /device:GPU:0\r\n",
      "  report_uninitialized_variables/VarIsInitializedOp_19 (VarIsInitializedOp) \r\n",
      "  report_uninitialized_variables_1/VarIsInitializedOp_19 (VarIsInitializedOp) \r\n",
      "  save/AssignVariableOp_28 (AssignVariableOp) /device:GPU:0\r\n",
      "\r\n",
      "2019-07-31 06:18:16.545723: W tensorflow/core/common_runtime/colocation_graph.cc:1016] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [\r\n",
      "  /job:localhost/replica:0/task:0/device:CPU:0\r\n",
      "  /job:localhost/replica:0/task:0/device:XLA_CPU:0].\r\n",
      "See below for details of this colocation group:\r\n",
      "Colocation Debug Info:\r\n",
      "Colocation group had the following types and supported devices: \r\n",
      "Root Member(assigned_device_name_index_=-1 requested_device_name_='/device:GPU:0' assigned_device_name_='' resource_device_name_='/device:GPU:0' supported_device_types_=[CPU, XLA_CPU] possible_devices_=[]\r\n",
      "AssignVariableOp: CPU XLA_CPU \r\n",
      "RandomUniform: CPU XLA_CPU \r\n",
      "VarIsInitializedOp: CPU XLA_CPU \r\n",
      "Const: CPU XLA_CPU \r\n",
      "Mul: CPU XLA_CPU \r\n",
      "ReadVariableOp: CPU XLA_CPU \r\n",
      "Sub: CPU XLA_CPU \r\n",
      "VarHandleOp: CPU XLA_CPU \r\n",
      "Add: CPU XLA_CPU \r\n",
      "\r\n",
      "Colocation members, user-requested devices, and framework assigned devices, if any:\r\n",
      "  universal_transformer/body/encoder/universal_transformer_basic/rec_layer_0/self_attention/multihead_attention/v/kernel/Initializer/random_uniform/shape (Const) \r\n",
      "  universal_transformer/body/encoder/universal_transformer_basic/rec_layer_0/self_attention/multihead_attention/v/kernel/Initializer/random_uniform/min (Const) \r\n",
      "  universal_transformer/body/encoder/universal_transformer_basic/rec_layer_0/self_attention/multihead_attention/v/kernel/Initializer/random_uniform/max (Const) \r\n",
      "  universal_transformer/body/encoder/universal_transformer_basic/rec_layer_0/self_attention/multihead_attention/v/kernel/Initializer/random_uniform/RandomUniform (RandomUniform) \r\n",
      "  universal_transformer/body/encoder/universal_transformer_basic/rec_layer_0/self_attention/multihead_attention/v/kernel/Initializer/random_uniform/sub (Sub) \r\n",
      "  universal_transformer/body/encoder/universal_transformer_basic/rec_layer_0/self_attention/multihead_attention/v/kernel/Initializer/random_uniform/mul (Mul) \r\n",
      "  universal_transformer/body/encoder/universal_transformer_basic/rec_layer_0/self_attention/multihead_attention/v/kernel/Initializer/random_uniform (Add) \r\n",
      "  universal_transformer/body/encoder/universal_transformer_basic/rec_layer_0/self_attention/multihead_attention/v/kernel (VarHandleOp) /device:GPU:0\r\n",
      "  universal_transformer/body/encoder/universal_transformer_basic/rec_layer_0/self_attention/multihead_attention/v/kernel/IsInitialized/VarIsInitializedOp (VarIsInitializedOp) /device:GPU:0\r\n",
      "  universal_transformer/body/encoder/universal_transformer_basic/rec_layer_0/self_attention/multihead_attention/v/kernel/Assign (AssignVariableOp) /device:GPU:0\r\n",
      "  universal_transformer/body/encoder/universal_transformer_basic/rec_layer_0/self_attention/multihead_attention/v/kernel/Read/ReadVariableOp (ReadVariableOp) /device:GPU:0\r\n",
      "  report_uninitialized_variables/VarIsInitializedOp_20 (VarIsInitializedOp) \r\n",
      "  report_uninitialized_variables_1/VarIsInitializedOp_20 (VarIsInitializedOp) \r\n",
      "  save/AssignVariableOp_31 (AssignVariableOp) /device:GPU:0\r\n",
      "\r\n",
      "2019-07-31 06:18:16.546253: W tensorflow/core/common_runtime/colocation_graph.cc:1016] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [\r\n",
      "  /job:localhost/replica:0/task:0/device:CPU:0\r\n",
      "  /job:localhost/replica:0/task:0/device:XLA_CPU:0].\r\n",
      "See below for details of this colocation group:\r\n",
      "Colocation Debug Info:\r\n",
      "Colocation group had the following types and supported devices: \r\n",
      "Root Member(assigned_device_name_index_=-1 requested_device_name_='/device:GPU:0' assigned_device_name_='' resource_device_name_='/device:GPU:0' supported_device_types_=[CPU, XLA_CPU] possible_devices_=[]\r\n",
      "AssignVariableOp: CPU XLA_CPU \r\n",
      "RandomUniform: CPU XLA_CPU \r\n",
      "VarIsInitializedOp: CPU XLA_CPU \r\n",
      "Const: CPU XLA_CPU \r\n",
      "Mul: CPU XLA_CPU \r\n",
      "ReadVariableOp: CPU XLA_CPU \r\n",
      "Sub: CPU XLA_CPU \r\n",
      "VarHandleOp: CPU XLA_CPU \r\n",
      "Add: CPU XLA_CPU \r\n",
      "\r\n",
      "Colocation members, user-requested devices, and framework assigned devices, if any:\r\n",
      "  universal_transformer/body/encoder/universal_transformer_basic/rec_layer_0/self_attention/multihead_attention/output_transform/kernel/Initializer/random_uniform/shape (Const) \r\n",
      "  universal_transformer/body/encoder/universal_transformer_basic/rec_layer_0/self_attention/multihead_attention/output_transform/kernel/Initializer/random_uniform/min (Const) \r\n",
      "  universal_transformer/body/encoder/universal_transformer_basic/rec_layer_0/self_attention/multihead_attention/output_transform/kernel/Initializer/random_uniform/max (Const) \r\n",
      "  universal_transformer/body/encoder/universal_transformer_basic/rec_layer_0/self_attention/multihead_attention/output_transform/kernel/Initializer/random_uniform/RandomUniform (RandomUniform) \r\n",
      "  universal_transformer/body/encoder/universal_transformer_basic/rec_layer_0/self_attention/multihead_attention/output_transform/kernel/Initializer/random_uniform/sub (Sub) \r\n",
      "  universal_transformer/body/encoder/universal_transformer_basic/rec_layer_0/self_attention/multihead_attention/output_transform/kernel/Initializer/random_uniform/mul (Mul) \r\n",
      "  universal_transformer/body/encoder/universal_transformer_basic/rec_layer_0/self_attention/multihead_attention/output_transform/kernel/Initializer/random_uniform (Add) \r\n",
      "  universal_transformer/body/encoder/universal_transformer_basic/rec_layer_0/self_attention/multihead_attention/output_transform/kernel (VarHandleOp) /device:GPU:0\r\n",
      "  universal_transformer/body/encoder/universal_transformer_basic/rec_layer_0/self_attention/multihead_attention/output_transform/kernel/IsInitialized/VarIsInitializedOp (VarIsInitializedOp) /device:GPU:0\r\n",
      "  universal_transformer/body/encoder/universal_transformer_basic/rec_layer_0/self_attention/multihead_attention/output_transform/kernel/Assign (AssignVariableOp) /device:GPU:0\r\n",
      "  universal_transformer/body/encoder/universal_transformer_basic/rec_layer_0/self_attention/multihead_attention/output_transform/kernel/Read/ReadVariableOp (ReadVariableOp) /device:GPU:0\r\n",
      "  report_uninitialized_variables/VarIsInitializedOp_21 (VarIsInitializedOp) \r\n",
      "  report_uninitialized_variables_1/VarIsInitializedOp_21 (VarIsInitializedOp) \r\n",
      "  save/AssignVariableOp_29 (AssignVariableOp) /device:GPU:0\r\n",
      "\r\n",
      "2019-07-31 06:18:16.546713: W tensorflow/core/common_runtime/colocation_graph.cc:1016] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [\r\n",
      "  /job:localhost/replica:0/task:0/device:CPU:0\r\n",
      "  /job:localhost/replica:0/task:0/device:XLA_CPU:0].\r\n",
      "See below for details of this colocation group:\r\n",
      "Colocation Debug Info:\r\n",
      "Colocation group had the following types and supported devices: \r\n",
      "Root Member(assigned_device_name_index_=-1 requested_device_name_='/device:GPU:0' assigned_device_name_='' resource_device_name_='/device:GPU:0' supported_device_types_=[CPU, XLA_CPU] possible_devices_=[]\r\n",
      "ReadVariableOp: CPU XLA_CPU \r\n",
      "AssignVariableOp: CPU XLA_CPU \r\n",
      "VarIsInitializedOp: CPU XLA_CPU \r\n",
      "VarHandleOp: CPU XLA_CPU \r\n",
      "Const: CPU XLA_CPU \r\n",
      "Fill: CPU XLA_CPU \r\n",
      "\r\n",
      "Colocation members, user-requested devices, and framework assigned devices, if any:\r\n",
      "  universal_transformer/body/encoder/universal_transformer_basic/rec_layer_0/self_attention/layer_postprocess/layer_norm/layer_norm_scale/Initializer/ones/shape_as_tensor (Const) \r\n",
      "  universal_transformer/body/encoder/universal_transformer_basic/rec_layer_0/self_attention/layer_postprocess/layer_norm/layer_norm_scale/Initializer/ones/Const (Const) \r\n",
      "  universal_transformer/body/encoder/universal_transformer_basic/rec_layer_0/self_attention/layer_postprocess/layer_norm/layer_norm_scale/Initializer/ones (Fill) \r\n",
      "  universal_transformer/body/encoder/universal_transformer_basic/rec_layer_0/self_attention/layer_postprocess/layer_norm/layer_norm_scale (VarHandleOp) /device:GPU:0\r\n",
      "  universal_transformer/body/encoder/universal_transformer_basic/rec_layer_0/self_attention/layer_postprocess/layer_norm/layer_norm_scale/IsInitialized/VarIsInitializedOp (VarIsInitializedOp) /device:GPU:0\r\n",
      "  universal_transformer/body/encoder/universal_transformer_basic/rec_layer_0/self_attention/layer_postprocess/layer_norm/layer_norm_scale/Assign (AssignVariableOp) /device:GPU:0\r\n",
      "  universal_transformer/body/encoder/universal_transformer_basic/rec_layer_0/self_attention/layer_postprocess/layer_norm/layer_norm_scale/Read/ReadVariableOp (ReadVariableOp) /device:GPU:0\r\n",
      "  report_uninitialized_variables/VarIsInitializedOp_22 (VarIsInitializedOp) \r\n",
      "  report_uninitialized_variables_1/VarIsInitializedOp_22 (VarIsInitializedOp) \r\n",
      "  save/AssignVariableOp_27 (AssignVariableOp) /device:GPU:0\r\n",
      "\r\n",
      "2019-07-31 06:18:16.547078: W tensorflow/core/common_runtime/colocation_graph.cc:1016] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [\r\n",
      "  /job:localhost/replica:0/task:0/device:CPU:0\r\n",
      "  /job:localhost/replica:0/task:0/device:XLA_CPU:0].\r\n",
      "See below for details of this colocation group:\r\n",
      "Colocation Debug Info:\r\n",
      "Colocation group had the following types and supported devices: \r\n",
      "Root Member(assigned_device_name_index_=-1 requested_device_name_='/device:GPU:0' assigned_device_name_='' resource_device_name_='/device:GPU:0' supported_device_types_=[CPU, XLA_CPU] possible_devices_=[]\r\n",
      "ReadVariableOp: CPU XLA_CPU \r\n",
      "AssignVariableOp: CPU XLA_CPU \r\n",
      "VarIsInitializedOp: CPU XLA_CPU \r\n",
      "VarHandleOp: CPU XLA_CPU \r\n",
      "Const: CPU XLA_CPU \r\n",
      "Fill: CPU XLA_CPU \r\n",
      "\r\n",
      "Colocation members, user-requested devices, and framework assigned devices, if any:\r\n",
      "  universal_transformer/body/encoder/universal_transformer_basic/rec_layer_0/self_attention/layer_postprocess/layer_norm/layer_norm_bias/Initializer/zeros/shape_as_tensor (Const) \r\n",
      "  universal_transformer/body/encoder/universal_transformer_basic/rec_layer_0/self_attention/layer_postprocess/layer_norm/layer_norm_bias/Initializer/zeros/Const (Const) \r\n",
      "  universal_transformer/body/encoder/universal_transformer_basic/rec_layer_0/self_attention/layer_postprocess/layer_norm/layer_norm_bias/Initializer/zeros (Fill) \r\n",
      "  universal_transformer/body/encoder/universal_transformer_basic/rec_layer_0/self_attention/layer_postprocess/layer_norm/layer_norm_bias (VarHandleOp) /device:GPU:0\r\n",
      "  universal_transformer/body/encoder/universal_transformer_basic/rec_layer_0/self_attention/layer_postprocess/layer_norm/layer_norm_bias/IsInitialized/VarIsInitializedOp (VarIsInitializedOp) /device:GPU:0\r\n",
      "  universal_transformer/body/encoder/universal_transformer_basic/rec_layer_0/self_attention/layer_postprocess/layer_norm/layer_norm_bias/Assign (AssignVariableOp) /device:GPU:0\r\n",
      "  universal_transformer/body/encoder/universal_transformer_basic/rec_layer_0/self_attention/layer_postprocess/layer_norm/layer_norm_bias/Read/ReadVariableOp (ReadVariableOp) /device:GPU:0\r\n",
      "  report_uninitialized_variables/VarIsInitializedOp_23 (VarIsInitializedOp) \r\n",
      "  report_uninitialized_variables_1/VarIsInitializedOp_23 (VarIsInitializedOp) \r\n",
      "  save/AssignVariableOp_26 (AssignVariableOp) /device:GPU:0\r\n",
      "\r\n",
      "2019-07-31 06:18:16.547499: W tensorflow/core/common_runtime/colocation_graph.cc:1016] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [\r\n",
      "  /job:localhost/replica:0/task:0/device:CPU:0\r\n",
      "  /job:localhost/replica:0/task:0/device:XLA_CPU:0].\r\n",
      "See below for details of this colocation group:\r\n",
      "Colocation Debug Info:\r\n",
      "Colocation group had the following types and supported devices: \r\n",
      "Root Member(assigned_device_name_index_=-1 requested_device_name_='/device:GPU:0' assigned_device_name_='' resource_device_name_='/device:GPU:0' supported_device_types_=[CPU, XLA_CPU] possible_devices_=[]\r\n",
      "AssignVariableOp: CPU XLA_CPU \r\n",
      "RandomUniform: CPU XLA_CPU \r\n",
      "VarIsInitializedOp: CPU XLA_CPU \r\n",
      "Const: CPU XLA_CPU \r\n",
      "Mul: CPU XLA_CPU \r\n",
      "ReadVariableOp: CPU XLA_CPU \r\n",
      "Sub: CPU XLA_CPU \r\n",
      "VarHandleOp: CPU XLA_CPU \r\n",
      "Add: CPU XLA_CPU \r\n",
      "\r\n",
      "Colocation members, user-requested devices, and framework assigned devices, if any:\r\n",
      "  universal_transformer/body/encoder/universal_transformer_basic/rec_layer_0/ffn/conv1/kernel/Initializer/random_uniform/shape (Const) \r\n",
      "  universal_transformer/body/encoder/universal_transformer_basic/rec_layer_0/ffn/conv1/kernel/Initializer/random_uniform/min (Const) \r\n",
      "  universal_transformer/body/encoder/universal_transformer_basic/rec_layer_0/ffn/conv1/kernel/Initializer/random_uniform/max (Const) \r\n",
      "  universal_transformer/body/encoder/universal_transformer_basic/rec_layer_0/ffn/conv1/kernel/Initializer/random_uniform/RandomUniform (RandomUniform) \r\n",
      "  universal_transformer/body/encoder/universal_transformer_basic/rec_layer_0/ffn/conv1/kernel/Initializer/random_uniform/sub (Sub) \r\n",
      "  universal_transformer/body/encoder/universal_transformer_basic/rec_layer_0/ffn/conv1/kernel/Initializer/random_uniform/mul (Mul) \r\n",
      "  universal_transformer/body/encoder/universal_transformer_basic/rec_layer_0/ffn/conv1/kernel/Initializer/random_uniform (Add) \r\n",
      "  universal_transformer/body/encoder/universal_transformer_basic/rec_layer_0/ffn/conv1/kernel (VarHandleOp) /device:GPU:0\r\n",
      "  universal_transformer/body/encoder/universal_transformer_basic/rec_layer_0/ffn/conv1/kernel/IsInitialized/VarIsInitializedOp (VarIsInitializedOp) /device:GPU:0\r\n",
      "  universal_transformer/body/encoder/universal_transformer_basic/rec_layer_0/ffn/conv1/kernel/Assign (AssignVariableOp) /device:GPU:0\r\n",
      "  universal_transformer/body/encoder/universal_transformer_basic/rec_layer_0/ffn/conv1/kernel/Read/ReadVariableOp (ReadVariableOp) /device:GPU:0\r\n",
      "  report_uninitialized_variables/VarIsInitializedOp_24 (VarIsInitializedOp) \r\n",
      "  report_uninitialized_variables_1/VarIsInitializedOp_24 (VarIsInitializedOp) \r\n",
      "  save/AssignVariableOp_21 (AssignVariableOp) /device:GPU:0\r\n",
      "\r\n",
      "2019-07-31 06:18:16.547932: W tensorflow/core/common_runtime/colocation_graph.cc:1016] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [\r\n",
      "  /job:localhost/replica:0/task:0/device:CPU:0\r\n",
      "  /job:localhost/replica:0/task:0/device:XLA_CPU:0].\r\n",
      "See below for details of this colocation group:\r\n",
      "Colocation Debug Info:\r\n",
      "Colocation group had the following types and supported devices: \r\n",
      "Root Member(assigned_device_name_index_=-1 requested_device_name_='/device:GPU:0' assigned_device_name_='' resource_device_name_='/device:GPU:0' supported_device_types_=[CPU, XLA_CPU] possible_devices_=[]\r\n",
      "ReadVariableOp: CPU XLA_CPU \r\n",
      "AssignVariableOp: CPU XLA_CPU \r\n",
      "VarIsInitializedOp: CPU XLA_CPU \r\n",
      "VarHandleOp: CPU XLA_CPU \r\n",
      "Const: CPU XLA_CPU \r\n",
      "Fill: CPU XLA_CPU \r\n",
      "\r\n",
      "Colocation members, user-requested devices, and framework assigned devices, if any:\r\n",
      "  universal_transformer/body/encoder/universal_transformer_basic/rec_layer_0/ffn/conv1/bias/Initializer/zeros/shape_as_tensor (Const) \r\n",
      "  universal_transformer/body/encoder/universal_transformer_basic/rec_layer_0/ffn/conv1/bias/Initializer/zeros/Const (Const) \r\n",
      "  universal_transformer/body/encoder/universal_transformer_basic/rec_layer_0/ffn/conv1/bias/Initializer/zeros (Fill) \r\n",
      "  universal_transformer/body/encoder/universal_transformer_basic/rec_layer_0/ffn/conv1/bias (VarHandleOp) /device:GPU:0\r\n",
      "  universal_transformer/body/encoder/universal_transformer_basic/rec_layer_0/ffn/conv1/bias/IsInitialized/VarIsInitializedOp (VarIsInitializedOp) /device:GPU:0\r\n",
      "  universal_transformer/body/encoder/universal_transformer_basic/rec_layer_0/ffn/conv1/bias/Assign (AssignVariableOp) /device:GPU:0\r\n",
      "  universal_transformer/body/encoder/universal_transformer_basic/rec_layer_0/ffn/conv1/bias/Read/ReadVariableOp (ReadVariableOp) /device:GPU:0\r\n",
      "  report_uninitialized_variables/VarIsInitializedOp_25 (VarIsInitializedOp) \r\n",
      "  report_uninitialized_variables_1/VarIsInitializedOp_25 (VarIsInitializedOp) \r\n",
      "  save/AssignVariableOp_20 (AssignVariableOp) /device:GPU:0\r\n",
      "\r\n",
      "2019-07-31 06:18:16.548330: W tensorflow/core/common_runtime/colocation_graph.cc:1016] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [\r\n",
      "  /job:localhost/replica:0/task:0/device:CPU:0\r\n",
      "  /job:localhost/replica:0/task:0/device:XLA_CPU:0].\r\n",
      "See below for details of this colocation group:\r\n",
      "Colocation Debug Info:\r\n",
      "Colocation group had the following types and supported devices: \r\n",
      "Root Member(assigned_device_name_index_=-1 requested_device_name_='/device:GPU:0' assigned_device_name_='' resource_device_name_='/device:GPU:0' supported_device_types_=[CPU, XLA_CPU] possible_devices_=[]\r\n",
      "AssignVariableOp: CPU XLA_CPU \r\n",
      "RandomUniform: CPU XLA_CPU \r\n",
      "VarIsInitializedOp: CPU XLA_CPU \r\n",
      "Const: CPU XLA_CPU \r\n",
      "Mul: CPU XLA_CPU \r\n",
      "ReadVariableOp: CPU XLA_CPU \r\n",
      "Sub: CPU XLA_CPU \r\n",
      "VarHandleOp: CPU XLA_CPU \r\n",
      "Add: CPU XLA_CPU \r\n",
      "\r\n",
      "Colocation members, user-requested devices, and framework assigned devices, if any:\r\n",
      "  universal_transformer/body/encoder/universal_transformer_basic/rec_layer_0/ffn/conv2/kernel/Initializer/random_uniform/shape (Const) \r\n",
      "  universal_transformer/body/encoder/universal_transformer_basic/rec_layer_0/ffn/conv2/kernel/Initializer/random_uniform/min (Const) \r\n",
      "  universal_transformer/body/encoder/universal_transformer_basic/rec_layer_0/ffn/conv2/kernel/Initializer/random_uniform/max (Const) \r\n",
      "  universal_transformer/body/encoder/universal_transformer_basic/rec_layer_0/ffn/conv2/kernel/Initializer/random_uniform/RandomUniform (RandomUniform) \r\n",
      "  universal_transformer/body/encoder/universal_transformer_basic/rec_layer_0/ffn/conv2/kernel/Initializer/random_uniform/sub (Sub) \r\n",
      "  universal_transformer/body/encoder/universal_transformer_basic/rec_layer_0/ffn/conv2/kernel/Initializer/random_uniform/mul (Mul) \r\n",
      "  universal_transformer/body/encoder/universal_transformer_basic/rec_layer_0/ffn/conv2/kernel/Initializer/random_uniform (Add) \r\n",
      "  universal_transformer/body/encoder/universal_transformer_basic/rec_layer_0/ffn/conv2/kernel (VarHandleOp) /device:GPU:0\r\n",
      "  universal_transformer/body/encoder/universal_transformer_basic/rec_layer_0/ffn/conv2/kernel/IsInitialized/VarIsInitializedOp (VarIsInitializedOp) /device:GPU:0\r\n",
      "  universal_transformer/body/encoder/universal_transformer_basic/rec_layer_0/ffn/conv2/kernel/Assign (AssignVariableOp) /device:GPU:0\r\n",
      "  universal_transformer/body/encoder/universal_transformer_basic/rec_layer_0/ffn/conv2/kernel/Read/ReadVariableOp (ReadVariableOp) /device:GPU:0\r\n",
      "  report_uninitialized_variables/VarIsInitializedOp_26 (VarIsInitializedOp) \r\n",
      "  report_uninitialized_variables_1/VarIsInitializedOp_26 (VarIsInitializedOp) \r\n",
      "  save/AssignVariableOp_23 (AssignVariableOp) /device:GPU:0\r\n",
      "\r\n",
      "2019-07-31 06:18:16.548771: W tensorflow/core/common_runtime/colocation_graph.cc:1016] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [\r\n",
      "  /job:localhost/replica:0/task:0/device:CPU:0\r\n",
      "  /job:localhost/replica:0/task:0/device:XLA_CPU:0].\r\n",
      "See below for details of this colocation group:\r\n",
      "Colocation Debug Info:\r\n",
      "Colocation group had the following types and supported devices: \r\n",
      "Root Member(assigned_device_name_index_=-1 requested_device_name_='/device:GPU:0' assigned_device_name_='' resource_device_name_='/device:GPU:0' supported_device_types_=[CPU, XLA_CPU] possible_devices_=[]\r\n",
      "ReadVariableOp: CPU XLA_CPU \r\n",
      "AssignVariableOp: CPU XLA_CPU \r\n",
      "VarIsInitializedOp: CPU XLA_CPU \r\n",
      "VarHandleOp: CPU XLA_CPU \r\n",
      "Const: CPU XLA_CPU \r\n",
      "Fill: CPU XLA_CPU \r\n",
      "\r\n",
      "Colocation members, user-requested devices, and framework assigned devices, if any:\r\n",
      "  universal_transformer/body/encoder/universal_transformer_basic/rec_layer_0/ffn/conv2/bias/Initializer/zeros/shape_as_tensor (Const) \r\n",
      "  universal_transformer/body/encoder/universal_transformer_basic/rec_layer_0/ffn/conv2/bias/Initializer/zeros/Const (Const) \r\n",
      "  universal_transformer/body/encoder/universal_transformer_basic/rec_layer_0/ffn/conv2/bias/Initializer/zeros (Fill) \r\n",
      "  universal_transformer/body/encoder/universal_transformer_basic/rec_layer_0/ffn/conv2/bias (VarHandleOp) /device:GPU:0\r\n",
      "  universal_transformer/body/encoder/universal_transformer_basic/rec_layer_0/ffn/conv2/bias/IsInitialized/VarIsInitializedOp (VarIsInitializedOp) /device:GPU:0\r\n",
      "  universal_transformer/body/encoder/universal_transformer_basic/rec_layer_0/ffn/conv2/bias/Assign (AssignVariableOp) /device:GPU:0\r\n",
      "  universal_transformer/body/encoder/universal_transformer_basic/rec_layer_0/ffn/conv2/bias/Read/ReadVariableOp (ReadVariableOp) /device:GPU:0\r\n",
      "  report_uninitialized_variables/VarIsInitializedOp_27 (VarIsInitializedOp) \r\n",
      "  report_uninitialized_variables_1/VarIsInitializedOp_27 (VarIsInitializedOp) \r\n",
      "  save/AssignVariableOp_22 (AssignVariableOp) /device:GPU:0\r\n",
      "\r\n",
      "2019-07-31 06:18:16.549215: W tensorflow/core/common_runtime/colocation_graph.cc:1016] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [\r\n",
      "  /job:localhost/replica:0/task:0/device:CPU:0\r\n",
      "  /job:localhost/replica:0/task:0/device:XLA_CPU:0].\r\n",
      "See below for details of this colocation group:\r\n",
      "Colocation Debug Info:\r\n",
      "Colocation group had the following types and supported devices: \r\n",
      "Root Member(assigned_device_name_index_=-1 requested_device_name_='/device:GPU:0' assigned_device_name_='' resource_device_name_='/device:GPU:0' supported_device_types_=[CPU, XLA_CPU] possible_devices_=[]\r\n",
      "ReadVariableOp: CPU XLA_CPU \r\n",
      "AssignVariableOp: CPU XLA_CPU \r\n",
      "VarIsInitializedOp: CPU XLA_CPU \r\n",
      "VarHandleOp: CPU XLA_CPU \r\n",
      "Const: CPU XLA_CPU \r\n",
      "Fill: CPU XLA_CPU \r\n",
      "\r\n",
      "Colocation members, user-requested devices, and framework assigned devices, if any:\r\n",
      "  universal_transformer/body/encoder/universal_transformer_basic/rec_layer_0/ffn/layer_postprocess/layer_norm/layer_norm_scale/Initializer/ones/shape_as_tensor (Const) \r\n",
      "  universal_transformer/body/encoder/universal_transformer_basic/rec_layer_0/ffn/layer_postprocess/layer_norm/layer_norm_scale/Initializer/ones/Const (Const) \r\n",
      "  universal_transformer/body/encoder/universal_transformer_basic/rec_layer_0/ffn/layer_postprocess/layer_norm/layer_norm_scale/Initializer/ones (Fill) \r\n",
      "  universal_transformer/body/encoder/universal_transformer_basic/rec_layer_0/ffn/layer_postprocess/layer_norm/layer_norm_scale (VarHandleOp) /device:GPU:0\r\n",
      "  universal_transformer/body/encoder/universal_transformer_basic/rec_layer_0/ffn/layer_postprocess/layer_norm/layer_norm_scale/IsInitialized/VarIsInitializedOp (VarIsInitializedOp) /device:GPU:0\r\n",
      "  universal_transformer/body/encoder/universal_transformer_basic/rec_layer_0/ffn/layer_postprocess/layer_norm/layer_norm_scale/Assign (AssignVariableOp) /device:GPU:0\r\n",
      "  universal_transformer/body/encoder/universal_transformer_basic/rec_layer_0/ffn/layer_postprocess/layer_norm/layer_norm_scale/Read/ReadVariableOp (ReadVariableOp) /device:GPU:0\r\n",
      "  report_uninitialized_variables/VarIsInitializedOp_28 (VarIsInitializedOp) \r\n",
      "  report_uninitialized_variables_1/VarIsInitializedOp_28 (VarIsInitializedOp) \r\n",
      "  save/AssignVariableOp_25 (AssignVariableOp) /device:GPU:0\r\n",
      "\r\n",
      "2019-07-31 06:18:16.549559: W tensorflow/core/common_runtime/colocation_graph.cc:1016] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [\r\n",
      "  /job:localhost/replica:0/task:0/device:CPU:0\r\n",
      "  /job:localhost/replica:0/task:0/device:XLA_CPU:0].\r\n",
      "See below for details of this colocation group:\r\n",
      "Colocation Debug Info:\r\n",
      "Colocation group had the following types and supported devices: \r\n",
      "Root Member(assigned_device_name_index_=-1 requested_device_name_='/device:GPU:0' assigned_device_name_='' resource_device_name_='/device:GPU:0' supported_device_types_=[CPU, XLA_CPU] possible_devices_=[]\r\n",
      "ReadVariableOp: CPU XLA_CPU \r\n",
      "AssignVariableOp: CPU XLA_CPU \r\n",
      "VarIsInitializedOp: CPU XLA_CPU \r\n",
      "VarHandleOp: CPU XLA_CPU \r\n",
      "Const: CPU XLA_CPU \r\n",
      "Fill: CPU XLA_CPU \r\n",
      "\r\n",
      "Colocation members, user-requested devices, and framework assigned devices, if any:\r\n",
      "  universal_transformer/body/encoder/universal_transformer_basic/rec_layer_0/ffn/layer_postprocess/layer_norm/layer_norm_bias/Initializer/zeros/shape_as_tensor (Const) \r\n",
      "  universal_transformer/body/encoder/universal_transformer_basic/rec_layer_0/ffn/layer_postprocess/layer_norm/layer_norm_bias/Initializer/zeros/Const (Const) \r\n",
      "  universal_transformer/body/encoder/universal_transformer_basic/rec_layer_0/ffn/layer_postprocess/layer_norm/layer_norm_bias/Initializer/zeros (Fill) \r\n",
      "  universal_transformer/body/encoder/universal_transformer_basic/rec_layer_0/ffn/layer_postprocess/layer_norm/layer_norm_bias (VarHandleOp) /device:GPU:0\r\n",
      "  universal_transformer/body/encoder/universal_transformer_basic/rec_layer_0/ffn/layer_postprocess/layer_norm/layer_norm_bias/IsInitialized/VarIsInitializedOp (VarIsInitializedOp) /device:GPU:0\r\n",
      "  universal_transformer/body/encoder/universal_transformer_basic/rec_layer_0/ffn/layer_postprocess/layer_norm/layer_norm_bias/Assign (AssignVariableOp) /device:GPU:0\r\n",
      "  universal_transformer/body/encoder/universal_transformer_basic/rec_layer_0/ffn/layer_postprocess/layer_norm/layer_norm_bias/Read/ReadVariableOp (ReadVariableOp) /device:GPU:0\r\n",
      "  report_uninitialized_variables/VarIsInitializedOp_29 (VarIsInitializedOp) \r\n",
      "  report_uninitialized_variables_1/VarIsInitializedOp_29 (VarIsInitializedOp) \r\n",
      "  save/AssignVariableOp_24 (AssignVariableOp) /device:GPU:0\r\n",
      "\r\n",
      "2019-07-31 06:18:16.550182: W tensorflow/core/common_runtime/colocation_graph.cc:1016] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [\r\n",
      "  /job:localhost/replica:0/task:0/device:CPU:0\r\n",
      "  /job:localhost/replica:0/task:0/device:XLA_CPU:0].\r\n",
      "See below for details of this colocation group:\r\n",
      "Colocation Debug Info:\r\n",
      "Colocation group had the following types and supported devices: \r\n",
      "Root Member(assigned_device_name_index_=-1 requested_device_name_='/device:GPU:0' assigned_device_name_='' resource_device_name_='/device:GPU:0' supported_device_types_=[CPU, XLA_CPU] possible_devices_=[]\r\n",
      "ReadVariableOp: CPU XLA_CPU \r\n",
      "AssignVariableOp: CPU XLA_CPU \r\n",
      "RandomStandardNormal: CPU XLA_CPU \r\n",
      "Mul: CPU XLA_CPU \r\n",
      "Add: CPU XLA_CPU \r\n",
      "VarHandleOp: CPU XLA_CPU \r\n",
      "Const: CPU XLA_CPU \r\n",
      "VarIsInitializedOp: CPU XLA_CPU \r\n",
      "\r\n",
      "Colocation members, user-requested devices, and framework assigned devices, if any:\r\n",
      "  universal_transformer/body/decoder/universal_transformer_basic/layer_embedding/Initializer/random_normal/shape (Const) \r\n",
      "  universal_transformer/body/decoder/universal_transformer_basic/layer_embedding/Initializer/random_normal/mean (Const) \r\n",
      "  universal_transformer/body/decoder/universal_transformer_basic/layer_embedding/Initializer/random_normal/stddev (Const) \r\n",
      "  universal_transformer/body/decoder/universal_transformer_basic/layer_embedding/Initializer/random_normal/RandomStandardNormal (RandomStandardNormal) \r\n",
      "  universal_transformer/body/decoder/universal_transformer_basic/layer_embedding/Initializer/random_normal/mul (Mul) \r\n",
      "  universal_transformer/body/decoder/universal_transformer_basic/layer_embedding/Initializer/random_normal (Add) \r\n",
      "  universal_transformer/body/decoder/universal_transformer_basic/layer_embedding (VarHandleOp) /device:GPU:0\r\n",
      "  universal_transformer/body/decoder/universal_transformer_basic/layer_embedding/IsInitialized/VarIsInitializedOp (VarIsInitializedOp) /device:GPU:0\r\n",
      "  universal_transformer/body/decoder/universal_transformer_basic/layer_embedding/Assign (AssignVariableOp) /device:GPU:0\r\n",
      "  universal_transformer/body/decoder/universal_transformer_basic/layer_embedding/Read/ReadVariableOp (ReadVariableOp) /device:GPU:0\r\n",
      "  report_uninitialized_variables/VarIsInitializedOp_30 (VarIsInitializedOp) \r\n",
      "  report_uninitialized_variables_1/VarIsInitializedOp_30 (VarIsInitializedOp) \r\n",
      "  save/AssignVariableOp (AssignVariableOp) /device:GPU:0\r\n",
      "\r\n",
      "2019-07-31 06:18:16.550623: W tensorflow/core/common_runtime/colocation_graph.cc:1016] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [\r\n",
      "  /job:localhost/replica:0/task:0/device:CPU:0\r\n",
      "  /job:localhost/replica:0/task:0/device:XLA_CPU:0].\r\n",
      "See below for details of this colocation group:\r\n",
      "Colocation Debug Info:\r\n",
      "Colocation group had the following types and supported devices: \r\n",
      "Root Member(assigned_device_name_index_=-1 requested_device_name_='/device:GPU:0' assigned_device_name_='' resource_device_name_='/device:GPU:0' supported_device_types_=[CPU, XLA_CPU] possible_devices_=[]\r\n",
      "AssignVariableOp: CPU XLA_CPU \r\n",
      "RandomUniform: CPU XLA_CPU \r\n",
      "VarIsInitializedOp: CPU XLA_CPU \r\n",
      "Const: CPU XLA_CPU \r\n",
      "Mul: CPU XLA_CPU \r\n",
      "ReadVariableOp: CPU XLA_CPU \r\n",
      "Sub: CPU XLA_CPU \r\n",
      "VarHandleOp: CPU XLA_CPU \r\n",
      "Add: CPU XLA_CPU \r\n",
      "\r\n",
      "Colocation members, user-requested devices, and framework assigned devices, if any:\r\n",
      "  universal_transformer/body/decoder/universal_transformer_basic/rec_layer_0/self_attention/multihead_attention/q/kernel/Initializer/random_uniform/shape (Const) \r\n",
      "  universal_transformer/body/decoder/universal_transformer_basic/rec_layer_0/self_attention/multihead_attention/q/kernel/Initializer/random_uniform/min (Const) \r\n",
      "  universal_transformer/body/decoder/universal_transformer_basic/rec_layer_0/self_attention/multihead_attention/q/kernel/Initializer/random_uniform/max (Const) \r\n",
      "  universal_transformer/body/decoder/universal_transformer_basic/rec_layer_0/self_attention/multihead_attention/q/kernel/Initializer/random_uniform/RandomUniform (RandomUniform) \r\n",
      "  universal_transformer/body/decoder/universal_transformer_basic/rec_layer_0/self_attention/multihead_attention/q/kernel/Initializer/random_uniform/sub (Sub) \r\n",
      "  universal_transformer/body/decoder/universal_transformer_basic/rec_layer_0/self_attention/multihead_attention/q/kernel/Initializer/random_uniform/mul (Mul) \r\n",
      "  universal_transformer/body/decoder/universal_transformer_basic/rec_layer_0/self_attention/multihead_attention/q/kernel/Initializer/random_uniform (Add) \r\n",
      "  universal_transformer/body/decoder/universal_transformer_basic/rec_layer_0/self_attention/multihead_attention/q/kernel (VarHandleOp) /device:GPU:0\r\n",
      "  universal_transformer/body/decoder/universal_transformer_basic/rec_layer_0/self_attention/multihead_attention/q/kernel/IsInitialized/VarIsInitializedOp (VarIsInitializedOp) /device:GPU:0\r\n",
      "  universal_transformer/body/decoder/universal_transformer_basic/rec_layer_0/self_attention/multihead_attention/q/kernel/Assign (AssignVariableOp) /device:GPU:0\r\n",
      "  universal_transformer/body/decoder/universal_transformer_basic/rec_layer_0/self_attention/multihead_attention/q/kernel/Read/ReadVariableOp (ReadVariableOp) /device:GPU:0\r\n",
      "  report_uninitialized_variables/VarIsInitializedOp_31 (VarIsInitializedOp) \r\n",
      "  report_uninitialized_variables_1/VarIsInitializedOp_31 (VarIsInitializedOp) \r\n",
      "  save/AssignVariableOp_17 (AssignVariableOp) /device:GPU:0\r\n",
      "\r\n",
      "2019-07-31 06:18:16.551086: W tensorflow/core/common_runtime/colocation_graph.cc:1016] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [\r\n",
      "  /job:localhost/replica:0/task:0/device:CPU:0\r\n",
      "  /job:localhost/replica:0/task:0/device:XLA_CPU:0].\r\n",
      "See below for details of this colocation group:\r\n",
      "Colocation Debug Info:\r\n",
      "Colocation group had the following types and supported devices: \r\n",
      "Root Member(assigned_device_name_index_=-1 requested_device_name_='/device:GPU:0' assigned_device_name_='' resource_device_name_='/device:GPU:0' supported_device_types_=[CPU, XLA_CPU] possible_devices_=[]\r\n",
      "AssignVariableOp: CPU XLA_CPU \r\n",
      "RandomUniform: CPU XLA_CPU \r\n",
      "VarIsInitializedOp: CPU XLA_CPU \r\n",
      "Const: CPU XLA_CPU \r\n",
      "Mul: CPU XLA_CPU \r\n",
      "ReadVariableOp: CPU XLA_CPU \r\n",
      "Sub: CPU XLA_CPU \r\n",
      "VarHandleOp: CPU XLA_CPU \r\n",
      "Add: CPU XLA_CPU \r\n",
      "\r\n",
      "Colocation members, user-requested devices, and framework assigned devices, if any:\r\n",
      "  universal_transformer/body/decoder/universal_transformer_basic/rec_layer_0/self_attention/multihead_attention/k/kernel/Initializer/random_uniform/shape (Const) \r\n",
      "  universal_transformer/body/decoder/universal_transformer_basic/rec_layer_0/self_attention/multihead_attention/k/kernel/Initializer/random_uniform/min (Const) \r\n",
      "  universal_transformer/body/decoder/universal_transformer_basic/rec_layer_0/self_attention/multihead_attention/k/kernel/Initializer/random_uniform/max (Const) \r\n",
      "  universal_transformer/body/decoder/universal_transformer_basic/rec_layer_0/self_attention/multihead_attention/k/kernel/Initializer/random_uniform/RandomUniform (RandomUniform) \r\n",
      "  universal_transformer/body/decoder/universal_transformer_basic/rec_layer_0/self_attention/multihead_attention/k/kernel/Initializer/random_uniform/sub (Sub) \r\n",
      "  universal_transformer/body/decoder/universal_transformer_basic/rec_layer_0/self_attention/multihead_attention/k/kernel/Initializer/random_uniform/mul (Mul) \r\n",
      "  universal_transformer/body/decoder/universal_transformer_basic/rec_layer_0/self_attention/multihead_attention/k/kernel/Initializer/random_uniform (Add) \r\n",
      "  universal_transformer/body/decoder/universal_transformer_basic/rec_layer_0/self_attention/multihead_attention/k/kernel (VarHandleOp) /device:GPU:0\r\n",
      "  universal_transformer/body/decoder/universal_transformer_basic/rec_layer_0/self_attention/multihead_attention/k/kernel/IsInitialized/VarIsInitializedOp (VarIsInitializedOp) /device:GPU:0\r\n",
      "  universal_transformer/body/decoder/universal_transformer_basic/rec_layer_0/self_attention/multihead_attention/k/kernel/Assign (AssignVariableOp) /device:GPU:0\r\n",
      "  universal_transformer/body/decoder/universal_transformer_basic/rec_layer_0/self_attention/multihead_attention/k/kernel/Read/ReadVariableOp (ReadVariableOp) /device:GPU:0\r\n",
      "  report_uninitialized_variables/VarIsInitializedOp_32 (VarIsInitializedOp) \r\n",
      "  report_uninitialized_variables_1/VarIsInitializedOp_32 (VarIsInitializedOp) \r\n",
      "  save/AssignVariableOp_15 (AssignVariableOp) /device:GPU:0\r\n",
      "\r\n",
      "2019-07-31 06:18:16.551546: W tensorflow/core/common_runtime/colocation_graph.cc:1016] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [\r\n",
      "  /job:localhost/replica:0/task:0/device:CPU:0\r\n",
      "  /job:localhost/replica:0/task:0/device:XLA_CPU:0].\r\n",
      "See below for details of this colocation group:\r\n",
      "Colocation Debug Info:\r\n",
      "Colocation group had the following types and supported devices: \r\n",
      "Root Member(assigned_device_name_index_=-1 requested_device_name_='/device:GPU:0' assigned_device_name_='' resource_device_name_='/device:GPU:0' supported_device_types_=[CPU, XLA_CPU] possible_devices_=[]\r\n",
      "AssignVariableOp: CPU XLA_CPU \r\n",
      "RandomUniform: CPU XLA_CPU \r\n",
      "VarIsInitializedOp: CPU XLA_CPU \r\n",
      "Const: CPU XLA_CPU \r\n",
      "Mul: CPU XLA_CPU \r\n",
      "ReadVariableOp: CPU XLA_CPU \r\n",
      "Sub: CPU XLA_CPU \r\n",
      "VarHandleOp: CPU XLA_CPU \r\n",
      "Add: CPU XLA_CPU \r\n",
      "\r\n",
      "Colocation members, user-requested devices, and framework assigned devices, if any:\r\n",
      "  universal_transformer/body/decoder/universal_transformer_basic/rec_layer_0/self_attention/multihead_attention/v/kernel/Initializer/random_uniform/shape (Const) \r\n",
      "  universal_transformer/body/decoder/universal_transformer_basic/rec_layer_0/self_attention/multihead_attention/v/kernel/Initializer/random_uniform/min (Const) \r\n",
      "  universal_transformer/body/decoder/universal_transformer_basic/rec_layer_0/self_attention/multihead_attention/v/kernel/Initializer/random_uniform/max (Const) \r\n",
      "  universal_transformer/body/decoder/universal_transformer_basic/rec_layer_0/self_attention/multihead_attention/v/kernel/Initializer/random_uniform/RandomUniform (RandomUniform) \r\n",
      "  universal_transformer/body/decoder/universal_transformer_basic/rec_layer_0/self_attention/multihead_attention/v/kernel/Initializer/random_uniform/sub (Sub) \r\n",
      "  universal_transformer/body/decoder/universal_transformer_basic/rec_layer_0/self_attention/multihead_attention/v/kernel/Initializer/random_uniform/mul (Mul) \r\n",
      "  universal_transformer/body/decoder/universal_transformer_basic/rec_layer_0/self_attention/multihead_attention/v/kernel/Initializer/random_uniform (Add) \r\n",
      "  universal_transformer/body/decoder/universal_transformer_basic/rec_layer_0/self_attention/multihead_attention/v/kernel (VarHandleOp) /device:GPU:0\r\n",
      "  universal_transformer/body/decoder/universal_transformer_basic/rec_layer_0/self_attention/multihead_attention/v/kernel/IsInitialized/VarIsInitializedOp (VarIsInitializedOp) /device:GPU:0\r\n",
      "  universal_transformer/body/decoder/universal_transformer_basic/rec_layer_0/self_attention/multihead_attention/v/kernel/Assign (AssignVariableOp) /device:GPU:0\r\n",
      "  universal_transformer/body/decoder/universal_transformer_basic/rec_layer_0/self_attention/multihead_attention/v/kernel/Read/ReadVariableOp (ReadVariableOp) /device:GPU:0\r\n",
      "  report_uninitialized_variables/VarIsInitializedOp_33 (VarIsInitializedOp) \r\n",
      "  report_uninitialized_variables_1/VarIsInitializedOp_33 (VarIsInitializedOp) \r\n",
      "  save/AssignVariableOp_18 (AssignVariableOp) /device:GPU:0\r\n",
      "\r\n",
      "2019-07-31 06:18:16.552160: W tensorflow/core/common_runtime/colocation_graph.cc:1016] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [\r\n",
      "  /job:localhost/replica:0/task:0/device:CPU:0\r\n",
      "  /job:localhost/replica:0/task:0/device:XLA_CPU:0].\r\n",
      "See below for details of this colocation group:\r\n",
      "Colocation Debug Info:\r\n",
      "Colocation group had the following types and supported devices: \r\n",
      "Root Member(assigned_device_name_index_=-1 requested_device_name_='/device:GPU:0' assigned_device_name_='' resource_device_name_='/device:GPU:0' supported_device_types_=[CPU, XLA_CPU] possible_devices_=[]\r\n",
      "AssignVariableOp: CPU XLA_CPU \r\n",
      "RandomUniform: CPU XLA_CPU \r\n",
      "VarIsInitializedOp: CPU XLA_CPU \r\n",
      "Const: CPU XLA_CPU \r\n",
      "Mul: CPU XLA_CPU \r\n",
      "ReadVariableOp: CPU XLA_CPU \r\n",
      "Sub: CPU XLA_CPU \r\n",
      "VarHandleOp: CPU XLA_CPU \r\n",
      "Add: CPU XLA_CPU \r\n",
      "\r\n",
      "Colocation members, user-requested devices, and framework assigned devices, if any:\r\n",
      "  universal_transformer/body/decoder/universal_transformer_basic/rec_layer_0/self_attention/multihead_attention/output_transform/kernel/Initializer/random_uniform/shape (Const) \r\n",
      "  universal_transformer/body/decoder/universal_transformer_basic/rec_layer_0/self_attention/multihead_attention/output_transform/kernel/Initializer/random_uniform/min (Const) \r\n",
      "  universal_transformer/body/decoder/universal_transformer_basic/rec_layer_0/self_attention/multihead_attention/output_transform/kernel/Initializer/random_uniform/max (Const) \r\n",
      "  universal_transformer/body/decoder/universal_transformer_basic/rec_layer_0/self_attention/multihead_attention/output_transform/kernel/Initializer/random_uniform/RandomUniform (RandomUniform) \r\n",
      "  universal_transformer/body/decoder/universal_transformer_basic/rec_layer_0/self_attention/multihead_attention/output_transform/kernel/Initializer/random_uniform/sub (Sub) \r\n",
      "  universal_transformer/body/decoder/universal_transformer_basic/rec_layer_0/self_attention/multihead_attention/output_transform/kernel/Initializer/random_uniform/mul (Mul) \r\n",
      "  universal_transformer/body/decoder/universal_transformer_basic/rec_layer_0/self_attention/multihead_attention/output_transform/kernel/Initializer/random_uniform (Add) \r\n",
      "  universal_transformer/body/decoder/universal_transformer_basic/rec_layer_0/self_attention/multihead_attention/output_transform/kernel (VarHandleOp) /device:GPU:0\r\n",
      "  universal_transformer/body/decoder/universal_transformer_basic/rec_layer_0/self_attention/multihead_attention/output_transform/kernel/IsInitialized/VarIsInitializedOp (VarIsInitializedOp) /device:GPU:0\r\n",
      "  universal_transformer/body/decoder/universal_transformer_basic/rec_layer_0/self_attention/multihead_attention/output_transform/kernel/Assign (AssignVariableOp) /device:GPU:0\r\n",
      "  universal_transformer/body/decoder/universal_transformer_basic/rec_layer_0/self_attention/multihead_attention/output_transform/kernel/Read/ReadVariableOp (ReadVariableOp) /device:GPU:0\r\n",
      "  report_uninitialized_variables/VarIsInitializedOp_34 (VarIsInitializedOp) \r\n",
      "  report_uninitialized_variables_1/VarIsInitializedOp_34 (VarIsInitializedOp) \r\n",
      "  save/AssignVariableOp_16 (AssignVariableOp) /device:GPU:0\r\n",
      "\r\n",
      "2019-07-31 06:18:16.552669: W tensorflow/core/common_runtime/colocation_graph.cc:1016] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [\r\n",
      "  /job:localhost/replica:0/task:0/device:CPU:0\r\n",
      "  /job:localhost/replica:0/task:0/device:XLA_CPU:0].\r\n",
      "See below for details of this colocation group:\r\n",
      "Colocation Debug Info:\r\n",
      "Colocation group had the following types and supported devices: \r\n",
      "Root Member(assigned_device_name_index_=-1 requested_device_name_='/device:GPU:0' assigned_device_name_='' resource_device_name_='/device:GPU:0' supported_device_types_=[CPU, XLA_CPU] possible_devices_=[]\r\n",
      "ReadVariableOp: CPU XLA_CPU \r\n",
      "AssignVariableOp: CPU XLA_CPU \r\n",
      "VarIsInitializedOp: CPU XLA_CPU \r\n",
      "VarHandleOp: CPU XLA_CPU \r\n",
      "Const: CPU XLA_CPU \r\n",
      "Fill: CPU XLA_CPU \r\n",
      "\r\n",
      "Colocation members, user-requested devices, and framework assigned devices, if any:\r\n",
      "  universal_transformer/body/decoder/universal_transformer_basic/rec_layer_0/self_attention/layer_postprocess/layer_norm/layer_norm_scale/Initializer/ones/shape_as_tensor (Const) \r\n",
      "  universal_transformer/body/decoder/universal_transformer_basic/rec_layer_0/self_attention/layer_postprocess/layer_norm/layer_norm_scale/Initializer/ones/Const (Const) \r\n",
      "  universal_transformer/body/decoder/universal_transformer_basic/rec_layer_0/self_attention/layer_postprocess/layer_norm/layer_norm_scale/Initializer/ones (Fill) \r\n",
      "  universal_transformer/body/decoder/universal_transformer_basic/rec_layer_0/self_attention/layer_postprocess/layer_norm/layer_norm_scale (VarHandleOp) /device:GPU:0\r\n",
      "  universal_transformer/body/decoder/universal_transformer_basic/rec_layer_0/self_attention/layer_postprocess/layer_norm/layer_norm_scale/IsInitialized/VarIsInitializedOp (VarIsInitializedOp) /device:GPU:0\r\n",
      "  universal_transformer/body/decoder/universal_transformer_basic/rec_layer_0/self_attention/layer_postprocess/layer_norm/layer_norm_scale/Assign (AssignVariableOp) /device:GPU:0\r\n",
      "  universal_transformer/body/decoder/universal_transformer_basic/rec_layer_0/self_attention/layer_postprocess/layer_norm/layer_norm_scale/Read/ReadVariableOp (ReadVariableOp) /device:GPU:0\r\n",
      "  report_uninitialized_variables/VarIsInitializedOp_35 (VarIsInitializedOp) \r\n",
      "  report_uninitialized_variables_1/VarIsInitializedOp_35 (VarIsInitializedOp) \r\n",
      "  save/AssignVariableOp_14 (AssignVariableOp) /device:GPU:0\r\n",
      "\r\n",
      "2019-07-31 06:18:16.552944: W tensorflow/core/common_runtime/colocation_graph.cc:1016] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [\r\n",
      "  /job:localhost/replica:0/task:0/device:CPU:0\r\n",
      "  /job:localhost/replica:0/task:0/device:XLA_CPU:0].\r\n",
      "See below for details of this colocation group:\r\n",
      "Colocation Debug Info:\r\n",
      "Colocation group had the following types and supported devices: \r\n",
      "Root Member(assigned_device_name_index_=-1 requested_device_name_='/device:GPU:0' assigned_device_name_='' resource_device_name_='/device:GPU:0' supported_device_types_=[CPU, XLA_CPU] possible_devices_=[]\r\n",
      "ReadVariableOp: CPU XLA_CPU \r\n",
      "AssignVariableOp: CPU XLA_CPU \r\n",
      "VarIsInitializedOp: CPU XLA_CPU \r\n",
      "VarHandleOp: CPU XLA_CPU \r\n",
      "Const: CPU XLA_CPU \r\n",
      "Fill: CPU XLA_CPU \r\n",
      "\r\n",
      "Colocation members, user-requested devices, and framework assigned devices, if any:\r\n",
      "  universal_transformer/body/decoder/universal_transformer_basic/rec_layer_0/self_attention/layer_postprocess/layer_norm/layer_norm_bias/Initializer/zeros/shape_as_tensor (Const) \r\n",
      "  universal_transformer/body/decoder/universal_transformer_basic/rec_layer_0/self_attention/layer_postprocess/layer_norm/layer_norm_bias/Initializer/zeros/Const (Const) \r\n",
      "  universal_transformer/body/decoder/universal_transformer_basic/rec_layer_0/self_attention/layer_postprocess/layer_norm/layer_norm_bias/Initializer/zeros (Fill) \r\n",
      "  universal_transformer/body/decoder/universal_transformer_basic/rec_layer_0/self_attention/layer_postprocess/layer_norm/layer_norm_bias (VarHandleOp) /device:GPU:0\r\n",
      "  universal_transformer/body/decoder/universal_transformer_basic/rec_layer_0/self_attention/layer_postprocess/layer_norm/layer_norm_bias/IsInitialized/VarIsInitializedOp (VarIsInitializedOp) /device:GPU:0\r\n",
      "  universal_transformer/body/decoder/universal_transformer_basic/rec_layer_0/self_attention/layer_postprocess/layer_norm/layer_norm_bias/Assign (AssignVariableOp) /device:GPU:0\r\n",
      "  universal_transformer/body/decoder/universal_transformer_basic/rec_layer_0/self_attention/layer_postprocess/layer_norm/layer_norm_bias/Read/ReadVariableOp (ReadVariableOp) /device:GPU:0\r\n",
      "  report_uninitialized_variables/VarIsInitializedOp_36 (VarIsInitializedOp) \r\n",
      "  report_uninitialized_variables_1/VarIsInitializedOp_36 (VarIsInitializedOp) \r\n",
      "  save/AssignVariableOp_13 (AssignVariableOp) /device:GPU:0\r\n",
      "\r\n",
      "2019-07-31 06:18:16.553109: W tensorflow/core/common_runtime/colocation_graph.cc:1016] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [\r\n",
      "  /job:localhost/replica:0/task:0/device:CPU:0\r\n",
      "  /job:localhost/replica:0/task:0/device:XLA_CPU:0].\r\n",
      "See below for details of this colocation group:\r\n",
      "Colocation Debug Info:\r\n",
      "Colocation group had the following types and supported devices: \r\n",
      "Root Member(assigned_device_name_index_=-1 requested_device_name_='/device:GPU:0' assigned_device_name_='' resource_device_name_='/device:GPU:0' supported_device_types_=[CPU, XLA_CPU] possible_devices_=[]\r\n",
      "AssignVariableOp: CPU XLA_CPU \r\n",
      "RandomUniform: CPU XLA_CPU \r\n",
      "VarIsInitializedOp: CPU XLA_CPU \r\n",
      "Const: CPU XLA_CPU \r\n",
      "Mul: CPU XLA_CPU \r\n",
      "ReadVariableOp: CPU XLA_CPU \r\n",
      "Sub: CPU XLA_CPU \r\n",
      "VarHandleOp: CPU XLA_CPU \r\n",
      "Add: CPU XLA_CPU \r\n",
      "\r\n",
      "Colocation members, user-requested devices, and framework assigned devices, if any:\r\n",
      "  universal_transformer/body/decoder/universal_transformer_basic/rec_layer_0/encdec_attention/multihead_attention/q/kernel/Initializer/random_uniform/shape (Const) \r\n",
      "  universal_transformer/body/decoder/universal_transformer_basic/rec_layer_0/encdec_attention/multihead_attention/q/kernel/Initializer/random_uniform/min (Const) \r\n",
      "  universal_transformer/body/decoder/universal_transformer_basic/rec_layer_0/encdec_attention/multihead_attention/q/kernel/Initializer/random_uniform/max (Const) \r\n",
      "  universal_transformer/body/decoder/universal_transformer_basic/rec_layer_0/encdec_attention/multihead_attention/q/kernel/Initializer/random_uniform/RandomUniform (RandomUniform) \r\n",
      "  universal_transformer/body/decoder/universal_transformer_basic/rec_layer_0/encdec_attention/multihead_attention/q/kernel/Initializer/random_uniform/sub (Sub) \r\n",
      "  universal_transformer/body/decoder/universal_transformer_basic/rec_layer_0/encdec_attention/multihead_attention/q/kernel/Initializer/random_uniform/mul (Mul) \r\n",
      "  universal_transformer/body/decoder/universal_transformer_basic/rec_layer_0/encdec_attention/multihead_attention/q/kernel/Initializer/random_uniform (Add) \r\n",
      "  universal_transformer/body/decoder/universal_transformer_basic/rec_layer_0/encdec_attention/multihead_attention/q/kernel (VarHandleOp) /device:GPU:0\r\n",
      "  universal_transformer/body/decoder/universal_transformer_basic/rec_layer_0/encdec_attention/multihead_attention/q/kernel/IsInitialized/VarIsInitializedOp (VarIsInitializedOp) /device:GPU:0\r\n",
      "  universal_transformer/body/decoder/universal_transformer_basic/rec_layer_0/encdec_attention/multihead_attention/q/kernel/Assign (AssignVariableOp) /device:GPU:0\r\n",
      "  universal_transformer/body/decoder/universal_transformer_basic/rec_layer_0/encdec_attention/multihead_attention/q/kernel/Read/ReadVariableOp (ReadVariableOp) /device:GPU:0\r\n",
      "  report_uninitialized_variables/VarIsInitializedOp_37 (VarIsInitializedOp) \r\n",
      "  report_uninitialized_variables_1/VarIsInitializedOp_37 (VarIsInitializedOp) \r\n",
      "  save/AssignVariableOp_5 (AssignVariableOp) /device:GPU:0\r\n",
      "\r\n",
      "2019-07-31 06:18:16.553370: W tensorflow/core/common_runtime/colocation_graph.cc:1016] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [\r\n",
      "  /job:localhost/replica:0/task:0/device:CPU:0\r\n",
      "  /job:localhost/replica:0/task:0/device:XLA_CPU:0].\r\n",
      "See below for details of this colocation group:\r\n",
      "Colocation Debug Info:\r\n",
      "Colocation group had the following types and supported devices: \r\n",
      "Root Member(assigned_device_name_index_=-1 requested_device_name_='/device:GPU:0' assigned_device_name_='' resource_device_name_='/device:GPU:0' supported_device_types_=[CPU, XLA_CPU] possible_devices_=[]\r\n",
      "AssignVariableOp: CPU XLA_CPU \r\n",
      "RandomUniform: CPU XLA_CPU \r\n",
      "VarIsInitializedOp: CPU XLA_CPU \r\n",
      "Const: CPU XLA_CPU \r\n",
      "Mul: CPU XLA_CPU \r\n",
      "ReadVariableOp: CPU XLA_CPU \r\n",
      "Sub: CPU XLA_CPU \r\n",
      "VarHandleOp: CPU XLA_CPU \r\n",
      "Add: CPU XLA_CPU \r\n",
      "\r\n",
      "Colocation members, user-requested devices, and framework assigned devices, if any:\r\n",
      "  universal_transformer/body/decoder/universal_transformer_basic/rec_layer_0/encdec_attention/multihead_attention/k/kernel/Initializer/random_uniform/shape (Const) \r\n",
      "  universal_transformer/body/decoder/universal_transformer_basic/rec_layer_0/encdec_attention/multihead_attention/k/kernel/Initializer/random_uniform/min (Const) \r\n",
      "  universal_transformer/body/decoder/universal_transformer_basic/rec_layer_0/encdec_attention/multihead_attention/k/kernel/Initializer/random_uniform/max (Const) \r\n",
      "  universal_transformer/body/decoder/universal_transformer_basic/rec_layer_0/encdec_attention/multihead_attention/k/kernel/Initializer/random_uniform/RandomUniform (RandomUniform) \r\n",
      "  universal_transformer/body/decoder/universal_transformer_basic/rec_layer_0/encdec_attention/multihead_attention/k/kernel/Initializer/random_uniform/sub (Sub) \r\n",
      "  universal_transformer/body/decoder/universal_transformer_basic/rec_layer_0/encdec_attention/multihead_attention/k/kernel/Initializer/random_uniform/mul (Mul) \r\n",
      "  universal_transformer/body/decoder/universal_transformer_basic/rec_layer_0/encdec_attention/multihead_attention/k/kernel/Initializer/random_uniform (Add) \r\n",
      "  universal_transformer/body/decoder/universal_transformer_basic/rec_layer_0/encdec_attention/multihead_attention/k/kernel (VarHandleOp) /device:GPU:0\r\n",
      "  universal_transformer/body/decoder/universal_transformer_basic/rec_layer_0/encdec_attention/multihead_attention/k/kernel/IsInitialized/VarIsInitializedOp (VarIsInitializedOp) /device:GPU:0\r\n",
      "  universal_transformer/body/decoder/universal_transformer_basic/rec_layer_0/encdec_attention/multihead_attention/k/kernel/Assign (AssignVariableOp) /device:GPU:0\r\n",
      "  universal_transformer/body/decoder/universal_transformer_basic/rec_layer_0/encdec_attention/multihead_attention/k/kernel/Read/ReadVariableOp (ReadVariableOp) /device:GPU:0\r\n",
      "  report_uninitialized_variables/VarIsInitializedOp_38 (VarIsInitializedOp) \r\n",
      "  report_uninitialized_variables_1/VarIsInitializedOp_38 (VarIsInitializedOp) \r\n",
      "  save/AssignVariableOp_3 (AssignVariableOp) /device:GPU:0\r\n",
      "\r\n",
      "2019-07-31 06:18:16.553964: W tensorflow/core/common_runtime/colocation_graph.cc:1016] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [\r\n",
      "  /job:localhost/replica:0/task:0/device:CPU:0\r\n",
      "  /job:localhost/replica:0/task:0/device:XLA_CPU:0].\r\n",
      "See below for details of this colocation group:\r\n",
      "Colocation Debug Info:\r\n",
      "Colocation group had the following types and supported devices: \r\n",
      "Root Member(assigned_device_name_index_=-1 requested_device_name_='/device:GPU:0' assigned_device_name_='' resource_device_name_='/device:GPU:0' supported_device_types_=[CPU, XLA_CPU] possible_devices_=[]\r\n",
      "AssignVariableOp: CPU XLA_CPU \r\n",
      "RandomUniform: CPU XLA_CPU \r\n",
      "VarIsInitializedOp: CPU XLA_CPU \r\n",
      "Const: CPU XLA_CPU \r\n",
      "Mul: CPU XLA_CPU \r\n",
      "ReadVariableOp: CPU XLA_CPU \r\n",
      "Sub: CPU XLA_CPU \r\n",
      "VarHandleOp: CPU XLA_CPU \r\n",
      "Add: CPU XLA_CPU \r\n",
      "\r\n",
      "Colocation members, user-requested devices, and framework assigned devices, if any:\r\n",
      "  universal_transformer/body/decoder/universal_transformer_basic/rec_layer_0/encdec_attention/multihead_attention/v/kernel/Initializer/random_uniform/shape (Const) \r\n",
      "  universal_transformer/body/decoder/universal_transformer_basic/rec_layer_0/encdec_attention/multihead_attention/v/kernel/Initializer/random_uniform/min (Const) \r\n",
      "  universal_transformer/body/decoder/universal_transformer_basic/rec_layer_0/encdec_attention/multihead_attention/v/kernel/Initializer/random_uniform/max (Const) \r\n",
      "  universal_transformer/body/decoder/universal_transformer_basic/rec_layer_0/encdec_attention/multihead_attention/v/kernel/Initializer/random_uniform/RandomUniform (RandomUniform) \r\n",
      "  universal_transformer/body/decoder/universal_transformer_basic/rec_layer_0/encdec_attention/multihead_attention/v/kernel/Initializer/random_uniform/sub (Sub) \r\n",
      "  universal_transformer/body/decoder/universal_transformer_basic/rec_layer_0/encdec_attention/multihead_attention/v/kernel/Initializer/random_uniform/mul (Mul) \r\n",
      "  universal_transformer/body/decoder/universal_transformer_basic/rec_layer_0/encdec_attention/multihead_attention/v/kernel/Initializer/random_uniform (Add) \r\n",
      "  universal_transformer/body/decoder/universal_transformer_basic/rec_layer_0/encdec_attention/multihead_attention/v/kernel (VarHandleOp) /device:GPU:0\r\n",
      "  universal_transformer/body/decoder/universal_transformer_basic/rec_layer_0/encdec_attention/multihead_attention/v/kernel/IsInitialized/VarIsInitializedOp (VarIsInitializedOp) /device:GPU:0\r\n",
      "  universal_transformer/body/decoder/universal_transformer_basic/rec_layer_0/encdec_attention/multihead_attention/v/kernel/Assign (AssignVariableOp) /device:GPU:0\r\n",
      "  universal_transformer/body/decoder/universal_transformer_basic/rec_layer_0/encdec_attention/multihead_attention/v/kernel/Read/ReadVariableOp (ReadVariableOp) /device:GPU:0\r\n",
      "  report_uninitialized_variables/VarIsInitializedOp_39 (VarIsInitializedOp) \r\n",
      "  report_uninitialized_variables_1/VarIsInitializedOp_39 (VarIsInitializedOp) \r\n",
      "  save/AssignVariableOp_6 (AssignVariableOp) /device:GPU:0\r\n",
      "\r\n",
      "2019-07-31 06:18:16.554571: W tensorflow/core/common_runtime/colocation_graph.cc:1016] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [\r\n",
      "  /job:localhost/replica:0/task:0/device:CPU:0\r\n",
      "  /job:localhost/replica:0/task:0/device:XLA_CPU:0].\r\n",
      "See below for details of this colocation group:\r\n",
      "Colocation Debug Info:\r\n",
      "Colocation group had the following types and supported devices: \r\n",
      "Root Member(assigned_device_name_index_=-1 requested_device_name_='/device:GPU:0' assigned_device_name_='' resource_device_name_='/device:GPU:0' supported_device_types_=[CPU, XLA_CPU] possible_devices_=[]\r\n",
      "AssignVariableOp: CPU XLA_CPU \r\n",
      "RandomUniform: CPU XLA_CPU \r\n",
      "VarIsInitializedOp: CPU XLA_CPU \r\n",
      "Const: CPU XLA_CPU \r\n",
      "Mul: CPU XLA_CPU \r\n",
      "ReadVariableOp: CPU XLA_CPU \r\n",
      "Sub: CPU XLA_CPU \r\n",
      "VarHandleOp: CPU XLA_CPU \r\n",
      "Add: CPU XLA_CPU \r\n",
      "\r\n",
      "Colocation members, user-requested devices, and framework assigned devices, if any:\r\n",
      "  universal_transformer/body/decoder/universal_transformer_basic/rec_layer_0/encdec_attention/multihead_attention/output_transform/kernel/Initializer/random_uniform/shape (Const) \r\n",
      "  universal_transformer/body/decoder/universal_transformer_basic/rec_layer_0/encdec_attention/multihead_attention/output_transform/kernel/Initializer/random_uniform/min (Const) \r\n",
      "  universal_transformer/body/decoder/universal_transformer_basic/rec_layer_0/encdec_attention/multihead_attention/output_transform/kernel/Initializer/random_uniform/max (Const) \r\n",
      "  universal_transformer/body/decoder/universal_transformer_basic/rec_layer_0/encdec_attention/multihead_attention/output_transform/kernel/Initializer/random_uniform/RandomUniform (RandomUniform) \r\n",
      "  universal_transformer/body/decoder/universal_transformer_basic/rec_layer_0/encdec_attention/multihead_attention/output_transform/kernel/Initializer/random_uniform/sub (Sub) \r\n",
      "  universal_transformer/body/decoder/universal_transformer_basic/rec_layer_0/encdec_attention/multihead_attention/output_transform/kernel/Initializer/random_uniform/mul (Mul) \r\n",
      "  universal_transformer/body/decoder/universal_transformer_basic/rec_layer_0/encdec_attention/multihead_attention/output_transform/kernel/Initializer/random_uniform (Add) \r\n",
      "  universal_transformer/body/decoder/universal_transformer_basic/rec_layer_0/encdec_attention/multihead_attention/output_transform/kernel (VarHandleOp) /device:GPU:0\r\n",
      "  universal_transformer/body/decoder/universal_transformer_basic/rec_layer_0/encdec_attention/multihead_attention/output_transform/kernel/IsInitialized/VarIsInitializedOp (VarIsInitializedOp) /device:GPU:0\r\n",
      "  universal_transformer/body/decoder/universal_transformer_basic/rec_layer_0/encdec_attention/multihead_attention/output_transform/kernel/Assign (AssignVariableOp) /device:GPU:0\r\n",
      "  universal_transformer/body/decoder/universal_transformer_basic/rec_layer_0/encdec_attention/multihead_attention/output_transform/kernel/Read/ReadVariableOp (ReadVariableOp) /device:GPU:0\r\n",
      "  report_uninitialized_variables/VarIsInitializedOp_40 (VarIsInitializedOp) \r\n",
      "  report_uninitialized_variables_1/VarIsInitializedOp_40 (VarIsInitializedOp) \r\n",
      "  save/AssignVariableOp_4 (AssignVariableOp) /device:GPU:0\r\n",
      "\r\n",
      "2019-07-31 06:18:16.555116: W tensorflow/core/common_runtime/colocation_graph.cc:1016] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [\r\n",
      "  /job:localhost/replica:0/task:0/device:CPU:0\r\n",
      "  /job:localhost/replica:0/task:0/device:XLA_CPU:0].\r\n",
      "See below for details of this colocation group:\r\n",
      "Colocation Debug Info:\r\n",
      "Colocation group had the following types and supported devices: \r\n",
      "Root Member(assigned_device_name_index_=-1 requested_device_name_='/device:GPU:0' assigned_device_name_='' resource_device_name_='/device:GPU:0' supported_device_types_=[CPU, XLA_CPU] possible_devices_=[]\r\n",
      "ReadVariableOp: CPU XLA_CPU \r\n",
      "AssignVariableOp: CPU XLA_CPU \r\n",
      "VarIsInitializedOp: CPU XLA_CPU \r\n",
      "VarHandleOp: CPU XLA_CPU \r\n",
      "Const: CPU XLA_CPU \r\n",
      "Fill: CPU XLA_CPU \r\n",
      "\r\n",
      "Colocation members, user-requested devices, and framework assigned devices, if any:\r\n",
      "  universal_transformer/body/decoder/universal_transformer_basic/rec_layer_0/encdec_attention/layer_postprocess/layer_norm/layer_norm_scale/Initializer/ones/shape_as_tensor (Const) \r\n",
      "  universal_transformer/body/decoder/universal_transformer_basic/rec_layer_0/encdec_attention/layer_postprocess/layer_norm/layer_norm_scale/Initializer/ones/Const (Const) \r\n",
      "  universal_transformer/body/decoder/universal_transformer_basic/rec_layer_0/encdec_attention/layer_postprocess/layer_norm/layer_norm_scale/Initializer/ones (Fill) \r\n",
      "  universal_transformer/body/decoder/universal_transformer_basic/rec_layer_0/encdec_attention/layer_postprocess/layer_norm/layer_norm_scale (VarHandleOp) /device:GPU:0\r\n",
      "  universal_transformer/body/decoder/universal_transformer_basic/rec_layer_0/encdec_attention/layer_postprocess/layer_norm/layer_norm_scale/IsInitialized/VarIsInitializedOp (VarIsInitializedOp) /device:GPU:0\r\n",
      "  universal_transformer/body/decoder/universal_transformer_basic/rec_layer_0/encdec_attention/layer_postprocess/layer_norm/layer_norm_scale/Assign (AssignVariableOp) /device:GPU:0\r\n",
      "  universal_transformer/body/decoder/universal_transformer_basic/rec_layer_0/encdec_attention/layer_postprocess/layer_norm/layer_norm_scale/Read/ReadVariableOp (ReadVariableOp) /device:GPU:0\r\n",
      "  report_uninitialized_variables/VarIsInitializedOp_41 (VarIsInitializedOp) \r\n",
      "  report_uninitialized_variables_1/VarIsInitializedOp_41 (VarIsInitializedOp) \r\n",
      "  save/AssignVariableOp_2 (AssignVariableOp) /device:GPU:0\r\n",
      "\r\n",
      "2019-07-31 06:18:16.555550: W tensorflow/core/common_runtime/colocation_graph.cc:1016] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [\r\n",
      "  /job:localhost/replica:0/task:0/device:CPU:0\r\n",
      "  /job:localhost/replica:0/task:0/device:XLA_CPU:0].\r\n",
      "See below for details of this colocation group:\r\n",
      "Colocation Debug Info:\r\n",
      "Colocation group had the following types and supported devices: \r\n",
      "Root Member(assigned_device_name_index_=-1 requested_device_name_='/device:GPU:0' assigned_device_name_='' resource_device_name_='/device:GPU:0' supported_device_types_=[CPU, XLA_CPU] possible_devices_=[]\r\n",
      "ReadVariableOp: CPU XLA_CPU \r\n",
      "AssignVariableOp: CPU XLA_CPU \r\n",
      "VarIsInitializedOp: CPU XLA_CPU \r\n",
      "VarHandleOp: CPU XLA_CPU \r\n",
      "Const: CPU XLA_CPU \r\n",
      "Fill: CPU XLA_CPU \r\n",
      "\r\n",
      "Colocation members, user-requested devices, and framework assigned devices, if any:\r\n",
      "  universal_transformer/body/decoder/universal_transformer_basic/rec_layer_0/encdec_attention/layer_postprocess/layer_norm/layer_norm_bias/Initializer/zeros/shape_as_tensor (Const) \r\n",
      "  universal_transformer/body/decoder/universal_transformer_basic/rec_layer_0/encdec_attention/layer_postprocess/layer_norm/layer_norm_bias/Initializer/zeros/Const (Const) \r\n",
      "  universal_transformer/body/decoder/universal_transformer_basic/rec_layer_0/encdec_attention/layer_postprocess/layer_norm/layer_norm_bias/Initializer/zeros (Fill) \r\n",
      "  universal_transformer/body/decoder/universal_transformer_basic/rec_layer_0/encdec_attention/layer_postprocess/layer_norm/layer_norm_bias (VarHandleOp) /device:GPU:0\r\n",
      "  universal_transformer/body/decoder/universal_transformer_basic/rec_layer_0/encdec_attention/layer_postprocess/layer_norm/layer_norm_bias/IsInitialized/VarIsInitializedOp (VarIsInitializedOp) /device:GPU:0\r\n",
      "  universal_transformer/body/decoder/universal_transformer_basic/rec_layer_0/encdec_attention/layer_postprocess/layer_norm/layer_norm_bias/Assign (AssignVariableOp) /device:GPU:0\r\n",
      "  universal_transformer/body/decoder/universal_transformer_basic/rec_layer_0/encdec_attention/layer_postprocess/layer_norm/layer_norm_bias/Read/ReadVariableOp (ReadVariableOp) /device:GPU:0\r\n",
      "  report_uninitialized_variables/VarIsInitializedOp_42 (VarIsInitializedOp) \r\n",
      "  report_uninitialized_variables_1/VarIsInitializedOp_42 (VarIsInitializedOp) \r\n",
      "  save/AssignVariableOp_1 (AssignVariableOp) /device:GPU:0\r\n",
      "\r\n",
      "2019-07-31 06:18:16.556213: W tensorflow/core/common_runtime/colocation_graph.cc:1016] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [\r\n",
      "  /job:localhost/replica:0/task:0/device:CPU:0\r\n",
      "  /job:localhost/replica:0/task:0/device:XLA_CPU:0].\r\n",
      "See below for details of this colocation group:\r\n",
      "Colocation Debug Info:\r\n",
      "Colocation group had the following types and supported devices: \r\n",
      "Root Member(assigned_device_name_index_=-1 requested_device_name_='/device:GPU:0' assigned_device_name_='' resource_device_name_='/device:GPU:0' supported_device_types_=[CPU, XLA_CPU] possible_devices_=[]\r\n",
      "AssignVariableOp: CPU XLA_CPU \r\n",
      "RandomUniform: CPU XLA_CPU \r\n",
      "VarIsInitializedOp: CPU XLA_CPU \r\n",
      "Const: CPU XLA_CPU \r\n",
      "Mul: CPU XLA_CPU \r\n",
      "ReadVariableOp: CPU XLA_CPU \r\n",
      "Sub: CPU XLA_CPU \r\n",
      "VarHandleOp: CPU XLA_CPU \r\n",
      "Add: CPU XLA_CPU \r\n",
      "\r\n",
      "Colocation members, user-requested devices, and framework assigned devices, if any:\r\n",
      "  universal_transformer/body/decoder/universal_transformer_basic/rec_layer_0/ffn/conv1/kernel/Initializer/random_uniform/shape (Const) \r\n",
      "  universal_transformer/body/decoder/universal_transformer_basic/rec_layer_0/ffn/conv1/kernel/Initializer/random_uniform/min (Const) \r\n",
      "  universal_transformer/body/decoder/universal_transformer_basic/rec_layer_0/ffn/conv1/kernel/Initializer/random_uniform/max (Const) \r\n",
      "  universal_transformer/body/decoder/universal_transformer_basic/rec_layer_0/ffn/conv1/kernel/Initializer/random_uniform/RandomUniform (RandomUniform) \r\n",
      "  universal_transformer/body/decoder/universal_transformer_basic/rec_layer_0/ffn/conv1/kernel/Initializer/random_uniform/sub (Sub) \r\n",
      "  universal_transformer/body/decoder/universal_transformer_basic/rec_layer_0/ffn/conv1/kernel/Initializer/random_uniform/mul (Mul) \r\n",
      "  universal_transformer/body/decoder/universal_transformer_basic/rec_layer_0/ffn/conv1/kernel/Initializer/random_uniform (Add) \r\n",
      "  universal_transformer/body/decoder/universal_transformer_basic/rec_layer_0/ffn/conv1/kernel (VarHandleOp) /device:GPU:0\r\n",
      "  universal_transformer/body/decoder/universal_transformer_basic/rec_layer_0/ffn/conv1/kernel/IsInitialized/VarIsInitializedOp (VarIsInitializedOp) /device:GPU:0\r\n",
      "  universal_transformer/body/decoder/universal_transformer_basic/rec_layer_0/ffn/conv1/kernel/Assign (AssignVariableOp) /device:GPU:0\r\n",
      "  universal_transformer/body/decoder/universal_transformer_basic/rec_layer_0/ffn/conv1/kernel/Read/ReadVariableOp (ReadVariableOp) /device:GPU:0\r\n",
      "  report_uninitialized_variables/VarIsInitializedOp_43 (VarIsInitializedOp) \r\n",
      "  report_uninitialized_variables_1/VarIsInitializedOp_43 (VarIsInitializedOp) \r\n",
      "  save/AssignVariableOp_8 (AssignVariableOp) /device:GPU:0\r\n",
      "\r\n",
      "2019-07-31 06:18:16.556399: W tensorflow/core/common_runtime/colocation_graph.cc:1016] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [\r\n",
      "  /job:localhost/replica:0/task:0/device:CPU:0\r\n",
      "  /job:localhost/replica:0/task:0/device:XLA_CPU:0].\r\n",
      "See below for details of this colocation group:\r\n",
      "Colocation Debug Info:\r\n",
      "Colocation group had the following types and supported devices: \r\n",
      "Root Member(assigned_device_name_index_=-1 requested_device_name_='/device:GPU:0' assigned_device_name_='' resource_device_name_='/device:GPU:0' supported_device_types_=[CPU, XLA_CPU] possible_devices_=[]\r\n",
      "ReadVariableOp: CPU XLA_CPU \r\n",
      "AssignVariableOp: CPU XLA_CPU \r\n",
      "VarIsInitializedOp: CPU XLA_CPU \r\n",
      "VarHandleOp: CPU XLA_CPU \r\n",
      "Const: CPU XLA_CPU \r\n",
      "Fill: CPU XLA_CPU \r\n",
      "\r\n",
      "Colocation members, user-requested devices, and framework assigned devices, if any:\r\n",
      "  universal_transformer/body/decoder/universal_transformer_basic/rec_layer_0/ffn/conv1/bias/Initializer/zeros/shape_as_tensor (Const) \r\n",
      "  universal_transformer/body/decoder/universal_transformer_basic/rec_layer_0/ffn/conv1/bias/Initializer/zeros/Const (Const) \r\n",
      "  universal_transformer/body/decoder/universal_transformer_basic/rec_layer_0/ffn/conv1/bias/Initializer/zeros (Fill) \r\n",
      "  universal_transformer/body/decoder/universal_transformer_basic/rec_layer_0/ffn/conv1/bias (VarHandleOp) /device:GPU:0\r\n",
      "  universal_transformer/body/decoder/universal_transformer_basic/rec_layer_0/ffn/conv1/bias/IsInitialized/VarIsInitializedOp (VarIsInitializedOp) /device:GPU:0\r\n",
      "  universal_transformer/body/decoder/universal_transformer_basic/rec_layer_0/ffn/conv1/bias/Assign (AssignVariableOp) /device:GPU:0\r\n",
      "  universal_transformer/body/decoder/universal_transformer_basic/rec_layer_0/ffn/conv1/bias/Read/ReadVariableOp (ReadVariableOp) /device:GPU:0\r\n",
      "  report_uninitialized_variables/VarIsInitializedOp_44 (VarIsInitializedOp) \r\n",
      "  report_uninitialized_variables_1/VarIsInitializedOp_44 (VarIsInitializedOp) \r\n",
      "  save/AssignVariableOp_7 (AssignVariableOp) /device:GPU:0\r\n",
      "\r\n",
      "2019-07-31 06:18:16.556566: W tensorflow/core/common_runtime/colocation_graph.cc:1016] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [\r\n",
      "  /job:localhost/replica:0/task:0/device:CPU:0\r\n",
      "  /job:localhost/replica:0/task:0/device:XLA_CPU:0].\r\n",
      "See below for details of this colocation group:\r\n",
      "Colocation Debug Info:\r\n",
      "Colocation group had the following types and supported devices: \r\n",
      "Root Member(assigned_device_name_index_=-1 requested_device_name_='/device:GPU:0' assigned_device_name_='' resource_device_name_='/device:GPU:0' supported_device_types_=[CPU, XLA_CPU] possible_devices_=[]\r\n",
      "AssignVariableOp: CPU XLA_CPU \r\n",
      "RandomUniform: CPU XLA_CPU \r\n",
      "VarIsInitializedOp: CPU XLA_CPU \r\n",
      "Const: CPU XLA_CPU \r\n",
      "Mul: CPU XLA_CPU \r\n",
      "ReadVariableOp: CPU XLA_CPU \r\n",
      "Sub: CPU XLA_CPU \r\n",
      "VarHandleOp: CPU XLA_CPU \r\n",
      "Add: CPU XLA_CPU \r\n",
      "\r\n",
      "Colocation members, user-requested devices, and framework assigned devices, if any:\r\n",
      "  universal_transformer/body/decoder/universal_transformer_basic/rec_layer_0/ffn/conv2/kernel/Initializer/random_uniform/shape (Const) \r\n",
      "  universal_transformer/body/decoder/universal_transformer_basic/rec_layer_0/ffn/conv2/kernel/Initializer/random_uniform/min (Const) \r\n",
      "  universal_transformer/body/decoder/universal_transformer_basic/rec_layer_0/ffn/conv2/kernel/Initializer/random_uniform/max (Const) \r\n",
      "  universal_transformer/body/decoder/universal_transformer_basic/rec_layer_0/ffn/conv2/kernel/Initializer/random_uniform/RandomUniform (RandomUniform) \r\n",
      "  universal_transformer/body/decoder/universal_transformer_basic/rec_layer_0/ffn/conv2/kernel/Initializer/random_uniform/sub (Sub) \r\n",
      "  universal_transformer/body/decoder/universal_transformer_basic/rec_layer_0/ffn/conv2/kernel/Initializer/random_uniform/mul (Mul) \r\n",
      "  universal_transformer/body/decoder/universal_transformer_basic/rec_layer_0/ffn/conv2/kernel/Initializer/random_uniform (Add) \r\n",
      "  universal_transformer/body/decoder/universal_transformer_basic/rec_layer_0/ffn/conv2/kernel (VarHandleOp) /device:GPU:0\r\n",
      "  universal_transformer/body/decoder/universal_transformer_basic/rec_layer_0/ffn/conv2/kernel/IsInitialized/VarIsInitializedOp (VarIsInitializedOp) /device:GPU:0\r\n",
      "  universal_transformer/body/decoder/universal_transformer_basic/rec_layer_0/ffn/conv2/kernel/Assign (AssignVariableOp) /device:GPU:0\r\n",
      "  universal_transformer/body/decoder/universal_transformer_basic/rec_layer_0/ffn/conv2/kernel/Read/ReadVariableOp (ReadVariableOp) /device:GPU:0\r\n",
      "  report_uninitialized_variables/VarIsInitializedOp_45 (VarIsInitializedOp) \r\n",
      "  report_uninitialized_variables_1/VarIsInitializedOp_45 (VarIsInitializedOp) \r\n",
      "  save/AssignVariableOp_10 (AssignVariableOp) /device:GPU:0\r\n",
      "\r\n",
      "2019-07-31 06:18:16.556679: W tensorflow/core/common_runtime/colocation_graph.cc:1016] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [\r\n",
      "  /job:localhost/replica:0/task:0/device:CPU:0\r\n",
      "  /job:localhost/replica:0/task:0/device:XLA_CPU:0].\r\n",
      "See below for details of this colocation group:\r\n",
      "Colocation Debug Info:\r\n",
      "Colocation group had the following types and supported devices: \r\n",
      "Root Member(assigned_device_name_index_=-1 requested_device_name_='/device:GPU:0' assigned_device_name_='' resource_device_name_='/device:GPU:0' supported_device_types_=[CPU, XLA_CPU] possible_devices_=[]\r\n",
      "ReadVariableOp: CPU XLA_CPU \r\n",
      "AssignVariableOp: CPU XLA_CPU \r\n",
      "VarIsInitializedOp: CPU XLA_CPU \r\n",
      "VarHandleOp: CPU XLA_CPU \r\n",
      "Const: CPU XLA_CPU \r\n",
      "Fill: CPU XLA_CPU \r\n",
      "\r\n",
      "Colocation members, user-requested devices, and framework assigned devices, if any:\r\n",
      "  universal_transformer/body/decoder/universal_transformer_basic/rec_layer_0/ffn/conv2/bias/Initializer/zeros/shape_as_tensor (Const) \r\n",
      "  universal_transformer/body/decoder/universal_transformer_basic/rec_layer_0/ffn/conv2/bias/Initializer/zeros/Const (Const) \r\n",
      "  universal_transformer/body/decoder/universal_transformer_basic/rec_layer_0/ffn/conv2/bias/Initializer/zeros (Fill) \r\n",
      "  universal_transformer/body/decoder/universal_transformer_basic/rec_layer_0/ffn/conv2/bias (VarHandleOp) /device:GPU:0\r\n",
      "  universal_transformer/body/decoder/universal_transformer_basic/rec_layer_0/ffn/conv2/bias/IsInitialized/VarIsInitializedOp (VarIsInitializedOp) /device:GPU:0\r\n",
      "  universal_transformer/body/decoder/universal_transformer_basic/rec_layer_0/ffn/conv2/bias/Assign (AssignVariableOp) /device:GPU:0\r\n",
      "  universal_transformer/body/decoder/universal_transformer_basic/rec_layer_0/ffn/conv2/bias/Read/ReadVariableOp (ReadVariableOp) /device:GPU:0\r\n",
      "  report_uninitialized_variables/VarIsInitializedOp_46 (VarIsInitializedOp) \r\n",
      "  report_uninitialized_variables_1/VarIsInitializedOp_46 (VarIsInitializedOp) \r\n",
      "  save/AssignVariableOp_9 (AssignVariableOp) /device:GPU:0\r\n",
      "\r\n",
      "2019-07-31 06:18:16.556901: W tensorflow/core/common_runtime/colocation_graph.cc:1016] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [\r\n",
      "  /job:localhost/replica:0/task:0/device:CPU:0\r\n",
      "  /job:localhost/replica:0/task:0/device:XLA_CPU:0].\r\n",
      "See below for details of this colocation group:\r\n",
      "Colocation Debug Info:\r\n",
      "Colocation group had the following types and supported devices: \r\n",
      "Root Member(assigned_device_name_index_=-1 requested_device_name_='/device:GPU:0' assigned_device_name_='' resource_device_name_='/device:GPU:0' supported_device_types_=[CPU, XLA_CPU] possible_devices_=[]\r\n",
      "ReadVariableOp: CPU XLA_CPU \r\n",
      "AssignVariableOp: CPU XLA_CPU \r\n",
      "VarIsInitializedOp: CPU XLA_CPU \r\n",
      "VarHandleOp: CPU XLA_CPU \r\n",
      "Const: CPU XLA_CPU \r\n",
      "Fill: CPU XLA_CPU \r\n",
      "\r\n",
      "Colocation members, user-requested devices, and framework assigned devices, if any:\r\n",
      "  universal_transformer/body/decoder/universal_transformer_basic/rec_layer_0/ffn/layer_postprocess/layer_norm/layer_norm_scale/Initializer/ones/shape_as_tensor (Const) \r\n",
      "  universal_transformer/body/decoder/universal_transformer_basic/rec_layer_0/ffn/layer_postprocess/layer_norm/layer_norm_scale/Initializer/ones/Const (Const) \r\n",
      "  universal_transformer/body/decoder/universal_transformer_basic/rec_layer_0/ffn/layer_postprocess/layer_norm/layer_norm_scale/Initializer/ones (Fill) \r\n",
      "  universal_transformer/body/decoder/universal_transformer_basic/rec_layer_0/ffn/layer_postprocess/layer_norm/layer_norm_scale (VarHandleOp) /device:GPU:0\r\n",
      "  universal_transformer/body/decoder/universal_transformer_basic/rec_layer_0/ffn/layer_postprocess/layer_norm/layer_norm_scale/IsInitialized/VarIsInitializedOp (VarIsInitializedOp) /device:GPU:0\r\n",
      "  universal_transformer/body/decoder/universal_transformer_basic/rec_layer_0/ffn/layer_postprocess/layer_norm/layer_norm_scale/Assign (AssignVariableOp) /device:GPU:0\r\n",
      "  universal_transformer/body/decoder/universal_transformer_basic/rec_layer_0/ffn/layer_postprocess/layer_norm/layer_norm_scale/Read/ReadVariableOp (ReadVariableOp) /device:GPU:0\r\n",
      "  report_uninitialized_variables/VarIsInitializedOp_47 (VarIsInitializedOp) \r\n",
      "  report_uninitialized_variables_1/VarIsInitializedOp_47 (VarIsInitializedOp) \r\n",
      "  save/AssignVariableOp_12 (AssignVariableOp) /device:GPU:0\r\n",
      "\r\n",
      "2019-07-31 06:18:16.557045: W tensorflow/core/common_runtime/colocation_graph.cc:1016] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [\r\n",
      "  /job:localhost/replica:0/task:0/device:CPU:0\r\n",
      "  /job:localhost/replica:0/task:0/device:XLA_CPU:0].\r\n",
      "See below for details of this colocation group:\r\n",
      "Colocation Debug Info:\r\n",
      "Colocation group had the following types and supported devices: \r\n",
      "Root Member(assigned_device_name_index_=-1 requested_device_name_='/device:GPU:0' assigned_device_name_='' resource_device_name_='/device:GPU:0' supported_device_types_=[CPU, XLA_CPU] possible_devices_=[]\r\n",
      "ReadVariableOp: CPU XLA_CPU \r\n",
      "AssignVariableOp: CPU XLA_CPU \r\n",
      "VarIsInitializedOp: CPU XLA_CPU \r\n",
      "VarHandleOp: CPU XLA_CPU \r\n",
      "Const: CPU XLA_CPU \r\n",
      "Fill: CPU XLA_CPU \r\n",
      "\r\n",
      "Colocation members, user-requested devices, and framework assigned devices, if any:\r\n",
      "  universal_transformer/body/decoder/universal_transformer_basic/rec_layer_0/ffn/layer_postprocess/layer_norm/layer_norm_bias/Initializer/zeros/shape_as_tensor (Const) \r\n",
      "  universal_transformer/body/decoder/universal_transformer_basic/rec_layer_0/ffn/layer_postprocess/layer_norm/layer_norm_bias/Initializer/zeros/Const (Const) \r\n",
      "  universal_transformer/body/decoder/universal_transformer_basic/rec_layer_0/ffn/layer_postprocess/layer_norm/layer_norm_bias/Initializer/zeros (Fill) \r\n",
      "  universal_transformer/body/decoder/universal_transformer_basic/rec_layer_0/ffn/layer_postprocess/layer_norm/layer_norm_bias (VarHandleOp) /device:GPU:0\r\n",
      "  universal_transformer/body/decoder/universal_transformer_basic/rec_layer_0/ffn/layer_postprocess/layer_norm/layer_norm_bias/IsInitialized/VarIsInitializedOp (VarIsInitializedOp) /device:GPU:0\r\n",
      "  universal_transformer/body/decoder/universal_transformer_basic/rec_layer_0/ffn/layer_postprocess/layer_norm/layer_norm_bias/Assign (AssignVariableOp) /device:GPU:0\r\n",
      "  universal_transformer/body/decoder/universal_transformer_basic/rec_layer_0/ffn/layer_postprocess/layer_norm/layer_norm_bias/Read/ReadVariableOp (ReadVariableOp) /device:GPU:0\r\n",
      "  report_uninitialized_variables/VarIsInitializedOp_48 (VarIsInitializedOp) \r\n",
      "  report_uninitialized_variables_1/VarIsInitializedOp_48 (VarIsInitializedOp) \r\n",
      "  save/AssignVariableOp_11 (AssignVariableOp) /device:GPU:0\r\n",
      "\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-07-31 06:18:16.678634: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.\n",
      "I0731 06:18:17.083458 139690170451776 session_manager.py:500] Running local_init_op.\n",
      "I0731 06:18:17.138101 139690170451776 session_manager.py:502] Done running local_init_op.\n",
      "W0731 06:18:17.258200 139690170451776 deprecation.py:323] From /home/arnoldyb/anaconda3/lib/python3.7/site-packages/tensorflow/python/training/monitored_session.py:875: start_queue_runners (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "I0731 06:22:19.547268 139690170451776 decoding.py:332] BEAM 0:\n",
      "I0731 06:22:19.551424 139690170451776 decoding.py:152] Inference results INPUT: ON THE WALL OF AN EXHIBITION ROOM at the Pierpont Morgan Library is a framed assortment of composers' visiting cards, simple rectangular slips of stiff paper with names imprinted. One is a relic of a visit by Nikolai Rimsky-Korsakov; another, in impossibly florid script, announces Franz Liszt. A short note by Igor Stravinsky is scribbled around the stern lettering of his name. My favorite card is Franz Joseph Haydn's, used when he had achieved the status of elder statesman; alongside his name is a melody from one of his songs: \"Gone is all my strength,/ old and weak am I.\" What an endearingly bold proclamation of humility and mortality! These cards are part of a new exhibition, \"Auld Acquaintances,\" which draws from an imposing collection of musical scores and objects assembled over the last 65 years by James J. Fuld, a lawyer, and acquired recently by the library. The Morgan is already home to important collections of autograph manuscripts, but this acquisition is different. Its 10,000 items include the largest private collection of first editions of musical scores in the world, along with posters, recordings, programs, piano rolls, medals, bookplates, librettos, tickets, stamps, batons, porcelain objects and, in Mr. Fuld's words, \"other ephemera of historical note.\" If a manuscript provides a window on the private realm of the composer at work, first editions are the composer's public traces. \"They document works as they first saw the light of day,\" J. Rigbie Turner, the curator of music manuscripts and books at the Morgan, writes in the catalogue. And the ephemera add to the impression of music in a public marketplace. Many of the 200 objects on display (through Aug. 27) may be considered elaborate calling cards, left by composers or their agents for the pleasure of others.\n",
      "I0731 06:22:19.552370 139690170451776 decoding.py:167] Inference results OUTPUT: \n",
      "I0731 06:22:19.552573 139690170451776 decoding.py:169] Inference results TARGET: Composers Come Calling, Leaving Scores and Trinkets\n",
      "I0731 06:22:19.552774 139690170451776 decoding.py:332] BEAM 1:\n",
      "I0731 06:22:19.557425 139690170451776 decoding.py:152] Inference results INPUT: ON THE WALL OF AN EXHIBITION ROOM at the Pierpont Morgan Library is a framed assortment of composers' visiting cards, simple rectangular slips of stiff paper with names imprinted. One is a relic of a visit by Nikolai Rimsky-Korsakov; another, in impossibly florid script, announces Franz Liszt. A short note by Igor Stravinsky is scribbled around the stern lettering of his name. My favorite card is Franz Joseph Haydn's, used when he had achieved the status of elder statesman; alongside his name is a melody from one of his songs: \"Gone is all my strength,/ old and weak am I.\" What an endearingly bold proclamation of humility and mortality! These cards are part of a new exhibition, \"Auld Acquaintances,\" which draws from an imposing collection of musical scores and objects assembled over the last 65 years by James J. Fuld, a lawyer, and acquired recently by the library. The Morgan is already home to important collections of autograph manuscripts, but this acquisition is different. Its 10,000 items include the largest private collection of first editions of musical scores in the world, along with posters, recordings, programs, piano rolls, medals, bookplates, librettos, tickets, stamps, batons, porcelain objects and, in Mr. Fuld's words, \"other ephemera of historical note.\" If a manuscript provides a window on the private realm of the composer at work, first editions are the composer's public traces. \"They document works as they first saw the light of day,\" J. Rigbie Turner, the curator of music manuscripts and books at the Morgan, writes in the catalogue. And the ephemera add to the impression of music in a public marketplace. Many of the 200 objects on display (through Aug. 27) may be considered elaborate calling cards, left by composers or their agents for the pleasure of others.\n",
      "I0731 06:22:19.557965 139690170451776 decoding.py:167] Inference results OUTPUT: \n",
      "I0731 06:22:19.558144 139690170451776 decoding.py:169] Inference results TARGET: Composers Come Calling, Leaving Scores and Trinkets\n",
      "I0731 06:22:19.558253 139690170451776 decoding.py:332] BEAM 2:\n",
      "I0731 06:22:19.562151 139690170451776 decoding.py:152] Inference results INPUT: ON THE WALL OF AN EXHIBITION ROOM at the Pierpont Morgan Library is a framed assortment of composers' visiting cards, simple rectangular slips of stiff paper with names imprinted. One is a relic of a visit by Nikolai Rimsky-Korsakov; another, in impossibly florid script, announces Franz Liszt. A short note by Igor Stravinsky is scribbled around the stern lettering of his name. My favorite card is Franz Joseph Haydn's, used when he had achieved the status of elder statesman; alongside his name is a melody from one of his songs: \"Gone is all my strength,/ old and weak am I.\" What an endearingly bold proclamation of humility and mortality! These cards are part of a new exhibition, \"Auld Acquaintances,\" which draws from an imposing collection of musical scores and objects assembled over the last 65 years by James J. Fuld, a lawyer, and acquired recently by the library. The Morgan is already home to important collections of autograph manuscripts, but this acquisition is different. Its 10,000 items include the largest private collection of first editions of musical scores in the world, along with posters, recordings, programs, piano rolls, medals, bookplates, librettos, tickets, stamps, batons, porcelain objects and, in Mr. Fuld's words, \"other ephemera of historical note.\" If a manuscript provides a window on the private realm of the composer at work, first editions are the composer's public traces. \"They document works as they first saw the light of day,\" J. Rigbie Turner, the curator of music manuscripts and books at the Morgan, writes in the catalogue. And the ephemera add to the impression of music in a public marketplace. Many of the 200 objects on display (through Aug. 27) may be considered elaborate calling cards, left by composers or their agents for the pleasure of others.\n",
      "I0731 06:22:19.562509 139690170451776 decoding.py:167] Inference results OUTPUT: s\n",
      "I0731 06:22:19.562576 139690170451776 decoding.py:169] Inference results TARGET: Composers Come Calling, Leaving Scores and Trinkets\n",
      "I0731 06:22:19.562742 139690170451776 decoding.py:332] BEAM 0:\n",
      "I0731 06:22:19.564651 139690170451776 decoding.py:152] Inference results INPUT: ROSALYN YALOW  Nobel Laureate:  Her Life and Work in Medicine.  By Eugene Straus.  Plenum, $26.95. In 1978, a year after winning the Nobel Prize, Rosalyn Sussman Yalow was called ''a Madame Curie from the Bronx.'' Only the second woman ever to win the prize for medicine, she identified closely with Curie, the ideal scientist, wife and mother, three roles in which she also sought to excel. In this biographical memoir, Eugene Straus, a longtime friend and colleague, pays tribute to an extraordinary woman. Yalow emerges from these pages as brilliant, ambitious and driven in her professional life, rigid, humorless and cold-blooded on a personal level. According to her biographer, Yalow believes that women scientists should marry, rear children, cook and clean in order to be fulfilled; while pursuing her career, she had a son and daughter. Outside her family, though, Yalow could appear unfeeling; when Solomon Berson, the dazzling colleague with whom she shared dozens of important discoveries and prizes, died suddenly in 1972, her public display of grief surprised several onlookers. Five years later, she achieved the Nobel -- to universal acclaim if not universal affection. Lynn Karpen\n",
      "I0731 06:22:19.565169 139690170451776 decoding.py:167] Inference results OUTPUT: \n",
      "I0731 06:22:19.565257 139690170451776 decoding.py:169] Inference results TARGET: BOOKS IN BRIEF: NONFICTION\n",
      "I0731 06:22:19.565313 139690170451776 decoding.py:332] BEAM 1:\n",
      "I0731 06:22:19.568384 139690170451776 decoding.py:152] Inference results INPUT: ROSALYN YALOW  Nobel Laureate:  Her Life and Work in Medicine.  By Eugene Straus.  Plenum, $26.95. In 1978, a year after winning the Nobel Prize, Rosalyn Sussman Yalow was called ''a Madame Curie from the Bronx.'' Only the second woman ever to win the prize for medicine, she identified closely with Curie, the ideal scientist, wife and mother, three roles in which she also sought to excel. In this biographical memoir, Eugene Straus, a longtime friend and colleague, pays tribute to an extraordinary woman. Yalow emerges from these pages as brilliant, ambitious and driven in her professional life, rigid, humorless and cold-blooded on a personal level. According to her biographer, Yalow believes that women scientists should marry, rear children, cook and clean in order to be fulfilled; while pursuing her career, she had a son and daughter. Outside her family, though, Yalow could appear unfeeling; when Solomon Berson, the dazzling colleague with whom she shared dozens of important discoveries and prizes, died suddenly in 1972, her public display of grief surprised several onlookers. Five years later, she achieved the Nobel -- to universal acclaim if not universal affection. Lynn Karpen\n",
      "I0731 06:22:19.568799 139690170451776 decoding.py:167] Inference results OUTPUT: \n",
      "I0731 06:22:19.568939 139690170451776 decoding.py:169] Inference results TARGET: BOOKS IN BRIEF: NONFICTION\n",
      "I0731 06:22:19.569036 139690170451776 decoding.py:332] BEAM 2:\n",
      "I0731 06:22:19.572884 139690170451776 decoding.py:152] Inference results INPUT: ROSALYN YALOW  Nobel Laureate:  Her Life and Work in Medicine.  By Eugene Straus.  Plenum, $26.95. In 1978, a year after winning the Nobel Prize, Rosalyn Sussman Yalow was called ''a Madame Curie from the Bronx.'' Only the second woman ever to win the prize for medicine, she identified closely with Curie, the ideal scientist, wife and mother, three roles in which she also sought to excel. In this biographical memoir, Eugene Straus, a longtime friend and colleague, pays tribute to an extraordinary woman. Yalow emerges from these pages as brilliant, ambitious and driven in her professional life, rigid, humorless and cold-blooded on a personal level. According to her biographer, Yalow believes that women scientists should marry, rear children, cook and clean in order to be fulfilled; while pursuing her career, she had a son and daughter. Outside her family, though, Yalow could appear unfeeling; when Solomon Berson, the dazzling colleague with whom she shared dozens of important discoveries and prizes, died suddenly in 1972, her public display of grief surprised several onlookers. Five years later, she achieved the Nobel -- to universal acclaim if not universal affection. Lynn Karpen\n",
      "I0731 06:22:19.573278 139690170451776 decoding.py:167] Inference results OUTPUT: s\n",
      "I0731 06:22:19.573411 139690170451776 decoding.py:169] Inference results TARGET: BOOKS IN BRIEF: NONFICTION\n",
      "I0731 06:22:19.573655 139690170451776 decoding.py:332] BEAM 0:\n",
      "I0731 06:22:19.577616 139690170451776 decoding.py:152] Inference results INPUT: A YEAR ago Alex Kamnitsis, 27, an executive assistant at a film production company in Manhattan, adopted a hair style he calls a modern version of the Mohawk. He was looking to make a statement: despite his corporate trappings he is a person with a little edge. This summer, when he asked his stylist at the Oscar Bond salon in SoHo for the same cut, closely buzzed along the sides and a strip of long hair on top, Mr. Kamnitsis discovered that the Mohawk, like so many other badges of anarchy, had gone mainstream. ''When I was getting my hair cut, there was a woman next to me with her son, a little kid, who was asking for a Mohawk,'' Mr. Kamnitsis said. Perhaps it was the wave of stylish men in New York and Los Angeles in the late 1990's who gelled their hair into luminous crests known as fauxhawks who paved the way for more extreme versions as a popular summer look. Or perhaps the Mohawk has re-entered the vocabulary of stylists who operate far from the barbershops near St. Marks Place, the city's historic thoroughfare for alternative style, thanks to the well-documented and ever-evolving Mohawk of one man, Maddox Jolie, 4.\n",
      "I0731 06:22:19.578050 139690170451776 decoding.py:167] Inference results OUTPUT: \n",
      "I0731 06:22:19.578184 139690170451776 decoding.py:169] Inference results TARGET: The Mohawk Becomes, Well, Cute\n",
      "I0731 06:22:19.578279 139690170451776 decoding.py:332] BEAM 1:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I0731 06:22:19.582183 139690170451776 decoding.py:152] Inference results INPUT: A YEAR ago Alex Kamnitsis, 27, an executive assistant at a film production company in Manhattan, adopted a hair style he calls a modern version of the Mohawk. He was looking to make a statement: despite his corporate trappings he is a person with a little edge. This summer, when he asked his stylist at the Oscar Bond salon in SoHo for the same cut, closely buzzed along the sides and a strip of long hair on top, Mr. Kamnitsis discovered that the Mohawk, like so many other badges of anarchy, had gone mainstream. ''When I was getting my hair cut, there was a woman next to me with her son, a little kid, who was asking for a Mohawk,'' Mr. Kamnitsis said. Perhaps it was the wave of stylish men in New York and Los Angeles in the late 1990's who gelled their hair into luminous crests known as fauxhawks who paved the way for more extreme versions as a popular summer look. Or perhaps the Mohawk has re-entered the vocabulary of stylists who operate far from the barbershops near St. Marks Place, the city's historic thoroughfare for alternative style, thanks to the well-documented and ever-evolving Mohawk of one man, Maddox Jolie, 4.\r\n",
      "I0731 06:22:19.582597 139690170451776 decoding.py:167] Inference results OUTPUT: \r\n",
      "I0731 06:22:19.582749 139690170451776 decoding.py:169] Inference results TARGET: The Mohawk Becomes, Well, Cute\r\n",
      "I0731 06:22:19.582855 139690170451776 decoding.py:332] BEAM 2:\r\n",
      "I0731 06:22:19.586707 139690170451776 decoding.py:152] Inference results INPUT: A YEAR ago Alex Kamnitsis, 27, an executive assistant at a film production company in Manhattan, adopted a hair style he calls a modern version of the Mohawk. He was looking to make a statement: despite his corporate trappings he is a person with a little edge. This summer, when he asked his stylist at the Oscar Bond salon in SoHo for the same cut, closely buzzed along the sides and a strip of long hair on top, Mr. Kamnitsis discovered that the Mohawk, like so many other badges of anarchy, had gone mainstream. ''When I was getting my hair cut, there was a woman next to me with her son, a little kid, who was asking for a Mohawk,'' Mr. Kamnitsis said. Perhaps it was the wave of stylish men in New York and Los Angeles in the late 1990's who gelled their hair into luminous crests known as fauxhawks who paved the way for more extreme versions as a popular summer look. Or perhaps the Mohawk has re-entered the vocabulary of stylists who operate far from the barbershops near St. Marks Place, the city's historic thoroughfare for alternative style, thanks to the well-documented and ever-evolving Mohawk of one man, Maddox Jolie, 4.\r\n",
      "I0731 06:22:19.587106 139690170451776 decoding.py:167] Inference results OUTPUT: s\r\n",
      "I0731 06:22:19.587236 139690170451776 decoding.py:169] Inference results TARGET: The Mohawk Becomes, Well, Cute\r\n",
      "I0731 06:22:19.587472 139690170451776 decoding.py:332] BEAM 0:\r\n",
      "I0731 06:22:19.591533 139690170451776 decoding.py:152] Inference results INPUT: Dorothea Poggi marched past the muddy cricket fields and weathered picnic benches to a little stretch of beach in Ferry Point Park in the Bronx. She padded in sneakers on the damp sand littered with coconut shells, synthetic flowers and wet coils of golden yellow fabric. Plunging a hand between the reeds, she picked up a water-faded picture of a goddess with four arms and raven black hair. ''Look, this is her,'' said Ms. Poggi, 55, a signmaker and the founder of the Ferry Point Park West Coalition, a community group. ''I think the ritual is beautiful. I just wish they would stuff it in the garbage pail.'' The picture is of Mother Ganga, the Hindu goddess of the river, and the ritual in question involves offerings to her that are made on the banks of Westchester Creek. According to Pandit Vishnu Sukul, the priest of the 500-member Vishnu Mandir temple in the Unionport section, the ritual, which is held year round, involves floating yards of yellow fabric topped with offerings of fruit, flowers, incense and money while prayers are said. In Ferry Point Park, the offering material, which also sometimes includes pictures like the one Ms. Poggi found, is often left behind.\r\n",
      "I0731 06:22:19.591963 139690170451776 decoding.py:167] Inference results OUTPUT: \r\n",
      "I0731 06:22:19.592095 139690170451776 decoding.py:169] Inference results TARGET: Offerings to Mother Ganga, Worries About Mother Nature\r\n",
      "I0731 06:22:19.592189 139690170451776 decoding.py:332] BEAM 1:\r\n",
      "I0731 06:22:19.596134 139690170451776 decoding.py:152] Inference results INPUT: Dorothea Poggi marched past the muddy cricket fields and weathered picnic benches to a little stretch of beach in Ferry Point Park in the Bronx. She padded in sneakers on the damp sand littered with coconut shells, synthetic flowers and wet coils of golden yellow fabric. Plunging a hand between the reeds, she picked up a water-faded picture of a goddess with four arms and raven black hair. ''Look, this is her,'' said Ms. Poggi, 55, a signmaker and the founder of the Ferry Point Park West Coalition, a community group. ''I think the ritual is beautiful. I just wish they would stuff it in the garbage pail.'' The picture is of Mother Ganga, the Hindu goddess of the river, and the ritual in question involves offerings to her that are made on the banks of Westchester Creek. According to Pandit Vishnu Sukul, the priest of the 500-member Vishnu Mandir temple in the Unionport section, the ritual, which is held year round, involves floating yards of yellow fabric topped with offerings of fruit, flowers, incense and money while prayers are said. In Ferry Point Park, the offering material, which also sometimes includes pictures like the one Ms. Poggi found, is often left behind.\r\n",
      "I0731 06:22:19.596554 139690170451776 decoding.py:167] Inference results OUTPUT: \r\n",
      "I0731 06:22:19.596681 139690170451776 decoding.py:169] Inference results TARGET: Offerings to Mother Ganga, Worries About Mother Nature\r\n",
      "I0731 06:22:19.596836 139690170451776 decoding.py:332] BEAM 2:\r\n",
      "I0731 06:22:19.601645 139690170451776 decoding.py:152] Inference results INPUT: Dorothea Poggi marched past the muddy cricket fields and weathered picnic benches to a little stretch of beach in Ferry Point Park in the Bronx. She padded in sneakers on the damp sand littered with coconut shells, synthetic flowers and wet coils of golden yellow fabric. Plunging a hand between the reeds, she picked up a water-faded picture of a goddess with four arms and raven black hair. ''Look, this is her,'' said Ms. Poggi, 55, a signmaker and the founder of the Ferry Point Park West Coalition, a community group. ''I think the ritual is beautiful. I just wish they would stuff it in the garbage pail.'' The picture is of Mother Ganga, the Hindu goddess of the river, and the ritual in question involves offerings to her that are made on the banks of Westchester Creek. According to Pandit Vishnu Sukul, the priest of the 500-member Vishnu Mandir temple in the Unionport section, the ritual, which is held year round, involves floating yards of yellow fabric topped with offerings of fruit, flowers, incense and money while prayers are said. In Ferry Point Park, the offering material, which also sometimes includes pictures like the one Ms. Poggi found, is often left behind.\r\n",
      "I0731 06:22:19.602235 139690170451776 decoding.py:167] Inference results OUTPUT: s\r\n",
      "I0731 06:22:19.602428 139690170451776 decoding.py:169] Inference results TARGET: Offerings to Mother Ganga, Worries About Mother Nature\r\n",
      "I0731 06:22:19.602747 139690170451776 decoding.py:332] BEAM 0:\r\n",
      "I0731 06:22:19.606921 139690170451776 decoding.py:152] Inference results INPUT: THE MANHATTAN HUNT CLUB  By John Saul  Ballantine  ($25.95, hardcover) Pushing her wire shopping cart, Tillie walked slowly along the paths of Riverside Park. She wasn't in a hurry -- hadn't ever been in a hurry, really. Except when she was young. She'd been in a hurry then. Too much of a hurry. She was going to be an actress, and she'd come to New York when she was 18, right out of high school. She got a job as a waitress and started going to auditions, but nobody gave her more than a walk-on. But she kep trying, always certain that in just another year she'd finally get her break. At first it had been fun -- she had friends who wanted to be actors and actresses, too, and some of them had actually gotten jobs. One of them was on a soap opera now -- in fact, Tillie still saw him sometimes when he and his friends from the show ate picnic lunches in the park. Of course, she never spoke to him, and he'd never recognized her, and that was all right.\r\n",
      "I0731 06:22:19.607306 139690170451776 decoding.py:167] Inference results OUTPUT: \r\n",
      "I0731 06:22:19.607456 139690170451776 decoding.py:169] Inference results TARGET: Beginnings And Endings Of City Lives\r\n",
      "I0731 06:22:19.607560 139690170451776 decoding.py:332] BEAM 1:\r\n",
      "I0731 06:22:19.611243 139690170451776 decoding.py:152] Inference results INPUT: THE MANHATTAN HUNT CLUB  By John Saul  Ballantine  ($25.95, hardcover) Pushing her wire shopping cart, Tillie walked slowly along the paths of Riverside Park. She wasn't in a hurry -- hadn't ever been in a hurry, really. Except when she was young. She'd been in a hurry then. Too much of a hurry. She was going to be an actress, and she'd come to New York when she was 18, right out of high school. She got a job as a waitress and started going to auditions, but nobody gave her more than a walk-on. But she kep trying, always certain that in just another year she'd finally get her break. At first it had been fun -- she had friends who wanted to be actors and actresses, too, and some of them had actually gotten jobs. One of them was on a soap opera now -- in fact, Tillie still saw him sometimes when he and his friends from the show ate picnic lunches in the park. Of course, she never spoke to him, and he'd never recognized her, and that was all right.\r\n",
      "I0731 06:22:19.611644 139690170451776 decoding.py:167] Inference results OUTPUT: \r\n",
      "I0731 06:22:19.611819 139690170451776 decoding.py:169] Inference results TARGET: Beginnings And Endings Of City Lives\r\n",
      "I0731 06:22:19.611926 139690170451776 decoding.py:332] BEAM 2:\r\n",
      "I0731 06:22:19.615512 139690170451776 decoding.py:152] Inference results INPUT: THE MANHATTAN HUNT CLUB  By John Saul  Ballantine  ($25.95, hardcover) Pushing her wire shopping cart, Tillie walked slowly along the paths of Riverside Park. She wasn't in a hurry -- hadn't ever been in a hurry, really. Except when she was young. She'd been in a hurry then. Too much of a hurry. She was going to be an actress, and she'd come to New York when she was 18, right out of high school. She got a job as a waitress and started going to auditions, but nobody gave her more than a walk-on. But she kep trying, always certain that in just another year she'd finally get her break. At first it had been fun -- she had friends who wanted to be actors and actresses, too, and some of them had actually gotten jobs. One of them was on a soap opera now -- in fact, Tillie still saw him sometimes when he and his friends from the show ate picnic lunches in the park. Of course, she never spoke to him, and he'd never recognized her, and that was all right.\r\n",
      "I0731 06:22:19.615922 139690170451776 decoding.py:167] Inference results OUTPUT: s\r\n",
      "I0731 06:22:19.616072 139690170451776 decoding.py:169] Inference results TARGET: Beginnings And Endings Of City Lives\r\n",
      "I0731 06:22:19.616321 139690170451776 decoding.py:332] BEAM 0:\r\n",
      "I0731 06:22:19.620653 139690170451776 decoding.py:152] Inference results INPUT: Suzanne Marie Mitchell, a daughter of M. Lois Mitchell of Wynnewood, Pa., and the late Robert J. Mitchell, was married yesterday to Marco Augusto Parillo, a son of Marisa and Louis F. Parillo of Water Mill, N.Y. The Rev. Donald E. Leighton performed the ceremony at St. John Vianney Roman Catholic Church in Gladwyne, Pa. Mrs. Parillo, 38, is the associate general counsel at Philadelphia Newspapers Inc., which publishes The Philadelphia Inquirer and The Philadelphia Daily News. She graduated from Villanova and received her law degree from Notre Dame. Her mother manages a maternity store, A Pea in the Pod, in Haverford, Pa. The bride's father was a senior vice president who oversaw commercial lending and trust activities in Philadelphia for the PNC Financial Services Group. Mr. Parillo, 43, is a consultant in the Philadelphia office of I.B.M. Global Services, the e-business consulting division of the computer company. He graduated from Johns Hopkins University and received an M.B.A. from Duke. His mother, who is retired, taught French at St. Peter's by-the-Sea, an Episcopal elementary school in Bay Shore, N.Y. His father, also retired, was a contracts manager for the Fairchild Republic Company, the former aircraft manufacturer in Farmingdale, N.Y.\r\n",
      "I0731 06:22:19.621024 139690170451776 decoding.py:167] Inference results OUTPUT: \r\n",
      "I0731 06:22:19.621167 139690170451776 decoding.py:169] Inference results TARGET: Suzanne Mitchell, Marco Parillo\r\n",
      "I0731 06:22:19.621290 139690170451776 decoding.py:332] BEAM 1:\r\n",
      "I0731 06:22:19.625556 139690170451776 decoding.py:152] Inference results INPUT: Suzanne Marie Mitchell, a daughter of M. Lois Mitchell of Wynnewood, Pa., and the late Robert J. Mitchell, was married yesterday to Marco Augusto Parillo, a son of Marisa and Louis F. Parillo of Water Mill, N.Y. The Rev. Donald E. Leighton performed the ceremony at St. John Vianney Roman Catholic Church in Gladwyne, Pa. Mrs. Parillo, 38, is the associate general counsel at Philadelphia Newspapers Inc., which publishes The Philadelphia Inquirer and The Philadelphia Daily News. She graduated from Villanova and received her law degree from Notre Dame. Her mother manages a maternity store, A Pea in the Pod, in Haverford, Pa. The bride's father was a senior vice president who oversaw commercial lending and trust activities in Philadelphia for the PNC Financial Services Group. Mr. Parillo, 43, is a consultant in the Philadelphia office of I.B.M. Global Services, the e-business consulting division of the computer company. He graduated from Johns Hopkins University and received an M.B.A. from Duke. His mother, who is retired, taught French at St. Peter's by-the-Sea, an Episcopal elementary school in Bay Shore, N.Y. His father, also retired, was a contracts manager for the Fairchild Republic Company, the former aircraft manufacturer in Farmingdale, N.Y.\r\n",
      "I0731 06:22:19.625976 139690170451776 decoding.py:167] Inference results OUTPUT: \r\n",
      "I0731 06:22:19.626136 139690170451776 decoding.py:169] Inference results TARGET: Suzanne Mitchell, Marco Parillo\r\n",
      "I0731 06:22:19.626243 139690170451776 decoding.py:332] BEAM 2:\r\n",
      "I0731 06:22:19.630881 139690170451776 decoding.py:152] Inference results INPUT: Suzanne Marie Mitchell, a daughter of M. Lois Mitchell of Wynnewood, Pa., and the late Robert J. Mitchell, was married yesterday to Marco Augusto Parillo, a son of Marisa and Louis F. Parillo of Water Mill, N.Y. The Rev. Donald E. Leighton performed the ceremony at St. John Vianney Roman Catholic Church in Gladwyne, Pa. Mrs. Parillo, 38, is the associate general counsel at Philadelphia Newspapers Inc., which publishes The Philadelphia Inquirer and The Philadelphia Daily News. She graduated from Villanova and received her law degree from Notre Dame. Her mother manages a maternity store, A Pea in the Pod, in Haverford, Pa. The bride's father was a senior vice president who oversaw commercial lending and trust activities in Philadelphia for the PNC Financial Services Group. Mr. Parillo, 43, is a consultant in the Philadelphia office of I.B.M. Global Services, the e-business consulting division of the computer company. He graduated from Johns Hopkins University and received an M.B.A. from Duke. His mother, who is retired, taught French at St. Peter's by-the-Sea, an Episcopal elementary school in Bay Shore, N.Y. His father, also retired, was a contracts manager for the Fairchild Republic Company, the former aircraft manufacturer in Farmingdale, N.Y.\r\n",
      "I0731 06:22:19.631321 139690170451776 decoding.py:167] Inference results OUTPUT: s\r\n",
      "I0731 06:22:19.631486 139690170451776 decoding.py:169] Inference results TARGET: Suzanne Mitchell, Marco Parillo\r\n",
      "I0731 06:22:19.631787 139690170451776 decoding.py:332] BEAM 0:\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I0731 06:22:19.634530 139690170451776 decoding.py:152] Inference results INPUT: Two related National Security Agency surveillance programs begun after the Sept. 11 attacks have provoked legal controversy because the agency does not seek court warrants for their operation. In the domestic eavesdropping program, the N.S.A. listens in on phone calls and reads e-mail messages to and from Americans and others in the United States who the agency believes may be linked to Al Qaeda. Only international communications -- those into and out of the country -- are monitored, according to administration officials. Until late 2001, the N.S.A. focused on only the foreign end of such conversations; if it decided someone in the United States was of intelligence interest, it had to get a warrant from the Foreign Intelligence Surveillance Court. Now such warrants are sought only for communications between two people who are both in the United States. In the telephone record data-mining program, the N.S.A. has obtained from at least three phone companies the records of all calls -- domestic and international -- showing the phone numbers on both ends of each conversation, and its date, time, duration and other details. The records do not include the contents of any call or e-mail message and do not include personal data like credit card numbers and home addresses, officials say.\r\n",
      "I0731 06:22:19.634749 139690170451776 decoding.py:167] Inference results OUTPUT: \r\n",
      "I0731 06:22:19.634817 139690170451776 decoding.py:169] Inference results TARGET: Details of Two Surveillance Programs\r\n",
      "I0731 06:22:19.634897 139690170451776 decoding.py:332] BEAM 1:\r\n",
      "I0731 06:22:19.636703 139690170451776 decoding.py:152] Inference results INPUT: Two related National Security Agency surveillance programs begun after the Sept. 11 attacks have provoked legal controversy because the agency does not seek court warrants for their operation. In the domestic eavesdropping program, the N.S.A. listens in on phone calls and reads e-mail messages to and from Americans and others in the United States who the agency believes may be linked to Al Qaeda. Only international communications -- those into and out of the country -- are monitored, according to administration officials. Until late 2001, the N.S.A. focused on only the foreign end of such conversations; if it decided someone in the United States was of intelligence interest, it had to get a warrant from the Foreign Intelligence Surveillance Court. Now such warrants are sought only for communications between two people who are both in the United States. In the telephone record data-mining program, the N.S.A. has obtained from at least three phone companies the records of all calls -- domestic and international -- showing the phone numbers on both ends of each conversation, and its date, time, duration and other details. The records do not include the contents of any call or e-mail message and do not include personal data like credit card numbers and home addresses, officials say.\r\n",
      "I0731 06:22:19.636865 139690170451776 decoding.py:167] Inference results OUTPUT: \r\n",
      "I0731 06:22:19.636920 139690170451776 decoding.py:169] Inference results TARGET: Details of Two Surveillance Programs\r\n",
      "I0731 06:22:19.636985 139690170451776 decoding.py:332] BEAM 2:\r\n",
      "I0731 06:22:19.639976 139690170451776 decoding.py:152] Inference results INPUT: Two related National Security Agency surveillance programs begun after the Sept. 11 attacks have provoked legal controversy because the agency does not seek court warrants for their operation. In the domestic eavesdropping program, the N.S.A. listens in on phone calls and reads e-mail messages to and from Americans and others in the United States who the agency believes may be linked to Al Qaeda. Only international communications -- those into and out of the country -- are monitored, according to administration officials. Until late 2001, the N.S.A. focused on only the foreign end of such conversations; if it decided someone in the United States was of intelligence interest, it had to get a warrant from the Foreign Intelligence Surveillance Court. Now such warrants are sought only for communications between two people who are both in the United States. In the telephone record data-mining program, the N.S.A. has obtained from at least three phone companies the records of all calls -- domestic and international -- showing the phone numbers on both ends of each conversation, and its date, time, duration and other details. The records do not include the contents of any call or e-mail message and do not include personal data like credit card numbers and home addresses, officials say.\r\n",
      "I0731 06:22:19.640201 139690170451776 decoding.py:167] Inference results OUTPUT: s\r\n",
      "I0731 06:22:19.640265 139690170451776 decoding.py:169] Inference results TARGET: Details of Two Surveillance Programs\r\n",
      "I0731 06:22:19.640403 139690170451776 decoding.py:332] BEAM 0:\r\n",
      "I0731 06:22:19.642123 139690170451776 decoding.py:152] Inference results INPUT: Overuse injuries happen to the very best of athletes. Just 16 days before this year's United States Open golf tournament Tiger Woods was forced to take a break from golf for a week to let a sore back heal. Soon after, during the United States Open semifinal tennis match, Pete Sampras was hobbled by a strained muscle in his thigh. But for most of us amateurs on the playing fields, walking and running paths, and in swimming pools and weight rooms, overuse injuries are all too often the consequence of poor technique or misalignment of body parts. A recent issue of the Penn State Sports Medicine Newsletter points out: ''An injury caused by moving the body the wrong way over a period of time presents athletes with two problems. First, they have to recover from the injury. Then they have to retrain themselves so that it won't happen again.'' But there is a better approach: To minimize the risk of injuries, learn how to perform your chosen activities correctly from the beginning and have your technique monitored periodically by an expert to be sure you haven't lapsed into body-damaging form. Although it is not possible in the space of this column to describe injury-provoking errors for all sports, several popular activities account for common problems.\r\n",
      "I0731 06:22:19.642352 139690170451776 decoding.py:167] Inference results OUTPUT: \r\n",
      "I0731 06:22:19.642409 139690170451776 decoding.py:169] Inference results TARGET: The Athlete's Secret to Warding Off Overuse Injuries: Good Technique\r\n",
      "I0731 06:22:19.642468 139690170451776 decoding.py:332] BEAM 1:\r\n",
      "I0731 06:22:19.644463 139690170451776 decoding.py:152] Inference results INPUT: Overuse injuries happen to the very best of athletes. Just 16 days before this year's United States Open golf tournament Tiger Woods was forced to take a break from golf for a week to let a sore back heal. Soon after, during the United States Open semifinal tennis match, Pete Sampras was hobbled by a strained muscle in his thigh. But for most of us amateurs on the playing fields, walking and running paths, and in swimming pools and weight rooms, overuse injuries are all too often the consequence of poor technique or misalignment of body parts. A recent issue of the Penn State Sports Medicine Newsletter points out: ''An injury caused by moving the body the wrong way over a period of time presents athletes with two problems. First, they have to recover from the injury. Then they have to retrain themselves so that it won't happen again.'' But there is a better approach: To minimize the risk of injuries, learn how to perform your chosen activities correctly from the beginning and have your technique monitored periodically by an expert to be sure you haven't lapsed into body-damaging form. Although it is not possible in the space of this column to describe injury-provoking errors for all sports, several popular activities account for common problems.\r\n",
      "I0731 06:22:19.645107 139690170451776 decoding.py:167] Inference results OUTPUT: \r\n",
      "I0731 06:22:19.645203 139690170451776 decoding.py:169] Inference results TARGET: The Athlete's Secret to Warding Off Overuse Injuries: Good Technique\r\n",
      "I0731 06:22:19.645288 139690170451776 decoding.py:332] BEAM 2:\r\n",
      "I0731 06:22:19.647957 139690170451776 decoding.py:152] Inference results INPUT: Overuse injuries happen to the very best of athletes. Just 16 days before this year's United States Open golf tournament Tiger Woods was forced to take a break from golf for a week to let a sore back heal. Soon after, during the United States Open semifinal tennis match, Pete Sampras was hobbled by a strained muscle in his thigh. But for most of us amateurs on the playing fields, walking and running paths, and in swimming pools and weight rooms, overuse injuries are all too often the consequence of poor technique or misalignment of body parts. A recent issue of the Penn State Sports Medicine Newsletter points out: ''An injury caused by moving the body the wrong way over a period of time presents athletes with two problems. First, they have to recover from the injury. Then they have to retrain themselves so that it won't happen again.'' But there is a better approach: To minimize the risk of injuries, learn how to perform your chosen activities correctly from the beginning and have your technique monitored periodically by an expert to be sure you haven't lapsed into body-damaging form. Although it is not possible in the space of this column to describe injury-provoking errors for all sports, several popular activities account for common problems.\r\n",
      "I0731 06:22:19.648231 139690170451776 decoding.py:167] Inference results OUTPUT: s\r\n",
      "I0731 06:22:19.648292 139690170451776 decoding.py:169] Inference results TARGET: The Athlete's Secret to Warding Off Overuse Injuries: Good Technique\r\n",
      "I0731 06:22:19.648443 139690170451776 decoding.py:332] BEAM 0:\r\n",
      "I0731 06:22:19.650076 139690170451776 decoding.py:152] Inference results INPUT: A stroll down tree-lined Oak Avenue is all a visitor needs to see how Oakwood got its name. But some residents say the name could also apply to the town's solid family life; three and four generations of some families live on the same streets. The Oakwood Girls, a group of 20 women who grew up in the Staten Island community and have known each other for more than 50 years, meet monthly. ''Everyone is related to everyone else,'' said the Rev. Thomas Bergin, principal of Monsignor Farrell High School in Oakwood and a 29-year resident of the town. ''Brothers and sisters buy homes next to each other. Children take over their parents' homes when the parents move to retirement communities or die. Many Oakwood boys marry the girl next door.'' ''It's a place where you can knock on a neighbor's door anytime, day or night, and ask for a box of pasta,'' said Frances Sisto, chairwoman of the Oakwood Civic Association, a community group. Mrs. Sisto lives in the house her husband's late grandfather once owned, next door to her in-laws' house, on Amherst Avenue.\r\n",
      "I0731 06:22:19.650262 139690170451776 decoding.py:167] Inference results OUTPUT: \r\n",
      "I0731 06:22:19.650320 139690170451776 decoding.py:169] Inference results TARGET: If You're Thinking of Living in: Oakwood\r\n",
      "I0731 06:22:19.650371 139690170451776 decoding.py:332] BEAM 1:\r\n",
      "I0731 06:22:19.652591 139690170451776 decoding.py:152] Inference results INPUT: A stroll down tree-lined Oak Avenue is all a visitor needs to see how Oakwood got its name. But some residents say the name could also apply to the town's solid family life; three and four generations of some families live on the same streets. The Oakwood Girls, a group of 20 women who grew up in the Staten Island community and have known each other for more than 50 years, meet monthly. ''Everyone is related to everyone else,'' said the Rev. Thomas Bergin, principal of Monsignor Farrell High School in Oakwood and a 29-year resident of the town. ''Brothers and sisters buy homes next to each other. Children take over their parents' homes when the parents move to retirement communities or die. Many Oakwood boys marry the girl next door.'' ''It's a place where you can knock on a neighbor's door anytime, day or night, and ask for a box of pasta,'' said Frances Sisto, chairwoman of the Oakwood Civic Association, a community group. Mrs. Sisto lives in the house her husband's late grandfather once owned, next door to her in-laws' house, on Amherst Avenue.\r\n",
      "I0731 06:22:19.652845 139690170451776 decoding.py:167] Inference results OUTPUT: \r\n",
      "I0731 06:22:19.652906 139690170451776 decoding.py:169] Inference results TARGET: If You're Thinking of Living in: Oakwood\r\n",
      "I0731 06:22:19.652957 139690170451776 decoding.py:332] BEAM 2:\r\n",
      "I0731 06:22:19.656479 139690170451776 decoding.py:152] Inference results INPUT: A stroll down tree-lined Oak Avenue is all a visitor needs to see how Oakwood got its name. But some residents say the name could also apply to the town's solid family life; three and four generations of some families live on the same streets. The Oakwood Girls, a group of 20 women who grew up in the Staten Island community and have known each other for more than 50 years, meet monthly. ''Everyone is related to everyone else,'' said the Rev. Thomas Bergin, principal of Monsignor Farrell High School in Oakwood and a 29-year resident of the town. ''Brothers and sisters buy homes next to each other. Children take over their parents' homes when the parents move to retirement communities or die. Many Oakwood boys marry the girl next door.'' ''It's a place where you can knock on a neighbor's door anytime, day or night, and ask for a box of pasta,'' said Frances Sisto, chairwoman of the Oakwood Civic Association, a community group. Mrs. Sisto lives in the house her husband's late grandfather once owned, next door to her in-laws' house, on Amherst Avenue.\r\n",
      "I0731 06:22:19.657042 139690170451776 decoding.py:167] Inference results OUTPUT: s\r\n",
      "I0731 06:22:19.657193 139690170451776 decoding.py:169] Inference results TARGET: If You're Thinking of Living in: Oakwood\r\n",
      "I0731 06:22:19.657447 139690170451776 decoding.py:332] BEAM 0:\r\n",
      "I0731 06:22:19.661762 139690170451776 decoding.py:152] Inference results INPUT: For the next two years, my sports universe will be without a sun. Central Park's dreaded Great Lawn Project has begun. If Central Park really is the lungs of New York City, the place where New Yorkers go to breathe freely and relax, the Great Lawn is the heart of the lungs. Thousands of sports stories, love stories and life stories spring from that 15-acre so-called lawn. As a person who plays softball there from April through September, along with players from 200 other teams, and regularly chases footballs and Frisbees there, I have lived many unforgettable New York moments on those grounds. Like the time I turned out for a regular Wednesday evening ultimate Frisbee game and Paul Simon and his band showed up to rehearse for his  free concert the next day. We ran and dove and danced around the lit-up field while Paul strummed and sang to his new Brazilian beat. Then, we came out the next day and squeezed into the crowd of 600,000 for the concert. I'm not against the renovation. Parks Commissioner Henry J. Stern called the Great Lawn a \"dust bowl.\" He's right, but it's our dust bowl. I'm despondent, as I'd be if a dear friend were moving away, and I'm worried, as I'd be if a loved  one were undergoing surgery.\r\n",
      "I0731 06:22:19.662217 139690170451776 decoding.py:167] Inference results OUTPUT: \r\n",
      "I0731 06:22:19.662361 139690170451776 decoding.py:169] Inference results TARGET: Trying to Do Without a Glorious Dust Bowl\r\n",
      "I0731 06:22:19.662456 139690170451776 decoding.py:332] BEAM 1:\r\n",
      "I0731 06:22:19.666743 139690170451776 decoding.py:152] Inference results INPUT: For the next two years, my sports universe will be without a sun. Central Park's dreaded Great Lawn Project has begun. If Central Park really is the lungs of New York City, the place where New Yorkers go to breathe freely and relax, the Great Lawn is the heart of the lungs. Thousands of sports stories, love stories and life stories spring from that 15-acre so-called lawn. As a person who plays softball there from April through September, along with players from 200 other teams, and regularly chases footballs and Frisbees there, I have lived many unforgettable New York moments on those grounds. Like the time I turned out for a regular Wednesday evening ultimate Frisbee game and Paul Simon and his band showed up to rehearse for his  free concert the next day. We ran and dove and danced around the lit-up field while Paul strummed and sang to his new Brazilian beat. Then, we came out the next day and squeezed into the crowd of 600,000 for the concert. I'm not against the renovation. Parks Commissioner Henry J. Stern called the Great Lawn a \"dust bowl.\" He's right, but it's our dust bowl. I'm despondent, as I'd be if a dear friend were moving away, and I'm worried, as I'd be if a loved  one were undergoing surgery.\r\n",
      "I0731 06:22:19.667212 139690170451776 decoding.py:167] Inference results OUTPUT: \r\n",
      "I0731 06:22:19.667351 139690170451776 decoding.py:169] Inference results TARGET: Trying to Do Without a Glorious Dust Bowl\r\n",
      "I0731 06:22:19.667446 139690170451776 decoding.py:332] BEAM 2:\r\n",
      "I0731 06:22:19.671680 139690170451776 decoding.py:152] Inference results INPUT: For the next two years, my sports universe will be without a sun. Central Park's dreaded Great Lawn Project has begun. If Central Park really is the lungs of New York City, the place where New Yorkers go to breathe freely and relax, the Great Lawn is the heart of the lungs. Thousands of sports stories, love stories and life stories spring from that 15-acre so-called lawn. As a person who plays softball there from April through September, along with players from 200 other teams, and regularly chases footballs and Frisbees there, I have lived many unforgettable New York moments on those grounds. Like the time I turned out for a regular Wednesday evening ultimate Frisbee game and Paul Simon and his band showed up to rehearse for his  free concert the next day. We ran and dove and danced around the lit-up field while Paul strummed and sang to his new Brazilian beat. Then, we came out the next day and squeezed into the crowd of 600,000 for the concert. I'm not against the renovation. Parks Commissioner Henry J. Stern called the Great Lawn a \"dust bowl.\" He's right, but it's our dust bowl. I'm despondent, as I'd be if a dear friend were moving away, and I'm worried, as I'd be if a loved  one were undergoing surgery.\r\n",
      "I0731 06:22:19.672164 139690170451776 decoding.py:167] Inference results OUTPUT: s\r\n",
      "I0731 06:22:19.672295 139690170451776 decoding.py:169] Inference results TARGET: Trying to Do Without a Glorious Dust Bowl\r\n",
      "I0731 06:22:19.672534 139690170451776 decoding.py:332] BEAM 0:\r\n",
      "I0731 06:22:19.676661 139690170451776 decoding.py:152] Inference results INPUT: What does a hip-hop heartthrob look like these days? Often, he looks a lot like Juelz Santana, the 21-year-old Harlem rapper who has a knack for seeming boyish without ever quite seeming harmless. He has dimples, a mischievous smile and a rude but charming habit of eschewing come-ons in favor of let's-gos. He once famously barked, ''Get in the car/ And don't touch nothing, sit in the car''; this was his idea of smooth seduction. And he's not shy about telling potential lovers exactly what he wants -- and, while he's at it, exactly what his friends want, too. How can rappers get away with delivering such salty pickup lines? Here's one answer: It's because their counterparts, R&B singers, deliver such sweet ones. For an example, look no further than a 16-year-old crooner who is the ascendant R&B star of the moment. His name is Chris Brown and he has his first hit with ''Run It!,'' a lighthearted club track based on a zooming electronic beat; his debut album, ''Chris Brown'' (Jive/Sony BMG), is poised to become one of next week's biggest sellers after it is released on Tuesday.\r\n",
      "I0731 06:22:19.677043 139690170451776 decoding.py:167] Inference results OUTPUT: \r\n",
      "I0731 06:22:19.677167 139690170451776 decoding.py:169] Inference results TARGET: Crooning And Rap, In Harmony\r\n",
      "I0731 06:22:19.677263 139690170451776 decoding.py:332] BEAM 1:\r\n",
      "I0731 06:22:19.681313 139690170451776 decoding.py:152] Inference results INPUT: What does a hip-hop heartthrob look like these days? Often, he looks a lot like Juelz Santana, the 21-year-old Harlem rapper who has a knack for seeming boyish without ever quite seeming harmless. He has dimples, a mischievous smile and a rude but charming habit of eschewing come-ons in favor of let's-gos. He once famously barked, ''Get in the car/ And don't touch nothing, sit in the car''; this was his idea of smooth seduction. And he's not shy about telling potential lovers exactly what he wants -- and, while he's at it, exactly what his friends want, too. How can rappers get away with delivering such salty pickup lines? Here's one answer: It's because their counterparts, R&B singers, deliver such sweet ones. For an example, look no further than a 16-year-old crooner who is the ascendant R&B star of the moment. His name is Chris Brown and he has his first hit with ''Run It!,'' a lighthearted club track based on a zooming electronic beat; his debut album, ''Chris Brown'' (Jive/Sony BMG), is poised to become one of next week's biggest sellers after it is released on Tuesday.\r\n",
      "I0731 06:22:19.681749 139690170451776 decoding.py:167] Inference results OUTPUT: \r\n",
      "I0731 06:22:19.681889 139690170451776 decoding.py:169] Inference results TARGET: Crooning And Rap, In Harmony\r\n",
      "I0731 06:22:19.681996 139690170451776 decoding.py:332] BEAM 2:\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I0731 06:22:19.686190 139690170451776 decoding.py:152] Inference results INPUT: What does a hip-hop heartthrob look like these days? Often, he looks a lot like Juelz Santana, the 21-year-old Harlem rapper who has a knack for seeming boyish without ever quite seeming harmless. He has dimples, a mischievous smile and a rude but charming habit of eschewing come-ons in favor of let's-gos. He once famously barked, ''Get in the car/ And don't touch nothing, sit in the car''; this was his idea of smooth seduction. And he's not shy about telling potential lovers exactly what he wants -- and, while he's at it, exactly what his friends want, too. How can rappers get away with delivering such salty pickup lines? Here's one answer: It's because their counterparts, R&B singers, deliver such sweet ones. For an example, look no further than a 16-year-old crooner who is the ascendant R&B star of the moment. His name is Chris Brown and he has his first hit with ''Run It!,'' a lighthearted club track based on a zooming electronic beat; his debut album, ''Chris Brown'' (Jive/Sony BMG), is poised to become one of next week's biggest sellers after it is released on Tuesday.\r\n",
      "I0731 06:22:19.686651 139690170451776 decoding.py:167] Inference results OUTPUT: s\r\n",
      "I0731 06:22:19.686810 139690170451776 decoding.py:169] Inference results TARGET: Crooning And Rap, In Harmony\r\n",
      "I0731 06:22:19.687084 139690170451776 decoding.py:332] BEAM 0:\r\n",
      "I0731 06:22:19.691603 139690170451776 decoding.py:152] Inference results INPUT: ON the day when the first list of dormant Swiss bank accounts was published last week, the evening news program in Israel carried nothing about it. And the main headlines in Israeli papers dealt not with the list but with a one-day strike and the collapse of a stadium bridge. In fact, the entire storm over assets of Holocaust victims held in Switzerland never really made many waves in the country where, it would seem, the reaction should be most intense. ''Frankly speaking, not only Israel as a whole, but me personally, I find myself much less involved in this than many American friends,'' said Natan Sharansky, the Minister of Industry and Trade, echoing a common sentiment among Israelis. One reason, of course, is that on any given day, Israel has more than enough news of its own, what with the Palestinians and the endless internal squabbles. But in conversations with many Israelis who have themselves been struck by their reserve, the explanation reaches far deeper -- to a different understanding of Jewish history and of the Holocaust than that of Jews abroad, and to a certain unease, even annoyance, with the way the issue has been seized on by Jews elsewhere.\r\n",
      "I0731 06:22:19.692101 139690170451776 decoding.py:167] Inference results OUTPUT: \r\n",
      "I0731 06:22:19.692269 139690170451776 decoding.py:169] Inference results TARGET: Why Israel Shrugs At the Swiss List\r\n",
      "I0731 06:22:19.692380 139690170451776 decoding.py:332] BEAM 1:\r\n",
      "I0731 06:22:19.696352 139690170451776 decoding.py:152] Inference results INPUT: ON the day when the first list of dormant Swiss bank accounts was published last week, the evening news program in Israel carried nothing about it. And the main headlines in Israeli papers dealt not with the list but with a one-day strike and the collapse of a stadium bridge. In fact, the entire storm over assets of Holocaust victims held in Switzerland never really made many waves in the country where, it would seem, the reaction should be most intense. ''Frankly speaking, not only Israel as a whole, but me personally, I find myself much less involved in this than many American friends,'' said Natan Sharansky, the Minister of Industry and Trade, echoing a common sentiment among Israelis. One reason, of course, is that on any given day, Israel has more than enough news of its own, what with the Palestinians and the endless internal squabbles. But in conversations with many Israelis who have themselves been struck by their reserve, the explanation reaches far deeper -- to a different understanding of Jewish history and of the Holocaust than that of Jews abroad, and to a certain unease, even annoyance, with the way the issue has been seized on by Jews elsewhere.\r\n",
      "I0731 06:22:19.696772 139690170451776 decoding.py:167] Inference results OUTPUT: \r\n",
      "I0731 06:22:19.696905 139690170451776 decoding.py:169] Inference results TARGET: Why Israel Shrugs At the Swiss List\r\n",
      "I0731 06:22:19.697002 139690170451776 decoding.py:332] BEAM 2:\r\n",
      "I0731 06:22:19.700527 139690170451776 decoding.py:152] Inference results INPUT: ON the day when the first list of dormant Swiss bank accounts was published last week, the evening news program in Israel carried nothing about it. And the main headlines in Israeli papers dealt not with the list but with a one-day strike and the collapse of a stadium bridge. In fact, the entire storm over assets of Holocaust victims held in Switzerland never really made many waves in the country where, it would seem, the reaction should be most intense. ''Frankly speaking, not only Israel as a whole, but me personally, I find myself much less involved in this than many American friends,'' said Natan Sharansky, the Minister of Industry and Trade, echoing a common sentiment among Israelis. One reason, of course, is that on any given day, Israel has more than enough news of its own, what with the Palestinians and the endless internal squabbles. But in conversations with many Israelis who have themselves been struck by their reserve, the explanation reaches far deeper -- to a different understanding of Jewish history and of the Holocaust than that of Jews abroad, and to a certain unease, even annoyance, with the way the issue has been seized on by Jews elsewhere.\r\n",
      "I0731 06:22:19.700969 139690170451776 decoding.py:167] Inference results OUTPUT: s\r\n",
      "I0731 06:22:19.701102 139690170451776 decoding.py:169] Inference results TARGET: Why Israel Shrugs At the Swiss List\r\n",
      "I0731 06:22:19.701344 139690170451776 decoding.py:332] BEAM 0:\r\n",
      "I0731 06:22:19.707404 139690170451776 decoding.py:152] Inference results INPUT: It's bad news for a boy named Herb when the Big Bad Wolf and a little not-so-bad wolf fall out of a storybook, drooling and hungry. Thank goodness for fairy godmothers. After all, who else can bring the big wolf down to size and turn the little wolf into a fashion plate? If all that sounds silly, it is. It's meant to be, in BEWARE OF THE STORYBOOK WOLVES (Arthur A. Levine/Scholastic, $15.95; ages 4 to 8). With a sly wit and a handful of evocative characters, Lauren Child takes the familiar ''once upon a time'' story, shakes it and then spins it for a giggle. Imagine Mother Goose meeting Roald Dahl's ''Enormous Crocodile.'' The result is a smile-provoking yarn full of fairy-tale twists. The story begins when Herb's mother reads him ''Little Red Riding Hood,'' and journeys into silliness when the Big Bad Wolf falls out of the book. What's a boy to do when confronted by a hungry storybook wolf? Reach into another storybook for help, of course. And another. And another. If a snarling fairy is no help, then certainly a fairy godmother is. And if Cinderella is left at home to do the dishes, then so be it. Child's pictures mesh artfully with her words, and her characters, especially little Herb, are marvelously expressive. The spare strokes on the human characters set up a nice contrast to the bold designs and bright colors of clothes and backgrounds. Child's penchant for style occasionally moves into gimmickry, though, with swirly typefaces that distract from the narrative. Despite some problems of legibility, the story is well worth the effort, if only to learn why little Herb now sleeps atop his storybooks, why Cinderella is staying home from the ball and why Little Red Riding Hood no longer cries wolf. Doug Ward\r\n",
      "I0731 06:22:19.707873 139690170451776 decoding.py:167] Inference results OUTPUT: \r\n",
      "I0731 06:22:19.708023 139690170451776 decoding.py:169] Inference results TARGET: Saved by Books\r\n",
      "I0731 06:22:19.708125 139690170451776 decoding.py:332] BEAM 1:\r\n",
      "I0731 06:22:19.714308 139690170451776 decoding.py:152] Inference results INPUT: It's bad news for a boy named Herb when the Big Bad Wolf and a little not-so-bad wolf fall out of a storybook, drooling and hungry. Thank goodness for fairy godmothers. After all, who else can bring the big wolf down to size and turn the little wolf into a fashion plate? If all that sounds silly, it is. It's meant to be, in BEWARE OF THE STORYBOOK WOLVES (Arthur A. Levine/Scholastic, $15.95; ages 4 to 8). With a sly wit and a handful of evocative characters, Lauren Child takes the familiar ''once upon a time'' story, shakes it and then spins it for a giggle. Imagine Mother Goose meeting Roald Dahl's ''Enormous Crocodile.'' The result is a smile-provoking yarn full of fairy-tale twists. The story begins when Herb's mother reads him ''Little Red Riding Hood,'' and journeys into silliness when the Big Bad Wolf falls out of the book. What's a boy to do when confronted by a hungry storybook wolf? Reach into another storybook for help, of course. And another. And another. If a snarling fairy is no help, then certainly a fairy godmother is. And if Cinderella is left at home to do the dishes, then so be it. Child's pictures mesh artfully with her words, and her characters, especially little Herb, are marvelously expressive. The spare strokes on the human characters set up a nice contrast to the bold designs and bright colors of clothes and backgrounds. Child's penchant for style occasionally moves into gimmickry, though, with swirly typefaces that distract from the narrative. Despite some problems of legibility, the story is well worth the effort, if only to learn why little Herb now sleeps atop his storybooks, why Cinderella is staying home from the ball and why Little Red Riding Hood no longer cries wolf. Doug Ward\r\n",
      "I0731 06:22:19.714727 139690170451776 decoding.py:167] Inference results OUTPUT: \r\n",
      "I0731 06:22:19.714880 139690170451776 decoding.py:169] Inference results TARGET: Saved by Books\r\n",
      "I0731 06:22:19.714990 139690170451776 decoding.py:332] BEAM 2:\r\n",
      "I0731 06:22:19.719202 139690170451776 decoding.py:152] Inference results INPUT: It's bad news for a boy named Herb when the Big Bad Wolf and a little not-so-bad wolf fall out of a storybook, drooling and hungry. Thank goodness for fairy godmothers. After all, who else can bring the big wolf down to size and turn the little wolf into a fashion plate? If all that sounds silly, it is. It's meant to be, in BEWARE OF THE STORYBOOK WOLVES (Arthur A. Levine/Scholastic, $15.95; ages 4 to 8). With a sly wit and a handful of evocative characters, Lauren Child takes the familiar ''once upon a time'' story, shakes it and then spins it for a giggle. Imagine Mother Goose meeting Roald Dahl's ''Enormous Crocodile.'' The result is a smile-provoking yarn full of fairy-tale twists. The story begins when Herb's mother reads him ''Little Red Riding Hood,'' and journeys into silliness when the Big Bad Wolf falls out of the book. What's a boy to do when confronted by a hungry storybook wolf? Reach into another storybook for help, of course. And another. And another. If a snarling fairy is no help, then certainly a fairy godmother is. And if Cinderella is left at home to do the dishes, then so be it. Child's pictures mesh artfully with her words, and her characters, especially little Herb, are marvelously expressive. The spare strokes on the human characters set up a nice contrast to the bold designs and bright colors of clothes and backgrounds. Child's penchant for style occasionally moves into gimmickry, though, with swirly typefaces that distract from the narrative. Despite some problems of legibility, the story is well worth the effort, if only to learn why little Herb now sleeps atop his storybooks, why Cinderella is staying home from the ball and why Little Red Riding Hood no longer cries wolf. Doug Ward\r\n",
      "I0731 06:22:19.719459 139690170451776 decoding.py:167] Inference results OUTPUT: s\r\n",
      "I0731 06:22:19.719545 139690170451776 decoding.py:169] Inference results TARGET: Saved by Books\r\n",
      "I0731 06:22:19.719749 139690170451776 decoding.py:332] BEAM 0:\r\n",
      "I0731 06:22:19.722718 139690170451776 decoding.py:152] Inference results INPUT: Twenty-five years ago, a band with the instincts of INXS would have been playing for sock hop dancers and garage-rock entrepreneurs, pounding out riff after riff and calling for ecstasy in three-minute stretches. As rock moved back to the dance floor in the 1980's, the Australian band INXS (pronounced \"in excess\") emerged triumphant. With an array of solid, mostly borrowed riffs backing a singer, Michael Hutchence, who draws screams from teen-age girls, INXS has been selling millions of albums since the mid-1980's. At Madison Square Garden on Saturday night, young girls were dancing as they squealed. INXS is a single-minded, efficient band. It has three kinds of songs: power-chord stomps recalling the Rolling Stones and Billy Idol, funk by way of Prince and piano-centered marches that echo Roxy Music, all braced by Jon Farriss's authoritative drumming. The lyrics, sung by Mr. Hutchence in a voice that can sound like Bryan Ferry or Elton John, are terse, rarely using more than five words per line; the melodies are often two- or three-note chants. And the band plays them straight through, not even disgressing for guitar or keyboard solos; instrumental interludes almost always stick to the riff at hand. Mr. Hutchence has a limber, graceful stage presence. He shakes his hips, struts up walkways to get closer to the fans and kicks his long legs. In his telegraphic lines, he sings about lust and pleasure-seeking, about \"the devil inside\" and about true love.  \"Disappear,\" the band's current single from its album \"X\" (Atlantic), says that a romance obliterates any worries about the world's problems; it's pop escapism in telegraphic form. The irony is that while INXS sings about breaking free and having wild times, it has sealed itself into a relentless formula; a formula that is, however, perfect for dancers.\r\n",
      "I0731 06:22:19.722944 139690170451776 decoding.py:167] Inference results OUTPUT: \r\n",
      "I0731 06:22:19.723018 139690170451776 decoding.py:169] Inference results TARGET: Review/Rock; A Band With a Beat Made For Dancing\r\n",
      "I0731 06:22:19.723088 139690170451776 decoding.py:332] BEAM 1:\r\n",
      "I0731 06:22:19.726266 139690170451776 decoding.py:152] Inference results INPUT: Twenty-five years ago, a band with the instincts of INXS would have been playing for sock hop dancers and garage-rock entrepreneurs, pounding out riff after riff and calling for ecstasy in three-minute stretches. As rock moved back to the dance floor in the 1980's, the Australian band INXS (pronounced \"in excess\") emerged triumphant. With an array of solid, mostly borrowed riffs backing a singer, Michael Hutchence, who draws screams from teen-age girls, INXS has been selling millions of albums since the mid-1980's. At Madison Square Garden on Saturday night, young girls were dancing as they squealed. INXS is a single-minded, efficient band. It has three kinds of songs: power-chord stomps recalling the Rolling Stones and Billy Idol, funk by way of Prince and piano-centered marches that echo Roxy Music, all braced by Jon Farriss's authoritative drumming. The lyrics, sung by Mr. Hutchence in a voice that can sound like Bryan Ferry or Elton John, are terse, rarely using more than five words per line; the melodies are often two- or three-note chants. And the band plays them straight through, not even disgressing for guitar or keyboard solos; instrumental interludes almost always stick to the riff at hand. Mr. Hutchence has a limber, graceful stage presence. He shakes his hips, struts up walkways to get closer to the fans and kicks his long legs. In his telegraphic lines, he sings about lust and pleasure-seeking, about \"the devil inside\" and about true love.  \"Disappear,\" the band's current single from its album \"X\" (Atlantic), says that a romance obliterates any worries about the world's problems; it's pop escapism in telegraphic form. The irony is that while INXS sings about breaking free and having wild times, it has sealed itself into a relentless formula; a formula that is, however, perfect for dancers.\r\n",
      "I0731 06:22:19.726527 139690170451776 decoding.py:167] Inference results OUTPUT: \r\n",
      "I0731 06:22:19.726604 139690170451776 decoding.py:169] Inference results TARGET: Review/Rock; A Band With a Beat Made For Dancing\r\n",
      "I0731 06:22:19.726673 139690170451776 decoding.py:332] BEAM 2:\r\n",
      "I0731 06:22:19.729492 139690170451776 decoding.py:152] Inference results INPUT: Twenty-five years ago, a band with the instincts of INXS would have been playing for sock hop dancers and garage-rock entrepreneurs, pounding out riff after riff and calling for ecstasy in three-minute stretches. As rock moved back to the dance floor in the 1980's, the Australian band INXS (pronounced \"in excess\") emerged triumphant. With an array of solid, mostly borrowed riffs backing a singer, Michael Hutchence, who draws screams from teen-age girls, INXS has been selling millions of albums since the mid-1980's. At Madison Square Garden on Saturday night, young girls were dancing as they squealed. INXS is a single-minded, efficient band. It has three kinds of songs: power-chord stomps recalling the Rolling Stones and Billy Idol, funk by way of Prince and piano-centered marches that echo Roxy Music, all braced by Jon Farriss's authoritative drumming. The lyrics, sung by Mr. Hutchence in a voice that can sound like Bryan Ferry or Elton John, are terse, rarely using more than five words per line; the melodies are often two- or three-note chants. And the band plays them straight through, not even disgressing for guitar or keyboard solos; instrumental interludes almost always stick to the riff at hand. Mr. Hutchence has a limber, graceful stage presence. He shakes his hips, struts up walkways to get closer to the fans and kicks his long legs. In his telegraphic lines, he sings about lust and pleasure-seeking, about \"the devil inside\" and about true love.  \"Disappear,\" the band's current single from its album \"X\" (Atlantic), says that a romance obliterates any worries about the world's problems; it's pop escapism in telegraphic form. The irony is that while INXS sings about breaking free and having wild times, it has sealed itself into a relentless formula; a formula that is, however, perfect for dancers.\r\n",
      "I0731 06:22:19.729859 139690170451776 decoding.py:167] Inference results OUTPUT: s\r\n",
      "I0731 06:22:19.729988 139690170451776 decoding.py:169] Inference results TARGET: Review/Rock; A Band With a Beat Made For Dancing\r\n",
      "I0731 06:22:19.730159 139690170451776 decoding.py:332] BEAM 0:\r\n",
      "I0731 06:22:19.733372 139690170451776 decoding.py:152] Inference results INPUT: Anyone visiting this town in the days after Hurricane Katrina might reasonably have concluded that it would be a long while before slot machines were again ringing their incessant chimes. The storm destroyed 9 of 10 floating casinos in Biloxi, and the tenth suffered significant damage. Yet so well financed is the gambling industry -- and so profitable the facilities that line the beaches here -- that one casino is set to open its doors to the public on Dec. 22. Another is to reopen the day after Christmas. A third, the Palace Casino, will have spent $23 million in four months to reopen by New Year's Eve, said the general manager, Keith Crosby. All 10 Biloxi casinos have told the city they will rebuild, and most plan larger, more elaborate facilities. One, Harrah's Entertainment Inc., the world's largest gambling company, has told city officials that it plans to invest as much as $1 billion in a new resort-casino -- a figure sizable enough to catch people's attention even in Las Vegas. And a growing list of investors, looking to take advantage of a new state law allowing the first-ever land-based casinos, is seeking an audience with city officials or state regulators in Jackson.\r\n",
      "I0731 06:22:19.733944 139690170451776 decoding.py:167] Inference results OUTPUT: \r\n",
      "I0731 06:22:19.734110 139690170451776 decoding.py:169] Inference results TARGET: Bright Spot on Gulf as Casinos Rush to Rebuild\r\n",
      "I0731 06:22:19.734214 139690170451776 decoding.py:332] BEAM 1:\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I0731 06:22:19.737158 139690170451776 decoding.py:152] Inference results INPUT: Anyone visiting this town in the days after Hurricane Katrina might reasonably have concluded that it would be a long while before slot machines were again ringing their incessant chimes. The storm destroyed 9 of 10 floating casinos in Biloxi, and the tenth suffered significant damage. Yet so well financed is the gambling industry -- and so profitable the facilities that line the beaches here -- that one casino is set to open its doors to the public on Dec. 22. Another is to reopen the day after Christmas. A third, the Palace Casino, will have spent $23 million in four months to reopen by New Year's Eve, said the general manager, Keith Crosby. All 10 Biloxi casinos have told the city they will rebuild, and most plan larger, more elaborate facilities. One, Harrah's Entertainment Inc., the world's largest gambling company, has told city officials that it plans to invest as much as $1 billion in a new resort-casino -- a figure sizable enough to catch people's attention even in Las Vegas. And a growing list of investors, looking to take advantage of a new state law allowing the first-ever land-based casinos, is seeking an audience with city officials or state regulators in Jackson.\n",
      "I0731 06:22:19.737855 139690170451776 decoding.py:167] Inference results OUTPUT: \n",
      "I0731 06:22:19.738013 139690170451776 decoding.py:169] Inference results TARGET: Bright Spot on Gulf as Casinos Rush to Rebuild\n",
      "I0731 06:22:19.738104 139690170451776 decoding.py:332] BEAM 2:\n",
      "I0731 06:22:19.741975 139690170451776 decoding.py:152] Inference results INPUT: Anyone visiting this town in the days after Hurricane Katrina might reasonably have concluded that it would be a long while before slot machines were again ringing their incessant chimes. The storm destroyed 9 of 10 floating casinos in Biloxi, and the tenth suffered significant damage. Yet so well financed is the gambling industry -- and so profitable the facilities that line the beaches here -- that one casino is set to open its doors to the public on Dec. 22. Another is to reopen the day after Christmas. A third, the Palace Casino, will have spent $23 million in four months to reopen by New Year's Eve, said the general manager, Keith Crosby. All 10 Biloxi casinos have told the city they will rebuild, and most plan larger, more elaborate facilities. One, Harrah's Entertainment Inc., the world's largest gambling company, has told city officials that it plans to invest as much as $1 billion in a new resort-casino -- a figure sizable enough to catch people's attention even in Las Vegas. And a growing list of investors, looking to take advantage of a new state law allowing the first-ever land-based casinos, is seeking an audience with city officials or state regulators in Jackson.\n",
      "I0731 06:22:19.742510 139690170451776 decoding.py:167] Inference results OUTPUT: s\n",
      "I0731 06:22:19.742651 139690170451776 decoding.py:169] Inference results TARGET: Bright Spot on Gulf as Casinos Rush to Rebuild\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "!t2t-decoder \\\n",
    "--t2t_usr_dir=\".\" \\\n",
    "--data_dir=\"./t2t_data/\" \\\n",
    "--problem=\"gavrilov\" \\\n",
    "--model=\"universal_transformer\" \\\n",
    "--hparams_set=\"universal_transformer_gavrilov\" \\\n",
    "--output_dir=\"./t2t_data/model\" \\\n",
    "--decode_hparams=\"beam_size=3,alpha=0.6,return_beams=True,write_beam_scores=True\" \\\n",
    "--decode_interactive \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "beamsize= 2, alpha=0.2 is OUTPUT: None\n",
    "beamsize= 2, alpha=0.8 is OUTPUT: None\n",
    "beamsize= 2, alpha=2.0 is OUTPUT: hung\n",
    "beamsize= 2, alpha=0.5 is OUTPUT: None\n",
    "beamsize= 2, alpha=0.01 is OUTPUT: None\n",
    "beamsize= 2, alpha=1.1 is OUTPUT: None. And long\n",
    "beamsize= 2, alpha=10 is OUTPUT: hung\n",
    "beamsize= 3, alpha=0.55, schedule=cont_eval is OUTPUT: None\n",
    "beamsize= 3, alpha=0.55, schedule=cont_eval is OUTPUT: None\n",
    "beamsize= 3, alpha=0.55, schedule=train is OUTPUT: None\n",
    "beamsize= 3, alpha=0.55, schedule=eval is OUTPUT: None\n",
    "beamsize= 10, alpha=0.5 is OUTPUT: None\n",
    "beamsize= 10, alpha=0.9 is OUTPUT: didn't finish\n",
    "choose no settings is OUTPUT: None\n",
    "removed decode_to_file setting, beam=4, alph=0.6 is OUTPUT: it shows the 4 beam options, some of which have a , or a single character. Progress!\n",
    "beam_size=4,alpha=0.9,return_beams=True is OUTPUT: just , or s or blank\n",
    "\"beam_size=4,alpha=0.9,return_beams=True,extra_length=200\" is OUTPUT: just , or s or blank\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# given sizes\n",
    "BEAM_SIZE=10\n",
    "ALPHA=0.6\n",
    "\n",
    "# sizes that failed:\n",
    "beam=10\n",
    "beam=1\n",
    "alpha=1.6\n",
    "alpha=0.3\n",
    "\n",
    "\\\n",
    "--decode_interactive=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from t2t https://github.com/tensorflow/tensor2tensor/blob/master/tensor2tensor/models/research/universal_transformer.py\n",
    "# this suggests that we could set decode_length in a similar call. And it does suggest alpha controls the translation. \n",
    "\n",
    "def _beam_decode(self, features, decode_length, beam_size, top_beams, alpha,\n",
    "                   use_tpu=False):\n",
    "    \"\"\"Beam search decoding.\n",
    "    Args:\n",
    "      features: an map of string to `Tensor`\n",
    "      decode_length: an integer.  How many additional timesteps to decode.\n",
    "      beam_size: number of beams.\n",
    "      top_beams: an integer. How many of the beams to return.\n",
    "      alpha: Float that controls the length penalty. larger the alpha, stronger\n",
    "        the preference for longer translations.\n",
    "      use_tpu: Whether we should use TPU or not.\"\"\"\n",
    "    \n",
    "# another dude's code: https://github.com/tensorflow/tensor2tensor/issues/869\n",
    "  def infer(self,\n",
    "            features=None,\n",
    "            decode_length=50,\n",
    "            beam_size=1,\n",
    "            top_beams=1,\n",
    "            alpha=0.0,\n",
    "            use_tpu=False):\n",
    "        \n",
    "# another guy's config: https://colab.research.google.com/github/tensorflow/tensor2tensor/blob/master/tensor2tensor/notebooks/asr_transformer.ipynb#scrollTo=od7ZPT3wfkZs\n",
    "def transcribe(inputs):\n",
    "  encoded_inputs = encode(inputs)\n",
    "  with tfe.restore_variables_on_create(ckpt_path): \n",
    "    model_output = asr_model.infer(encoded_inputs, beam_size=2, alpha=0.6, decode_length=1)[\"outputs\"]\n",
    "  return decode(model_output)\n",
    "\n",
    "def play_and_transcribe(inputs):\n",
    "  waveforms = encoders[\"waveforms\"].encode(inputs)\n",
    "  IPython.display.display(IPython.display.Audio(data=waveforms, rate=16000))\n",
    "  return transcribe(inputs) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When Democratic Rep. Rashida Tlaib accused Republican Rep. Mark Meadows of racism earlier this year, one of his \"best friends,\" House Oversight Committee chairman and Democratic Rep. Elijah Cummings immediately jumped to his defense. When Cummings was attacked on similar grounds by President Donald Trump over the weekend, it took a bit longer for Meadows to publicly repay the favor. On Saturday and Sunday, Trump went after Cummings on Twitter, calling the veteran Democratic lawmaker a \"racist\" and his district a \"disgusting, rat and rodent infested mess.\" Trump's comments hung in the air for days, sparking yet another conversation about the President's race-focused rhetoric. Republicans largely stayed silent, including Meadows, whose warm relationship with Cummings prompted questions about his reticence to defend his friend.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interesting convo about problems with decoder:\n",
    "    https://groups.google.com/forum/#!topic/tensor2tensor/2Nn-nXuDPAs\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!t2t-decoder \\\n",
    "--t2t_usr_dir=\".\" \\\n",
    "--data_dir=\"./t2t_data/\" \\\n",
    "--problem=\"gavrilov\" \\\n",
    "--model=\"universal_transformer\" \\\n",
    "--hparams_set=\"universal_transformer_gavrilov\" \\\n",
    "--output_dir=\"./t2t_data/model\" \\\n",
    "--decode_hparams=\"beam_size=10,alpha=0.9\" \\\n",
    "--decode_to_file=decoded_devtext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BEAM_SIZE=1\n",
    "ALPHA=0.6\n",
    "\n",
    "t2t-decoder \\\n",
    "  --data_dir=$DATA_DIR \\\n",
    "  --problems=$PROBLEM \\\n",
    "  --model=$MODEL \\\n",
    "  --hparams_set=$HPARAMS \\\n",
    "  --hparams='sampling_method=random' \\\n",
    "  --output_dir=$TRAIN_DIR \\\n",
    "  --decode_beam_size=$BEAM_SIZE \\\n",
    "  --decode_alpha=$ALPHA \\\n",
    "  --worker_gpu=$WORKER_GPU \\\n",
    "  --local_eval_frequency=0 \\\n",
    "  --return_beams=True \\\n",
    "  --decode_interactive \\"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
